{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolov7.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1900690/kyouyu/blob/main/yolov7.80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLOv7を使って自作データセットで物体検出してみたhttps://dev.classmethod.jp/articles/yolov7-train-with-customize-dataset/"
      ],
      "metadata": {
        "id": "rN5V-AInHMBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[精度を上げるための考察](https://www.nakasha.co.jp/future/ai/yolov3train.html)\n",
        "[ハイパーパラメータ進化について](https://farml1.com/yolov7/)"
      ],
      "metadata": {
        "id": "blVDL015QYjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "※まずランタイムをＧＰＵにすること\n",
        "\n",
        "※計算はdriveで行うのでログインするアカウントに注意"
      ],
      "metadata": {
        "id": "EG4zw1tF7aKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#★切り取り消去用道具★\n",
        "import shutil\n",
        "#shutil.rmtree('/content/detect_output2')\n",
        "#shutil.move('/content/drive/MyDrive/cut', '/content/')\n",
        "#shutil.move('/content/cut_crear', '/content/drive/MyDrive')\n",
        "#shutil.move('/content/drive/MyDrive/yolov7', '/content/')\n",
        "#shutil.rmtree('/content/drive/MyDrive/Untitled Folder')\n",
        "#shutil.rmtree('/content/drive/MyDrive/yolov7/dataset/mite')\n",
        "#%mkdir \"/content/drive/MyDrive/yolov7/dataset/mite/train/images\"\n",
        "#!unzip -q /content/DSC_0281split_y3_x9.zip\n",
        "shutil.make_archive('/content/drive/MyDrive/idouyou_dataset', format='zip', root_dir='/content/drive/MyDrive/idouyou_dataset')\n",
        "#shutil.unpack_archive(\"/content/drive/MyDrive/idouyou_dataset/dataset.zip\", \"/content/drive/MyDrive/idouyou_dataset/\")\n",
        "#shutil.unpack_archive(\"/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite.zip\", \"/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite\")\n",
        "#shutil.copy('/content/20221123yolov7-10epoch-8592mages-200size-mite2/weights/20221123yolov7-10epoch-8592mages-200size-mite2.pt','/content/drive/MyDrive/weights_box')"
      ],
      "metadata": {
        "id": "TJ8l9lcfGNsv",
        "outputId": "8f21ff7a-9e80-4053-b9bf-91c44076d154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/idouyou_dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite.zip\", \"/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite\")"
      ],
      "metadata": {
        "id": "9KK8wmOF0Elz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ドライブに接続"
      ],
      "metadata": {
        "id": "NOFSPhoocxaW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xv0DNhGz4Wj-",
        "outputId": "a185d733-d55a-4a65-c900-7f4f6cbc1892",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#リマウント\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "id": "kl3hGKoi9rKh",
        "outputId": "1a867bda-1bb0-4029-e829-11521c8a1346",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exit()"
      ],
      "metadata": {
        "id": "kbPZhZHz7Ox9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#事前準備"
      ],
      "metadata": {
        "id": "PpgKpzVbdOSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ドライブバージョン\n",
        "%cd \"/content/drive/MyDrive\"\n",
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "%cd \"/content/drive/MyDrive/yolov7\""
      ],
      "metadata": {
        "id": "91UrKWbYY1UE",
        "outputId": "e7d3a0a9-1df9-4a36-9bf9-dbfc18c0ae88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1088, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 1088 (delta 18), reused 81 (delta 17), pack-reused 998\u001b[K\n",
            "Receiving objects: 100% (1088/1088), 69.97 MiB | 17.91 MiB/s, done.\n",
            "Resolving deltas: 100% (485/485), done.\n",
            "Checking out files: 100% (104/104), done.\n",
            "/content/drive/MyDrive/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#contentバージョン\n",
        "!git clone https://github.com/WongKinYiu/yolov7"
      ],
      "metadata": {
        "id": "LFXc9RBy5adI",
        "outputId": "4a46547d-a2f1-47b2-ceb0-6c1a8243f7a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1127, done.\u001b[K\n",
            "remote: Total 1127 (delta 0), reused 0 (delta 0), pack-reused 1127\u001b[K\n",
            "Receiving objects: 100% (1127/1127), 69.92 MiB | 15.38 MiB/s, done.\n",
            "Resolving deltas: 100% (528/528), done.\n",
            "Checking out files: 100% (104/104), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -r requirements.txt\n",
        "!pip install PyYAML==5.4.1"
      ],
      "metadata": {
        "id": "eUhiWQ7h5qjw",
        "outputId": "1d53eeab-d35f-4a6c-ee96-a0fb44276733",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyYAML==5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "Successfully installed PyYAML-5.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#データセットを入れるためのフォルダを作成"
      ],
      "metadata": {
        "id": "bHHfw3UQd4Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree(\"/content/drive/MyDrive/yolov7/dataset\")"
      ],
      "metadata": {
        "id": "oZublqbwfgNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ドライブバージョン\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/drive/MyDrive/yolov7/dataset/mite/train/images'):\n",
        "  os.makedirs('/content/drive/MyDrive/yolov7/dataset/mite/train/images')\n",
        "  os.makedirs('/content/drive/MyDrive/yolov7/dataset/mite/train/labels')\n",
        "  os.makedirs('/content/drive/MyDrive/yolov7/dataset/mite/valid/images')\n",
        "  os.makedirs('/content/drive/MyDrive/yolov7/dataset/mite/valid/labels')"
      ],
      "metadata": {
        "id": "rLJThEu3HGKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#contentバージョン\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/yolov7/dataset/mite/train/images'):\n",
        "  os.makedirs('/content/yolov7/dataset/mite/train/images')\n",
        "  os.makedirs('/content/yolov7/dataset/mite/train/labels')\n",
        "  os.makedirs('/content/yolov7/dataset/mite/valid/images')\n",
        "  os.makedirs('/content/yolov7/dataset/mite/valid/labels')"
      ],
      "metadata": {
        "id": "dwgD5Mrm6B6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#データセットを分割"
      ],
      "metadata": {
        "id": "LG2hJpEEKi0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fastlabelから直接contentへダウンロード\n",
        "import shutil\n",
        "#fastrabel\n",
        "!wget -O \"/content/fastlabel.zip\" \"https://s3.ap-northeast-1.amazonaws.com/prod.fastlabel.app.exports/3efde406-abc7-4f3e-a3bd-905d3535a34d/3a93ecff-ad81-49b0-b8e1-74f460bc97c5/exports/20221106015037.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAYVHKCFVVH7AKJ5WM%2F20221106%2Fap-northeast-1%2Fs3%2Faws4_request&X-Amz-Date=20221106T054715Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBAaDmFwLW5vcnRoZWFzdC0xIkcwRQIhAKRilNroYbS4S4UrMwDebCBwMDzcDTNNQ1yPYeciwr7HAiA%2F85sv3lXqzII6%2B4s5YOritncpmF5UqJ0AdMghrg16WyqFBAj5%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDU5NTM0Mzg0Njc2MiIM1VIeAfPrwVXhH5LnKtkDomfYFDncXF7V5fEfp7L1kOb0xVl4bNmEo7a3E0R1NNgkFCKuH9SN8wVAhp6POD%2BGsDXcCQdDlDZEbodMKxxBAdnHVjqbxyA%2FmVd3xIAa0CI9LnDx7075a%2B3shibhfNoruSvdWKGeC2oXrSo91yvj0%2FfecgQtVYDzZ%2FLAf5oPqbWcwmG7vzKdX4DEAun75AlES6uNw9k8RCINPBvMX%2BQC%2BQy5MJ8bmY%2FdDgaSNQZCAtQzCNQ%2FGBmwfgc12UJqZrFy7e66bs3cfnCPoQ%2BbicQ5sENFwRaiYVvBZzgph%2FXh7FTlRL4pUhoTrlB24Kvml3%2BKqZRqMveA4GMtix12vZVukjmuvkylQPV0Nq%2BDqBXl%2BShl15EOdx2bYF20u%2FE%2FsY8%2BS488FlCbp1thXr0XrNis6H7dAc7os22Gj0ARGlsbCiF%2BvMJGMKyrwc7aZBxqpvZzzEsi%2F1Immm9CZiAyBrmz6mc3jX4j7mm8NjIIkDNaVP2Z3NWx6%2ByKMreSMLT0w%2FYWLTWJ%2BjxyIBPL3g53dOBFykwuMAXBWqq4xrcIHlsJsRefdWI%2FwINKAb46RJ%2BJUWAnfCN0QJJ2Jo0v5BHWuRNUFU6uEIO89m0MRihHHAioOlH8Jax558I%2FAtkww%2FCbmwY6pQH%2F3hZngAQ3I7zeNp%2BG34TXM6hbxKi8qUWJz%2BfiiuCCPW56cXjqOyss0ioXAFrglN41UlaAWwCbIsfZ1tb339viB%2BCZne1uBWQn15xAr%2FGIuZOZEBWLhzLTygbzyKHCsYQ5bhSQiEPQbyz3mN%2BalhqgTl%2FX1wZ6f3CceDSNdcRUNaBwXkZpxFFUsxnC7Oskp%2BwMNMX2LMCmWUtFKGSALLbEdmY6hdo%3D&X-Amz-Signature=55658812d65af34bb28d3f506eb933c66393aa7c981a3b39e701c3108060a19c&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22mite-bbox-rotation-360-flip_20221106015037.zip%22\"\n",
        "shutil.unpack_archive('/content/fastlabel.zip', '/content')\n",
        "#roboflow\n",
        "#!wget -O \"/content/mask.zip\" \"https://public.roboflow.com/ds/5Sgfwh8fVh?key=B1sJwF8cTX\"\n",
        "#shutil.unpack_archive('/content/mask.zip', '/content')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdUYbPerknvb",
        "outputId": "aa18a83c-0e9f-4e32-fe85-30c4e2f49e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-06 05:47:48--  https://s3.ap-northeast-1.amazonaws.com/prod.fastlabel.app.exports/3efde406-abc7-4f3e-a3bd-905d3535a34d/3a93ecff-ad81-49b0-b8e1-74f460bc97c5/exports/20221106015037.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAYVHKCFVVH7AKJ5WM%2F20221106%2Fap-northeast-1%2Fs3%2Faws4_request&X-Amz-Date=20221106T054715Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBAaDmFwLW5vcnRoZWFzdC0xIkcwRQIhAKRilNroYbS4S4UrMwDebCBwMDzcDTNNQ1yPYeciwr7HAiA%2F85sv3lXqzII6%2B4s5YOritncpmF5UqJ0AdMghrg16WyqFBAj5%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDU5NTM0Mzg0Njc2MiIM1VIeAfPrwVXhH5LnKtkDomfYFDncXF7V5fEfp7L1kOb0xVl4bNmEo7a3E0R1NNgkFCKuH9SN8wVAhp6POD%2BGsDXcCQdDlDZEbodMKxxBAdnHVjqbxyA%2FmVd3xIAa0CI9LnDx7075a%2B3shibhfNoruSvdWKGeC2oXrSo91yvj0%2FfecgQtVYDzZ%2FLAf5oPqbWcwmG7vzKdX4DEAun75AlES6uNw9k8RCINPBvMX%2BQC%2BQy5MJ8bmY%2FdDgaSNQZCAtQzCNQ%2FGBmwfgc12UJqZrFy7e66bs3cfnCPoQ%2BbicQ5sENFwRaiYVvBZzgph%2FXh7FTlRL4pUhoTrlB24Kvml3%2BKqZRqMveA4GMtix12vZVukjmuvkylQPV0Nq%2BDqBXl%2BShl15EOdx2bYF20u%2FE%2FsY8%2BS488FlCbp1thXr0XrNis6H7dAc7os22Gj0ARGlsbCiF%2BvMJGMKyrwc7aZBxqpvZzzEsi%2F1Immm9CZiAyBrmz6mc3jX4j7mm8NjIIkDNaVP2Z3NWx6%2ByKMreSMLT0w%2FYWLTWJ%2BjxyIBPL3g53dOBFykwuMAXBWqq4xrcIHlsJsRefdWI%2FwINKAb46RJ%2BJUWAnfCN0QJJ2Jo0v5BHWuRNUFU6uEIO89m0MRihHHAioOlH8Jax558I%2FAtkww%2FCbmwY6pQH%2F3hZngAQ3I7zeNp%2BG34TXM6hbxKi8qUWJz%2BfiiuCCPW56cXjqOyss0ioXAFrglN41UlaAWwCbIsfZ1tb339viB%2BCZne1uBWQn15xAr%2FGIuZOZEBWLhzLTygbzyKHCsYQ5bhSQiEPQbyz3mN%2BalhqgTl%2FX1wZ6f3CceDSNdcRUNaBwXkZpxFFUsxnC7Oskp%2BwMNMX2LMCmWUtFKGSALLbEdmY6hdo%3D&X-Amz-Signature=55658812d65af34bb28d3f506eb933c66393aa7c981a3b39e701c3108060a19c&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22mite-bbox-rotation-360-flip_20221106015037.zip%22\n",
            "Resolving s3.ap-northeast-1.amazonaws.com (s3.ap-northeast-1.amazonaws.com)... 52.219.196.88, 52.219.196.84, 52.219.16.22, ...\n",
            "Connecting to s3.ap-northeast-1.amazonaws.com (s3.ap-northeast-1.amazonaws.com)|52.219.196.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13321210 (13M) [binary/octet-stream]\n",
            "Saving to: ‘/content/fastlabel.zip’\n",
            "\n",
            "/content/fastlabel. 100%[===================>]  12.70M  5.16MB/s    in 2.5s    \n",
            "\n",
            "2022-11-06 05:47:52 (5.16 MB/s) - ‘/content/fastlabel.zip’ saved [13321210/13321210]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##contentに画像とラベルデータを解凍する"
      ],
      "metadata": {
        "id": "6DaU8-NbJXmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "if not os.path.exists('/content/annotations'):\n",
        "  shutil.unpack_archive('/content/drive/MyDrive/mite_annotations.zip', '/content/annotations')\n",
        "if not os.path.exists('/content/originals'):\n",
        "  shutil.unpack_archive('/content/drive/MyDrive/mite_original.zip', '/content/originals')\n",
        "if not os.path.exists('/content/annotations_not_mite'):\n",
        "  shutil.unpack_archive('/content/drive/MyDrive/not_mite_annotations.zip', '/content/annotations_not_mite')\n",
        "if not os.path.exists('/content/originals_not_mite'):\n",
        "  shutil.unpack_archive('/content/drive/MyDrive/not_mite_original.zip', '/content/originals_not_mite')"
      ],
      "metadata": {
        "id": "-3_GJn2ruaHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##画像サイズを640にアップサンプリング（アノテーションはそのままでよい）"
      ],
      "metadata": {
        "id": "pIO89t-FF95q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#画像サイズを640にアップサンプリング（アノテーションはそのままでよい）\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/originals_upsamples/'):\n",
        "  os.makedirs('/content/originals_upsamples/')\n",
        "if not os.path.exists('/content/originals_upsamples_not_mite/'):\n",
        "  os.makedirs('/content/originals_upsamples_not_mite/')\n",
        "\n",
        "originals=('/content/originals/*')\n",
        "read_files = glob.glob(originals)\n",
        "originals_not_mite=('/content/originals_not_mite/*')\n",
        "read_files_not_mite = glob.glob(originals_not_mite)\n",
        "\n",
        "for imgpass in read_files:\n",
        "  # 読み込む画像を選択\n",
        "  img = cv2.imread(imgpass)\n",
        "  # サイズ設定｜cv2では(幅、高さ）の順で数値を設定\n",
        "  size = (640,640) \n",
        "  # 画像拡大・縮小 オプションで拡大計算式変更可能\n",
        "  img_inter_area  = cv2.resize(img,size,interpolation = cv2.INTER_LINEAR) \n",
        "  #保存\n",
        "  cv2.imwrite('/content/originals_upsamples/'+os.path.split(imgpass)[1], img_inter_area)\n",
        "for imgpass in read_files_not_mite:\n",
        "  # 読み込む画像を選択\n",
        "  img = cv2.imread(imgpass)\n",
        "  # サイズ設定｜cv2では(幅、高さ）の順で数値を設定\n",
        "  size = (640,640) \n",
        "  # 画像拡大・縮小 オプションで拡大計算式変更可能\n",
        "  img_inter_area  = cv2.resize(img,size,interpolation = cv2.INTER_LINEAR) \n",
        "  #保存\n",
        "  cv2.imwrite('/content/originals_upsamples_not_mite/'+os.path.split(imgpass)[1], img_inter_area)"
      ],
      "metadata": {
        "id": "jXRvUztnWkuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "annotations=('/content/annotations')\n",
        "originals=('/content/originals_upsamples')\n",
        "annotations_not_mite=('/content/annotations_not_mite')\n",
        "originals_not_mite=('/content/originals_upsamples_not_mite')\n",
        "\n",
        "read_files_annotations = os.listdir(annotations)\n",
        "read_files_annotations.sort()\n",
        "read_files_originals= os.listdir(originals)\n",
        "read_files_originals.sort()\n",
        "read_files_annotations_not_mite = os.listdir(annotations_not_mite)\n",
        "read_files_annotations_not_mite.sort()\n",
        "read_files_originals_not_mite= os.listdir(originals_not_mite)\n",
        "read_files_originals_not_mite.sort()\n",
        "\n",
        "annotations_train, annotations_test, originals_train, originals_test = train_test_split(read_files_annotations,read_files_originals,test_size=0.2)\n",
        "annotations_train_not_mite, annotations_test_not_mite, originals_train_not_mite, originals_test_not_mite = train_test_split(read_files_annotations_not_mite,read_files_originals_not_mite,test_size=0.00001)"
      ],
      "metadata": {
        "id": "NPTMFr5NKg3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#driveバージョン\n",
        "import os\n",
        "import math\n",
        "\n",
        "for filename in annotations_train:\n",
        "  shutil.copy( annotations+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/train/labels/')\n",
        "for filename in annotations_test:\n",
        "  shutil.copy( annotations+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/valid/labels')\n",
        "for filename in originals_train:\n",
        "  shutil.copy( originals+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/train/images')\n",
        "for filename in originals_test:\n",
        "  shutil.copy( originals+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/valid/images')\n",
        "\n",
        "for filename in annotations_train_not_mite:\n",
        "  shutil.copy( annotations_not_mite+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/train/labels/')\n",
        "#for filename in annotations_test_not_mite:\n",
        "  #shutil.copy( annotations_not_mite+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/valid/labels')\n",
        "for filename in originals_train_not_mite:\n",
        "  shutil.copy( originals_not_mite+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/train/images')\n",
        "#for filename in originals_test_not_mite:\n",
        "  #shutil.copy( originals_not_mite+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/valid/images')\n",
        "\n",
        "#ディレクトリのパスを指定\n",
        "train_images = '/content/drive/MyDrive/yolov7/dataset/mite/train/images'\n",
        "train_labels = '/content/drive/MyDrive/yolov7/dataset/mite/train/labels'\n",
        "valid_images = '/content/drive/MyDrive/yolov7/dataset/mite/valid/images'\n",
        "valid_labels = '/content/drive/MyDrive/yolov7/dataset/mite/valid/labels'\n",
        "#ファイル数を出力\n",
        "print(\"train/imagesは\",sum(os.path.isfile(os.path.join(train_images, name)) for name in os.listdir(train_images)))\n",
        "print(\"train/labelsは\",sum(os.path.isfile(os.path.join(train_labels, name)) for name in os.listdir(train_labels)))\n",
        "print(\"valid/imagesは\",sum(os.path.isfile(os.path.join(valid_images, name)) for name in os.listdir(valid_images)))\n",
        "print(\"valid/labelsは\",sum(os.path.isfile(os.path.join(valid_labels, name)) for name in os.listdir(valid_labels)))\n",
        "print(\"最大公約数は\",math.gcd(sum(os.path.isfile(os.path.join(train_images, name)) for name in os.listdir(train_images)),sum(os.path.isfile(os.path.join(valid_images, name)) for name in os.listdir(valid_images))))"
      ],
      "metadata": {
        "id": "KjtJL8BjUUAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0052862a-1bed-4886-8259-8a76b7708fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/imagesは 16971\n",
            "train/labelsは 16971\n",
            "valid/imagesは 1851\n",
            "valid/labelsは 1851\n",
            "最大公約数は 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(annotations_test[0])\n",
        "print(originals_test[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4c8dv8bihjV",
        "outputId": "467a318a-28e2-42db-9664-49fa9ede7a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMG_20220310_111421_180_2190_2688_c0180_x-026_y0012_f.txt\n",
            "IMG_20220310_111421_180_2190_2688_c0180_x-026_y0012_f.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.remove(valid_images+\"/\"+originals_test[0])\n",
        "#os.remove(valid_labels+\"/\"+annotations_test[0])"
      ],
      "metadata": {
        "id": "eHrRt7Xyi4DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#調整後調査用\n",
        "train_images = '/content/drive/MyDrive/yolov7/dataset/mite/train/images'\n",
        "train_labels = '/content/drive/MyDrive/yolov7/dataset/mite/train/labels'\n",
        "valid_images = '/content/drive/MyDrive/yolov7/dataset/mite/valid/images'\n",
        "valid_labels = '/content/drive/MyDrive/yolov7/dataset/mite/valid/labels'\n",
        "#ファイル数を出力\n",
        "print(\"train/imagesは\",sum(os.path.isfile(os.path.join(train_images, name)) for name in os.listdir(train_images)))\n",
        "print(\"train/labelsは\",sum(os.path.isfile(os.path.join(train_labels, name)) for name in os.listdir(train_labels)))\n",
        "print(\"valid/imagesは\",sum(os.path.isfile(os.path.join(valid_images, name)) for name in os.listdir(valid_images)))\n",
        "print(\"valid/labelsは\",sum(os.path.isfile(os.path.join(valid_labels, name)) for name in os.listdir(valid_labels)))\n",
        "print(\"最大公約数は\",math.gcd(sum(os.path.isfile(os.path.join(train_images, name)) for name in os.listdir(train_images)),sum(os.path.isfile(os.path.join(valid_images, name)) for name in os.listdir(valid_images))))"
      ],
      "metadata": {
        "id": "-4BeSEGqJKsM",
        "outputId": "3ec27007-28c5-44bd-b3b3-516c8d9a25ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/imagesは 16970\n",
            "train/labelsは 16970\n",
            "valid/imagesは 1850\n",
            "valid/labelsは 1850\n",
            "最大公約数は 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#contentバージョン\n",
        "import os\n",
        "import math\n",
        "\n",
        "for filename in annotations_train:\n",
        "  shutil.copy( annotations+\"/\"+filename,'/content/yolov7/dataset/mite/train/labels/')\n",
        "for filename in annotations_test:\n",
        "  shutil.copy( annotations+\"/\"+filename,'/content/yolov7/dataset/mite/valid/labels')\n",
        "for filename in originals_train:\n",
        "  shutil.copy( originals+\"/\"+filename,'/content/yolov7/dataset/mite/train/images')\n",
        "for filename in originals_test:\n",
        "  shutil.copy( originals+\"/\"+filename,'/content/yolov7/dataset/mite/valid/images')\n",
        "#ディレクトリのパスを指定\n",
        "train_images = '/content/yolov7/dataset/mite/train/images'\n",
        "train_labels = '/content/yolov7/dataset/mite/train/labels'\n",
        "valid_images = '/content/yolov7/dataset/mite/valid/images'\n",
        "valid_labels = '/content/yolov7/dataset/mite/valid/labels'\n",
        "#ファイル数を出力\n",
        "print(\"train/imagesは\",sum(os.path.isfile(os.path.join(train_images, name)) for name in os.listdir(train_images)))\n",
        "print(\"train/labelsは\",sum(os.path.isfile(os.path.join(train_labels, name)) for name in os.listdir(train_labels)))\n",
        "print(\"valid/imagesは\",sum(os.path.isfile(os.path.join(valid_images, name)) for name in os.listdir(valid_images)))\n",
        "print(\"valid/labelsは\",sum(os.path.isfile(os.path.join(valid_labels, name)) for name in os.listdir(valid_labels)))"
      ],
      "metadata": {
        "id": "koHCIvwO7Akn",
        "outputId": "60926aa7-b889-4888-969c-233e83059e22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/imagesは 2296\n",
            "train/labelsは 2296\n",
            "valid/imagesは 574\n",
            "valid/labelsは 574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#データセットへのパスとクラスについての情報を記載しdataファイルへ入れる"
      ],
      "metadata": {
        "id": "bMau9RQveSVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/yolov7/data/mite.yaml\n",
        "# COCO 2017 dataset http://cocodataset.org\n",
        "\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: ./dataset/mite/train\n",
        "val: ./dataset/mite/valid\n",
        "\n",
        "# number of classes\n",
        "nc: 1\n",
        "\n",
        "# class names\n",
        "names: ['mite']"
      ],
      "metadata": {
        "id": "_odMXZBiYngq",
        "outputId": "03ec2122-9137-47f7-8f38-a085cd188cd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/drive/MyDrive/yolov7/data/mite.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/yolov7/data/mite.yaml\n",
        "# COCO 2017 dataset http://cocodataset.org\n",
        "\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: ./dataset/mite/train\n",
        "val: ./dataset/mite/valid\n",
        "\n",
        "# number of classes\n",
        "nc: 1\n",
        "\n",
        "# class names\n",
        "names: ['mite']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYQbuRa-HNXi",
        "outputId": "896544a0-15d1-415c-945b-5880907efdcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/yolov7/data/mite.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/yolov7/data/mask.yaml\n",
        "# COCO 2017 dataset http://cocodataset.org\n",
        "\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: ./dataset/mask/train\n",
        "val: ./dataset/mask/valid\n",
        "\n",
        "# number of classes\n",
        "nc: 2\n",
        "\n",
        "# class names\n",
        "names: ['mask','non-mask']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMLDEmX8MJDH",
        "outputId": "e8a47ee5-3dad-40d2-85eb-810e7ca17b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/yolov7/data/mask.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#学習開始\n",
        "※学習時間はlogの中に書いてある"
      ],
      "metadata": {
        "id": "Tw3efjK_H1MS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[物体検出の評価指標の計算方法](https://axa.biopapyrus.jp/deep-learning/cnn/object-detection/map.html)"
      ],
      "metadata": {
        "id": "AW2R7xfJsqSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "if os.path.exists('/content/drive/MyDrive/yolov7/checkpoints'):\n",
        "  shutil.rmtree('/content/drive/MyDrive/yolov7/checkpoints')\n",
        "#重みをコピー\n",
        "shutil.copytree('/content/drive/MyDrive/weights_box','/content/drive/MyDrive/yolov7/checkpoints')"
      ],
      "metadata": {
        "id": "FhPYxMwf83mV",
        "outputId": "d37f13e1-c83b-41c8-e604-a67e48e39d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/yolov7/checkpoints'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "#初学習用、学習前の重みをダウンロード\n",
        "#!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6.pt -P ./checkpoints\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt -P ./checkpoints"
      ],
      "metadata": {
        "id": "1qf9VrXAIIk8",
        "outputId": "9c059167-263b-48fe-c76b-3bd41b4ea057",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov7\n",
            "--2023-01-14 08:43:04--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230114T084304Z&X-Amz-Expires=300&X-Amz-Signature=2d1053a92ffcedc18a218d11d3ed7a3c0ad757281b3b01ac2fe38fb8b48cee88&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-01-14 08:43:05--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230114T084304Z&X-Amz-Expires=300&X-Amz-Signature=2d1053a92ffcedc18a218d11d3ed7a3c0ad757281b3b01ac2fe38fb8b48cee88&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75628875 (72M) [application/octet-stream]\n",
            "Saving to: ‘./checkpoints/yolov7_training.pt’\n",
            "\n",
            "yolov7_training.pt  100%[===================>]  72.12M  13.9MB/s    in 5.1s    \n",
            "\n",
            "2023-01-14 08:43:10 (14.2 MB/s) - ‘./checkpoints/yolov7_training.pt’ saved [75628875/75628875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   batch-sizeでepochあたりに使用する画像の枚数を調節（2だと1epochあたり総数/2枚使用する。なので、ここを増やすとGPUメモリを節約できる）（バッチ枚ごとにパラメータの見直しを行う）\n",
        "*   [index 30 is out of bounds for axis 0 with size 30 for Evolveエラーの場合](https://github.com/WongKinYiu/yolov7/issues/999)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qqT4FJfKpupu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#初学習\n",
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "!python train.py \\\n",
        "  --workers 1 \\\n",
        "  --batch-size 5 \\\n",
        "  --data data/mite.yaml \\\n",
        "  --cfg cfg/training/yolov7.yaml \\\n",
        "  --weights /content/drive/MyDrive/yolov7/checkpoints/yolov7_training.pt \\\n",
        "  --name '/content/drive/MyDrive/20230114yolov7-300epoch-5batch-188200images-640upsized-mite' \\\n",
        "  --hyp data/hyp.scratch.p5.yaml \\\n",
        "  --img 640 640 \\\n",
        "  --epochs 300 \\\n",
        "  --device 0 "
      ],
      "metadata": {
        "id": "VR0zPw8o8D3O",
        "outputId": "5cf01a25-7fec-4bcc-ca2b-c3f9799a330a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov7\n",
            "YOLOR 🚀 v0.1-116-g8c0bf3f torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=5, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/mite.yaml', device='0', entity=None, epochs=300, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='/content/drive/MyDrive/20230114yolov7-300epoch-5batch-188200images-640upsized-mite', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='/content/drive/MyDrive/20230114yolov7-300epoch-5batch-188200images-640upsized-mite', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=5, upload_dataset=False, v5_metric=False, weights='/content/drive/MyDrive/yolov7/checkpoints/yolov7_training.pt', workers=1, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     34156  models.yolo.IDetect                     [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "Model Summary: 415 layers, 37196556 parameters, 37196556 gradients\n",
            "\n",
            "Transferred 555/566 items from /content/drive/MyDrive/yolov7/checkpoints/yolov7_training.pt\n",
            "Scaled weight_decay = 0.0005078125\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'dataset/mite/train/labels' images and labels... 16970 found, 0 missing, 9571 empty, 0 corrupted: 100% 16970/16970 [01:00<00:00, 282.25it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: dataset/mite/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'dataset/mite/valid/labels' images and labels... 1850 found, 0 missing, 0 empty, 0 corrupted: 100% 1850/1850 [00:05<00:00, 316.93it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: dataset/mite/valid/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 6.06, Best Possible Recall (BPR) = 0.9998\n",
            "Image sizes 640 train, 640 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to /content/drive/MyDrive/20230114yolov7-300epoch-5batch-188200images-640upsized-mite\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     0/299      4.8G   0.06077   0.00413         0    0.0649         4       640: 100% 3394/3394 [20:30<00:00,  2.76it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/185 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 185/185 [00:41<00:00,  4.45it/s]\n",
            "                 all        1850        2393      0.0488       0.236      0.0271     0.00574\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     1/299     4.74G   0.05839  0.002989         0   0.06138         3       640: 100% 3394/3394 [19:23<00:00,  2.92it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 185/185 [00:36<00:00,  5.07it/s]\n",
            "                 all        1850        2393       0.169       0.185      0.0689      0.0159\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     2/299     4.74G   0.05557  0.002842         0   0.05841         4       640: 100% 3394/3394 [20:28<00:00,  2.76it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 185/185 [00:36<00:00,  5.00it/s]\n",
            "                 all        1850        2393       0.188       0.293       0.143      0.0295\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     3/299     4.74G    0.0502  0.002568         0   0.05276         2       640: 100% 3394/3394 [19:23<00:00,  2.92it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 185/185 [00:35<00:00,  5.15it/s]\n",
            "                 all        1850        2393       0.466       0.438       0.379       0.109\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     4/299     4.74G    0.0485  0.002553         0   0.05105         4       640: 100% 3394/3394 [19:27<00:00,  2.91it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 185/185 [00:36<00:00,  5.14it/s]\n",
            "                 all        1850        2393       0.396       0.483       0.373       0.121\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     5/299     4.74G   0.04729   0.00261         0    0.0499         5       640: 100% 3394/3394 [19:09<00:00,  2.95it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 185/185 [00:36<00:00,  5.12it/s]\n",
            "                 all        1850        2393       0.538       0.524       0.497       0.168\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     6/299     4.74G   0.04645  0.002551         0     0.049         2       640: 100% 3394/3394 [19:17<00:00,  2.93it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 185/185 [00:38<00:00,  4.83it/s]\n",
            "                 all        1850        2393       0.719       0.597       0.653       0.249\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     7/299     4.74G   0.04616   0.00247         0   0.04863         5       640:  88% 2971/3394 [17:05<02:32,  2.77it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#初学習\n",
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "!python train_aux.py --workers 8 --batch-size 8 \\\n",
        "  --data data/mask.yaml \\\n",
        "  --cfg cfg/training/yolov7.yaml \\\n",
        "  --weights '/content/drive/MyDrive/yolov7/checkpoints' \\\n",
        "  --name '/content/drive/MyDrive/20221103yolov7-e6-mask' \\\n",
        "  --nosave \\\n",
        "  --hyp data/hyp.scratch.p6.yaml \\\n",
        "  --device 0 \\\n",
        "  --evolve"
      ],
      "metadata": {
        "id": "XBbgrPuOMdCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#続きから学習\n",
        "\n",
        "\n",
        "*   [接続が切れたときに途中から学習を再開するには](https://tt-tsukumochi.com/archives/3288#vk-htags-258c208d-53e5-453d-acd8-c3e332224cfd)\n",
        "\n",
        "\n",
        "*   [エラー indices should be either on cpu or on the same device as the indexed tensor (cpu)の場合](https://github.com/WongKinYiu/yolov7/issues/1101)"
      ],
      "metadata": {
        "id": "c2zHqhK5nWSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JsKs9a0cQhHF",
        "outputId": "4aef57f9-8f75-40aa-e91a-1a9c62b977f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#途中で切れた場合\n",
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "#最新の重みをロードする\n",
        "#!python train.py --resume /content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite/weights/last.pt\n",
        "!python train.py --resume /content/drive/MyDrive/20230114yolov7-300epoch-5batch-188200images-640upsized-mite/weights/last.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CoDWdNpEFqk",
        "outputId": "2f723639-9d2b-4103-d2ba-11068522345f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/yolov7'\n",
            "/content\n",
            "python3: can't open file 'train.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gh7aLasVsYWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#続きから新しく学習\n",
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "!python train.py \\\n",
        "  --workers 1 \\\n",
        "  --batch-size 2 \\\n",
        "  --data data/mite.yaml \\\n",
        "  --cfg cfg/training/yolov7.yaml \\\n",
        "  --weights /content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite/weights/best.pt \\\n",
        "  --name '/content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite' \\\n",
        "  --hyp data/hyp.scratch.p5.yaml \\\n",
        "  --img 160 160 \\\n",
        "  --epochs 50 \\\n",
        "  --device 0 "
      ],
      "metadata": {
        "id": "pbLG3pDJ2x09",
        "outputId": "649906f9-f7fd-4387-9924-21ddd6e7b9c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov7\n",
            "YOLOR 🚀 v0.1-115-g072f76c torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=2, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/mite.yaml', device='0', entity=None, epochs=50, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[160, 160], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='/content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='/content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=2, upload_dataset=False, v5_metric=False, weights='/content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite/weights/best.pt', workers=1, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     34156  models.yolo.IDetect                     [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "Model Summary: 415 layers, 37196556 parameters, 37196556 gradients\n",
            "\n",
            "Transferred 564/566 items from /content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite/weights/best.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'dataset/mite/train/labels.cache' images and labels... 1242 found, 0 missing, 0 empty, 0 corrupted: 100% 1242/1242 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'dataset/mite/valid/labels.cache' images and labels... 310 found, 0 missing, 0 empty, 0 corrupted: 100% 310/310 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.51, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 160 train, 160 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to /content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite2\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/49     2.75G   0.02441  0.002455         0   0.02687         1       160: 100% 621/621 [01:14<00:00,  8.37it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/78 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:05<00:00, 14.86it/s]\n",
            "                 all         310         319      0.0287        0.31      0.0165     0.00394\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/49     2.69G   0.02468  0.002372         0   0.02705         0       160: 100% 621/621 [01:09<00:00,  8.98it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.52it/s]\n",
            "                 all         310         319      0.0289       0.376      0.0194     0.00441\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/49     2.69G   0.02498  0.002433         0   0.02742         2       160: 100% 621/621 [01:07<00:00,  9.27it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.45it/s]\n",
            "                 all         310         319      0.0229       0.191     0.00976     0.00205\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/49     2.69G   0.02405  0.002391         0   0.02644         8       160: 100% 621/621 [01:06<00:00,  9.34it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.17it/s]\n",
            "                 all         310         319      0.0271       0.298      0.0147     0.00327\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/49     2.69G   0.02521  0.002476         0   0.02769         7       160: 100% 621/621 [01:06<00:00,  9.39it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.89it/s]\n",
            "                 all         310         319      0.0274       0.357      0.0174     0.00417\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/49     2.69G   0.02361  0.002303         0   0.02592         3       160: 100% 621/621 [01:05<00:00,  9.53it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.81it/s]\n",
            "                 all         310         319       0.026       0.213      0.0134     0.00253\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/49     2.69G   0.02456  0.002262         0   0.02682         4       160: 100% 621/621 [01:07<00:00,  9.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.50it/s]\n",
            "                 all         310         319      0.0295        0.21      0.0152     0.00358\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/49     2.69G   0.02303  0.002369         0    0.0254         0       160: 100% 621/621 [01:05<00:00,  9.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.98it/s]\n",
            "                 all         310         319      0.0443       0.238      0.0257     0.00624\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/49     2.69G   0.02326  0.002267         0   0.02553         7       160: 100% 621/621 [01:07<00:00,  9.27it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 16.14it/s]\n",
            "                 all         310         319      0.0345       0.373      0.0239     0.00572\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/49     2.69G    0.0244  0.002314         0   0.02672         0       160: 100% 621/621 [01:05<00:00,  9.50it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.19it/s]\n",
            "                 all         310         319      0.0522       0.317      0.0341     0.00984\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/49     2.69G    0.0236  0.002387         0   0.02598         8       160: 100% 621/621 [01:05<00:00,  9.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.17it/s]\n",
            "                 all         310         319      0.0688       0.292      0.0384      0.0107\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/49     2.69G   0.02387   0.00227         0   0.02614         5       160: 100% 621/621 [01:07<00:00,  9.24it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.76it/s]\n",
            "                 all         310         319      0.0304       0.389      0.0207     0.00554\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/49     2.69G   0.02284  0.002289         0   0.02512         2       160: 100% 621/621 [01:04<00:00,  9.59it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.80it/s]\n",
            "                 all         310         319      0.0264       0.248      0.0173     0.00512\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/49     2.69G   0.02305    0.0023         0   0.02535         4       160: 100% 621/621 [01:05<00:00,  9.51it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.57it/s]\n",
            "                 all         310         319      0.0901       0.245      0.0504      0.0166\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/49     2.69G   0.02365  0.002365         0   0.02602         3       160: 100% 621/621 [01:08<00:00,  9.04it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.82it/s]\n",
            "                 all         310         319      0.0331       0.451      0.0244     0.00731\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/49     2.69G    0.0235  0.002341         0   0.02584         7       160: 100% 621/621 [01:06<00:00,  9.31it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.03it/s]\n",
            "                 all         310         319      0.0523       0.395      0.0343      0.0105\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/49     2.69G   0.02321  0.002347         0   0.02556         0       160: 100% 621/621 [01:07<00:00,  9.22it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.61it/s]\n",
            "                 all         310         319      0.0237       0.185     0.00886     0.00232\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/49     2.69G   0.02321  0.002362         0   0.02557         9       160: 100% 621/621 [01:05<00:00,  9.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.05it/s]\n",
            "                 all         310         319       0.301       0.325       0.224      0.0744\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/49     2.69G   0.02219  0.002331         0   0.02452         4       160: 100% 621/621 [01:07<00:00,  9.19it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.89it/s]\n",
            "                 all         310         319       0.228       0.298       0.148      0.0531\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/49     2.69G   0.02302  0.002341         0   0.02537         6       160: 100% 621/621 [01:07<00:00,  9.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.28it/s]\n",
            "                 all         310         319       0.372       0.332       0.269      0.0901\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/49     2.69G   0.02271  0.002245         0   0.02496         2       160: 100% 621/621 [01:06<00:00,  9.38it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.24it/s]\n",
            "                 all         310         319       0.291       0.351       0.176      0.0596\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/49     2.69G   0.02215  0.002235         0   0.02438         2       160: 100% 621/621 [01:05<00:00,  9.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.52it/s]\n",
            "                 all         310         319       0.261       0.367       0.176      0.0576\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/49     2.69G   0.02231  0.002237         0   0.02455         1       160: 100% 621/621 [01:07<00:00,  9.21it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.88it/s]\n",
            "                 all         310         319       0.143       0.352      0.0954      0.0291\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/49     2.69G    0.0222  0.002301         0    0.0245         8       160: 100% 621/621 [01:06<00:00,  9.34it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.91it/s]\n",
            "                 all         310         319       0.434       0.323       0.298       0.112\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/49     2.69G   0.02219  0.002293         0   0.02449        12       160: 100% 621/621 [01:08<00:00,  9.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.27it/s]\n",
            "                 all         310         319       0.188       0.338       0.108      0.0351\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/49     2.69G   0.02197  0.002353         0   0.02433         1       160: 100% 621/621 [01:07<00:00,  9.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.84it/s]\n",
            "                 all         310         319       0.269       0.382       0.172      0.0572\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/49     2.69G   0.02253  0.002269         0    0.0248         1       160: 100% 621/621 [01:05<00:00,  9.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.13it/s]\n",
            "                 all         310         319       0.259       0.401       0.163      0.0517\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/49     2.69G   0.02323  0.002346         0   0.02557         4       160: 100% 621/621 [01:06<00:00,  9.38it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.89it/s]\n",
            "                 all         310         319       0.164       0.389       0.109      0.0335\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/49     2.69G   0.02252  0.002258         0   0.02478         2       160: 100% 621/621 [01:04<00:00,  9.60it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.22it/s]\n",
            "                 all         310         319      0.0666       0.417      0.0487      0.0155\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/49     2.69G   0.02132  0.002277         0    0.0236         5       160: 100% 621/621 [01:05<00:00,  9.52it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.15it/s]\n",
            "                 all         310         319      0.0505       0.639      0.0412      0.0132\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/49     2.69G   0.02169  0.002227         0   0.02392         0       160: 100% 621/621 [01:05<00:00,  9.50it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.27it/s]\n",
            "                 all         310         319      0.0321        0.42      0.0209     0.00587\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/49     2.69G   0.02148   0.00222         0    0.0237         1       160: 100% 621/621 [01:04<00:00,  9.61it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.17it/s]\n",
            "                 all         310         319      0.0625        0.47      0.0501      0.0155\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/49     2.69G   0.02242  0.002346         0   0.02477         4       160: 100% 621/621 [01:04<00:00,  9.56it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.39it/s]\n",
            "                 all         310         319      0.0429       0.549      0.0348      0.0117\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/49     2.69G   0.02103  0.002352         0   0.02338         0       160: 100% 621/621 [01:06<00:00,  9.34it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.03it/s]\n",
            "                 all         310         319      0.0495       0.605      0.0406      0.0126\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/49     2.69G   0.02184  0.002337         0   0.02417         8       160: 100% 621/621 [01:05<00:00,  9.47it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.08it/s]\n",
            "                 all         310         319      0.0489       0.624      0.0412      0.0128\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     35/49     2.69G   0.02087  0.002395         0   0.02327         2       160: 100% 621/621 [01:06<00:00,  9.35it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.12it/s]\n",
            "                 all         310         319      0.0481        0.58      0.0397       0.012\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     36/49     2.69G   0.02142  0.002275         0   0.02369         4       160: 100% 621/621 [01:05<00:00,  9.55it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.67it/s]\n",
            "                 all         310         319      0.0496        0.62      0.0415      0.0137\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     37/49     2.69G    0.0211  0.002329         0   0.02343         4       160: 100% 621/621 [01:05<00:00,  9.51it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.39it/s]\n",
            "                 all         310         319      0.0455       0.627      0.0375      0.0124\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     38/49     2.69G   0.02095   0.00232         0   0.02327         3       160: 100% 621/621 [01:06<00:00,  9.38it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.18it/s]\n",
            "                 all         310         319      0.0456       0.605      0.0369      0.0125\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     39/49     2.69G   0.02165  0.002326         0   0.02398         5       160: 100% 621/621 [01:04<00:00,  9.66it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.30it/s]\n",
            "                 all         310         319      0.0453       0.608      0.0372      0.0125\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     40/49     2.69G   0.02151  0.002277         0   0.02378         8       160: 100% 621/621 [01:04<00:00,  9.65it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:03<00:00, 19.67it/s]\n",
            "                 all         310         319      0.0466       0.545      0.0378      0.0129\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     41/49     2.69G   0.02125  0.002326         0   0.02357         4       160: 100% 621/621 [01:05<00:00,  9.45it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.98it/s]\n",
            "                 all         310         319      0.0508       0.577      0.0421      0.0138\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     42/49     2.69G   0.02138  0.002464         0   0.02384         2       160: 100% 621/621 [01:05<00:00,  9.49it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.33it/s]\n",
            "                 all         310         319      0.0579        0.58      0.0482       0.016\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     43/49     2.69G   0.02177  0.002321         0   0.02409         5       160: 100% 621/621 [01:04<00:00,  9.63it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:03<00:00, 19.57it/s]\n",
            "                 all         310         319      0.0685       0.574       0.055      0.0186\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     44/49     2.69G   0.01964  0.002345         0   0.02199         6       160: 100% 621/621 [01:05<00:00,  9.49it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.47it/s]\n",
            "                 all         310         319      0.0492       0.633      0.0409      0.0146\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     45/49     2.69G   0.02009  0.002372         0   0.02247         5       160: 100% 621/621 [01:03<00:00,  9.74it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:03<00:00, 19.53it/s]\n",
            "                 all         310         319      0.0404       0.652      0.0337       0.011\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     46/49     2.69G   0.02048  0.002368         0   0.02285         0       160: 100% 621/621 [01:06<00:00,  9.33it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 15.80it/s]\n",
            "                 all         310         319      0.0444       0.627      0.0365       0.012\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     47/49     2.69G   0.02084  0.002406         0   0.02324         4       160: 100% 621/621 [01:05<00:00,  9.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.40it/s]\n",
            "                 all         310         319      0.0438       0.592      0.0359      0.0122\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     48/49     2.69G   0.02203  0.002331         0   0.02436         5       160: 100% 621/621 [01:05<00:00,  9.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:03<00:00, 19.55it/s]\n",
            "                 all         310         319      0.0475       0.571      0.0389      0.0129\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     49/49     2.69G   0.02037  0.002293         0   0.02266         4       160: 100% 621/621 [01:07<00:00,  9.20it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 17.65it/s]\n",
            "                 all         310         319      0.0691       0.473      0.0537       0.018\n",
            "50 epochs completed in 1.007 hours.\n",
            "\n",
            "Optimizer stripped from /content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite2/weights/last.pt, 74.7MB\n",
            "Optimizer stripped from /content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite2/weights/best.pt, 74.7MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#学習結果で推論\n",
        "\n",
        "[出力オプションについて](https://qiita.com/hkwsdgea_ttt2/items/ba352f6e5ef6032b5dc9)\n",
        "[出力テキストの内容について](https://tt-tsukumochi.com/object_detection)\n",
        "*   「--save-txt」でテスト結果の座標を出力することができます。実行すると「runs/detect/exp〇/labels」にテキストファイルとして保存されます。「–save-txt」、「–save-conf」の引数を追加することで、テスト結果の座標とスコアを同時に出力することができます。"
      ],
      "metadata": {
        "id": "gSgJQuA_kuvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXnHvyngutCC",
        "outputId": "10184778-2f9e-409b-f5e1-be75055ef94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##画像をアップロード"
      ],
      "metadata": {
        "id": "EwvviqXk_nJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#画像をアップロードする場合\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/originals_test/'):\n",
        "    os.makedirs('/content/originals_test/')\n",
        "\n",
        "%cd '/content/originals_test/'\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "GCx-5xKf_l8v",
        "outputId": "72ea1ffa-d3e8-441f-d482-e39be4d661f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/originals_test\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0754acd1-7320-46ad-880e-98cfcc195646\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0754acd1-7320-46ad-880e-98cfcc195646\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IMG_20220310_110900_000.jpg to IMG_20220310_110900_000.jpg\n",
            "Saving IMG_20220310_111004_000.jpg to IMG_20220310_111004_000.jpg\n",
            "Saving IMG_20220310_111048_000.jpg to IMG_20220310_111048_000.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ドライブから直接コピー\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "from_file='/content/drive/MyDrive/バラ画像/20220328/mite/DSC_0003.jpg'\n",
        "\n",
        "file_renamed=os.path.basename(from_file[:-4])+'_180'+'.jpg'#向きの情報が必要\n",
        "\n",
        "if not os.path.exists('/content/originals_test/'):\n",
        "    os.makedirs('/content/originals_test/')\n",
        "\n",
        "shutil.copy(from_file, '/content/originals_test/'+file_renamed)"
      ],
      "metadata": {
        "id": "z46lNpiCxGbZ",
        "outputId": "532fc1fc-d782-4dce-fe0d-e20c848e8cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/originals_test/DSC_0003_180.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fastlabelから直接contentへダウンロード\n",
        "import shutil\n",
        "import os\n",
        "#fastrabel\n",
        "!wget -O \"/content/fastlabel.zip\" \"https://s3.ap-northeast-1.amazonaws.com/prod.fastlabel.app.exports/3efde406-abc7-4f3e-a3bd-905d3535a34d/96859d83-8473-4dec-8b0f-ff750a7f1851/exports/20230113150917.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAYVHKCFVVOVWEOTNI%2F20230113%2Fap-northeast-1%2Fs3%2Faws4_request&X-Amz-Date=20230113T061015Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHEaDmFwLW5vcnRoZWFzdC0xIkgwRgIhALHx2TDj7s1ECDyQPtvm6liXBXet9mp3jz4gh9rGcjSUAiEAw0WTLnEUaQVUjUXMsCBgDIfRt9Ao5dLk1F%2BKgfExC9UqhQQIy%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw1OTUzNDM4NDY3NjIiDLUMScrsZpF11pJXsSrZA4v9o4P%2BRLfUTW%2BuJodCuILzkBb00j7BwEj%2FjIvgeeT3mIdTrmSOuz4Q1ewp4WPV%2F5GChfZzqxImCEJ7A6RN4XrXhTRf3NyK0JCnOHoYyTUC490gGM5R2X9gYQsDVwG7Sn9%2Bn%2FHXwTrxTDDCPLOGhwriddLUQgiJqQ9XBW6osPsM9ccqB56Eu0enGZa7A6akLIEBKcIRSRJZeQjjkBj5NrNpuWXKhBnMHO07tj8Ljh9ezwJp68%2FrdMwOXwlyxv%2FCsor6rZO6PtX0JizkN%2BIutB1kmaCnxK41FdRclFWEJWGPpGVgSjIWYp74bfHs1Avf0G8kNsPM%2FkyehIPwIaS7Xbeyie5qenfFAFWw9YQHNvM9WX9%2B5xhqtPQcYUOg4Wr1G%2BSlsItcEazxmHQERvNuLUOU2VigrvcEKNBnbZH7JoRVQTtPRgFECzfQQkPOi%2FU9GsAYpQu%2FqGVHwAPJLNVoBfnEe1Mg%2BKrAu0%2FL35OIS2fP46u75gCXLw1%2FBhzOm1umBlzFDUAsZQ3J5DR9mShhvHig%2BB8TCdMVjylaS%2Fh6hUCeP0%2FXvKRYuD4aW3J1m1EimyJzBy8Qi7C1hXgkepa9cNDShV%2BTF9phMWeVFY8SfA9X90jHF%2FSYMb%2BnMPLpgp4GOqQBZ5znXhjTPM14j53IobZ%2B4b3VHMs5dZZE%2Ff5Ha5ZX6k%2Bt%2FW9M5wu0Iwos9%2FYUlDqOF8HiPvdWiTlcdlpqih8EsQ56lZqwBjrKGBQxLiqefBfIER6HrpvBaW68hnEfCR9WZiFMWN3NYhz4uOL2RzYDHnSpOls%2BfqmKpmC98xTBrlXelX2208ubwFTa1YEHrCsP%2F9mLMQ%2FcEv9Uu49DULY9bhF%2FKtA%3D&X-Amz-Signature=a6d4d1695ca3a2a24bb46680c33391578ab52e4e1761f1392176664de60fbe31&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22boundhingbox-mite_20230113150917.zip%22\"\n",
        "!wget -O \"/content/fastlabel2.zip\" \"https://s3.ap-northeast-1.amazonaws.com/prod.fastlabel.app.exports/3efde406-abc7-4f3e-a3bd-905d3535a34d/96859d83-8473-4dec-8b0f-ff750a7f1851/exports/20230113150917.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAYVHKCFVVOVWEOTNI%2F20230113%2Fap-northeast-1%2Fs3%2Faws4_request&X-Amz-Date=20230113T061015Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHEaDmFwLW5vcnRoZWFzdC0xIkgwRgIhALHx2TDj7s1ECDyQPtvm6liXBXet9mp3jz4gh9rGcjSUAiEAw0WTLnEUaQVUjUXMsCBgDIfRt9Ao5dLk1F%2BKgfExC9UqhQQIy%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw1OTUzNDM4NDY3NjIiDLUMScrsZpF11pJXsSrZA4v9o4P%2BRLfUTW%2BuJodCuILzkBb00j7BwEj%2FjIvgeeT3mIdTrmSOuz4Q1ewp4WPV%2F5GChfZzqxImCEJ7A6RN4XrXhTRf3NyK0JCnOHoYyTUC490gGM5R2X9gYQsDVwG7Sn9%2Bn%2FHXwTrxTDDCPLOGhwriddLUQgiJqQ9XBW6osPsM9ccqB56Eu0enGZa7A6akLIEBKcIRSRJZeQjjkBj5NrNpuWXKhBnMHO07tj8Ljh9ezwJp68%2FrdMwOXwlyxv%2FCsor6rZO6PtX0JizkN%2BIutB1kmaCnxK41FdRclFWEJWGPpGVgSjIWYp74bfHs1Avf0G8kNsPM%2FkyehIPwIaS7Xbeyie5qenfFAFWw9YQHNvM9WX9%2B5xhqtPQcYUOg4Wr1G%2BSlsItcEazxmHQERvNuLUOU2VigrvcEKNBnbZH7JoRVQTtPRgFECzfQQkPOi%2FU9GsAYpQu%2FqGVHwAPJLNVoBfnEe1Mg%2BKrAu0%2FL35OIS2fP46u75gCXLw1%2FBhzOm1umBlzFDUAsZQ3J5DR9mShhvHig%2BB8TCdMVjylaS%2Fh6hUCeP0%2FXvKRYuD4aW3J1m1EimyJzBy8Qi7C1hXgkepa9cNDShV%2BTF9phMWeVFY8SfA9X90jHF%2FSYMb%2BnMPLpgp4GOqQBZ5znXhjTPM14j53IobZ%2B4b3VHMs5dZZE%2Ff5Ha5ZX6k%2Bt%2FW9M5wu0Iwos9%2FYUlDqOF8HiPvdWiTlcdlpqih8EsQ56lZqwBjrKGBQxLiqefBfIER6HrpvBaW68hnEfCR9WZiFMWN3NYhz4uOL2RzYDHnSpOls%2BfqmKpmC98xTBrlXelX2208ubwFTa1YEHrCsP%2F9mLMQ%2FcEv9Uu49DULY9bhF%2FKtA%3D&X-Amz-Signature=a6d4d1695ca3a2a24bb46680c33391578ab52e4e1761f1392176664de60fbe31&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22boundhingbox-mite_20230113150917.zip%22\"\n",
        "shutil.unpack_archive('/content/fastlabel.zip', '/content')\n",
        "shutil.unpack_archive('/content/fastlabel2.zip', '/content')\n",
        "\n",
        "os.rename('/content/originals', '/content/originals_test')\n",
        "\n",
        "if os.path.exists('/content/mask_direct_color'):\n",
        "  shutil.move('/content/mask_direct_color/instance_segmentations','/content/instance_segmentations')\n",
        "  shutil.rmtree('/content/mask_direct_color')\n",
        "  shutil.move('/content/yolo/annotations','/content/annotations')\n",
        "\n",
        "if os.path.exists('/content/csv'):\n",
        "  shutil.rmtree('/content/csv')\n",
        "if os.path.exists('/content/yolo'):\n",
        "  shutil.rmtree('/content/yolo')\n",
        "\n",
        "os.remove('/content/fastlabel.zip')\n",
        "os.remove('/content/fastlabel2.zip')  "
      ],
      "metadata": {
        "id": "ONDQAagBUD4E",
        "outputId": "650271e3-847c-45c5-ff55-6137d6c4acb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-13 06:15:21--  https://s3.ap-northeast-1.amazonaws.com/prod.fastlabel.app.exports/3efde406-abc7-4f3e-a3bd-905d3535a34d/96859d83-8473-4dec-8b0f-ff750a7f1851/exports/20230113150917.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAYVHKCFVVOVWEOTNI%2F20230113%2Fap-northeast-1%2Fs3%2Faws4_request&X-Amz-Date=20230113T061015Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHEaDmFwLW5vcnRoZWFzdC0xIkgwRgIhALHx2TDj7s1ECDyQPtvm6liXBXet9mp3jz4gh9rGcjSUAiEAw0WTLnEUaQVUjUXMsCBgDIfRt9Ao5dLk1F%2BKgfExC9UqhQQIy%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw1OTUzNDM4NDY3NjIiDLUMScrsZpF11pJXsSrZA4v9o4P%2BRLfUTW%2BuJodCuILzkBb00j7BwEj%2FjIvgeeT3mIdTrmSOuz4Q1ewp4WPV%2F5GChfZzqxImCEJ7A6RN4XrXhTRf3NyK0JCnOHoYyTUC490gGM5R2X9gYQsDVwG7Sn9%2Bn%2FHXwTrxTDDCPLOGhwriddLUQgiJqQ9XBW6osPsM9ccqB56Eu0enGZa7A6akLIEBKcIRSRJZeQjjkBj5NrNpuWXKhBnMHO07tj8Ljh9ezwJp68%2FrdMwOXwlyxv%2FCsor6rZO6PtX0JizkN%2BIutB1kmaCnxK41FdRclFWEJWGPpGVgSjIWYp74bfHs1Avf0G8kNsPM%2FkyehIPwIaS7Xbeyie5qenfFAFWw9YQHNvM9WX9%2B5xhqtPQcYUOg4Wr1G%2BSlsItcEazxmHQERvNuLUOU2VigrvcEKNBnbZH7JoRVQTtPRgFECzfQQkPOi%2FU9GsAYpQu%2FqGVHwAPJLNVoBfnEe1Mg%2BKrAu0%2FL35OIS2fP46u75gCXLw1%2FBhzOm1umBlzFDUAsZQ3J5DR9mShhvHig%2BB8TCdMVjylaS%2Fh6hUCeP0%2FXvKRYuD4aW3J1m1EimyJzBy8Qi7C1hXgkepa9cNDShV%2BTF9phMWeVFY8SfA9X90jHF%2FSYMb%2BnMPLpgp4GOqQBZ5znXhjTPM14j53IobZ%2B4b3VHMs5dZZE%2Ff5Ha5ZX6k%2Bt%2FW9M5wu0Iwos9%2FYUlDqOF8HiPvdWiTlcdlpqih8EsQ56lZqwBjrKGBQxLiqefBfIER6HrpvBaW68hnEfCR9WZiFMWN3NYhz4uOL2RzYDHnSpOls%2BfqmKpmC98xTBrlXelX2208ubwFTa1YEHrCsP%2F9mLMQ%2FcEv9Uu49DULY9bhF%2FKtA%3D&X-Amz-Signature=a6d4d1695ca3a2a24bb46680c33391578ab52e4e1761f1392176664de60fbe31&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22boundhingbox-mite_20230113150917.zip%22\n",
            "Resolving s3.ap-northeast-1.amazonaws.com (s3.ap-northeast-1.amazonaws.com)... 52.219.8.200, 52.219.1.78, 52.219.197.4, ...\n",
            "Connecting to s3.ap-northeast-1.amazonaws.com (s3.ap-northeast-1.amazonaws.com)|52.219.8.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32384936 (31M) [binary/octet-stream]\n",
            "Saving to: ‘/content/fastlabel.zip’\n",
            "\n",
            "/content/fastlabel. 100%[===================>]  30.88M  25.7MB/s    in 1.2s    \n",
            "\n",
            "2023-01-13 06:15:22 (25.7 MB/s) - ‘/content/fastlabel.zip’ saved [32384936/32384936]\n",
            "\n",
            "--2023-01-13 06:15:22--  https://s3.ap-northeast-1.amazonaws.com/prod.fastlabel.app.exports/3efde406-abc7-4f3e-a3bd-905d3535a34d/96859d83-8473-4dec-8b0f-ff750a7f1851/exports/20230113150917.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAYVHKCFVVOVWEOTNI%2F20230113%2Fap-northeast-1%2Fs3%2Faws4_request&X-Amz-Date=20230113T061015Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHEaDmFwLW5vcnRoZWFzdC0xIkgwRgIhALHx2TDj7s1ECDyQPtvm6liXBXet9mp3jz4gh9rGcjSUAiEAw0WTLnEUaQVUjUXMsCBgDIfRt9Ao5dLk1F%2BKgfExC9UqhQQIy%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw1OTUzNDM4NDY3NjIiDLUMScrsZpF11pJXsSrZA4v9o4P%2BRLfUTW%2BuJodCuILzkBb00j7BwEj%2FjIvgeeT3mIdTrmSOuz4Q1ewp4WPV%2F5GChfZzqxImCEJ7A6RN4XrXhTRf3NyK0JCnOHoYyTUC490gGM5R2X9gYQsDVwG7Sn9%2Bn%2FHXwTrxTDDCPLOGhwriddLUQgiJqQ9XBW6osPsM9ccqB56Eu0enGZa7A6akLIEBKcIRSRJZeQjjkBj5NrNpuWXKhBnMHO07tj8Ljh9ezwJp68%2FrdMwOXwlyxv%2FCsor6rZO6PtX0JizkN%2BIutB1kmaCnxK41FdRclFWEJWGPpGVgSjIWYp74bfHs1Avf0G8kNsPM%2FkyehIPwIaS7Xbeyie5qenfFAFWw9YQHNvM9WX9%2B5xhqtPQcYUOg4Wr1G%2BSlsItcEazxmHQERvNuLUOU2VigrvcEKNBnbZH7JoRVQTtPRgFECzfQQkPOi%2FU9GsAYpQu%2FqGVHwAPJLNVoBfnEe1Mg%2BKrAu0%2FL35OIS2fP46u75gCXLw1%2FBhzOm1umBlzFDUAsZQ3J5DR9mShhvHig%2BB8TCdMVjylaS%2Fh6hUCeP0%2FXvKRYuD4aW3J1m1EimyJzBy8Qi7C1hXgkepa9cNDShV%2BTF9phMWeVFY8SfA9X90jHF%2FSYMb%2BnMPLpgp4GOqQBZ5znXhjTPM14j53IobZ%2B4b3VHMs5dZZE%2Ff5Ha5ZX6k%2Bt%2FW9M5wu0Iwos9%2FYUlDqOF8HiPvdWiTlcdlpqih8EsQ56lZqwBjrKGBQxLiqefBfIER6HrpvBaW68hnEfCR9WZiFMWN3NYhz4uOL2RzYDHnSpOls%2BfqmKpmC98xTBrlXelX2208ubwFTa1YEHrCsP%2F9mLMQ%2FcEv9Uu49DULY9bhF%2FKtA%3D&X-Amz-Signature=a6d4d1695ca3a2a24bb46680c33391578ab52e4e1761f1392176664de60fbe31&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22boundhingbox-mite_20230113150917.zip%22\n",
            "Resolving s3.ap-northeast-1.amazonaws.com (s3.ap-northeast-1.amazonaws.com)... 52.219.8.200, 52.219.1.78, 52.219.197.4, ...\n",
            "Connecting to s3.ap-northeast-1.amazonaws.com (s3.ap-northeast-1.amazonaws.com)|52.219.8.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32384936 (31M) [binary/octet-stream]\n",
            "Saving to: ‘/content/fastlabel2.zip’\n",
            "\n",
            "/content/fastlabel2 100%[===================>]  30.88M  24.3MB/s    in 1.3s    \n",
            "\n",
            "2023-01-13 06:15:24 (24.3 MB/s) - ‘/content/fastlabel2.zip’ saved [32384936/32384936]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##★背景処理（やる）"
      ],
      "metadata": {
        "id": "nxHWmDL6Y0Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install rembg\n",
        "exit()\n",
        "from rembg import remove"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5qRejbZY7Y8",
        "outputId": "6f3c03dd-5881-4c3c-d2ce-50123c0c951d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 KB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/originals/'):\n",
        "  shutil.copytree('/content/originals_test/','/content/originals/')\n",
        "  shutil.rmtree('/content/originals_test/')\n",
        "  os.mkdir('/content/originals_test/')\n",
        "\n",
        "\n",
        "read_folda_name='/content/originals/'\n",
        "read_folda = os.listdir(read_folda_name)\n",
        "\n",
        "for imgname in read_folda:\n",
        "  input = cv2.imread('/content/originals/'+imgname)\n",
        "  output = remove(input)\n",
        "  cv2.imwrite('/content/originals_test/'+imgname, output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkJxwnZ_ZcZ-",
        "outputId": "5fe6f6cd-3648-4d20-9c8a-402defbcfc48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/root/.u2net/u2net.onnx'.\n",
            "100%|████████████████████████████████████████| 176M/176M [00:00<00:00, 134GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##画像分割"
      ],
      "metadata": {
        "id": "sVWRvD5CGquV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#画像分割数\n",
        "split_x=20\n",
        "split_y=20\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "if not os.path.exists('/content/originals_test'):\n",
        "  shutil.unpack_archive('/content/originals_test.zip', '/content')\n",
        "\n",
        "#'NoneType' object is not subscriptableといわれるので先にipynb_checkpointsを消す\n",
        "#!rm -rf `find -type d -name .ipynb_checkpoints`\n",
        "\n",
        "#画像の読み込み\n",
        "read_files_name='/content/originals_test/'\n",
        "read_files = os.listdir(read_files_name)\n",
        "\n",
        "for file_name in read_files:\n",
        "  fname = read_files_name+file_name #画像ファイル名\n",
        "  foldaname=fname[9:]\n",
        "\n",
        "\n",
        "  #img = np.array(Image.open(fname))  \n",
        "  img=cv2.imread(fname,cv2.IMREAD_COLOR)\n",
        "  #画像分割先のフォルダを作成\n",
        "  if not os.path.exists('/content/split_pic_original/'+file_name[:-4]):\n",
        "    os.makedirs('/content/split_pic_original/'+file_name[:-4])\n",
        "\n",
        "\n",
        "  #画像の読み込み\n",
        "  h,w=img.shape[:2]\n",
        "\n",
        "  #画像の分割処理\n",
        "  cx=0\n",
        "  cy=0\n",
        "  for j in range(split_x):\n",
        "      for i in range(split_y):\n",
        "          split_pic=img[cy:cy+int(h/split_y),cx:cx+int(w/split_x),:]          \n",
        "          cv2.imwrite(\"/content/split_pic_original/\"+file_name[:-4]+\"/\"+file_name[:-4]+'_y'+str('{0:02d}'.format(int(i)))+'_x'+str('{0:02d}'.format(int(j)))+foldaname[-4:],split_pic)\n",
        "          cy=cy+int(h/split_y)\n",
        "      cy=0\n",
        "      cx=cx+int(w/split_x)\n",
        "\n",
        "  #分割する線を描いた画像を出力\n",
        "  y_step=int(h/split_y) #縦の分割間隔\n",
        "  x_step=int(w/split_x) #横の分割間隔\n",
        "\n",
        "  #オブジェクトimgのshapeメソッドの1つ目の戻り値(画像の高さ)をimg_yに、2つ目の戻り値(画像の幅)をimg_xに\n",
        "  #img_y,img_x=img.size\n",
        "  img_y,img_x=img.shape[:2]  \n",
        "\n",
        "  #横線を引く：y_stepからimg_yの手前までy_stepおきに白い(BGRすべて255)横線を引く\n",
        "  img[y_step:img_y:y_step, :, :] = 0\n",
        "  #縦線を引く：x_stepからimg_xの手前までx_stepおきに白い(BGRすべて255)縦線を引く\n",
        "  img[:, x_step:img_x:x_step, :] = 0\n",
        "\n",
        "  cv2.imwrite(\"/content/split_pic_original/\"+file_name[:-4]+\"grid\"+foldaname[-4:],img) #ファイル名'grid.png'でimgを保存\n",
        "#★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "import glob\n",
        "if not os.path.exists('/content/originals_grid/'):\n",
        "    os.makedirs('/content/originals_grid/')\n",
        "\n",
        "originals=('/content/split_pic_original/*.jpg')\n",
        "read_files = glob.glob(originals)\n",
        "\n",
        "for i in read_files:\n",
        "  shutil.copy(i, '/content/originals_grid/')\n",
        "#★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "#画像サイズを640にアップサンプリング\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/originals_upsamples/'):\n",
        "  os.makedirs('/content/originals_upsamples/')\n",
        "\n",
        "read_folda_name='/content/split_pic_original/'\n",
        "read_folda = os.listdir(read_folda_name)\n",
        "\n",
        "for image_folda_name in read_folda:\n",
        "  originals=('/content/split_pic_original/'+image_folda_name+'/*')\n",
        "  read_files = glob.glob(originals)\n",
        "\n",
        "  for imgpass in read_files:\n",
        "    # 読み込む画像を選択\n",
        "    img = cv2.imread(imgpass)\n",
        "    h,w=img.shape[:2]\n",
        "    # サイズ設定｜cv2では(幅、高さ）の順で数値を設定\n",
        "    size = (w*5,h*5) \n",
        "    # 画像拡大・縮小 オプションで拡大計算式変更可能\n",
        "    img_inter_area  = cv2.resize(img,size,interpolation = cv2.INTER_LINEAR) \n",
        "    #保存\n",
        "    cv2.imwrite('/content/originals_upsamples/'+os.path.split(imgpass)[1], img_inter_area)"
      ],
      "metadata": {
        "id": "MiIFeBJGEuGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##黒いだけのところを検出外にする"
      ],
      "metadata": {
        "id": "cWItPFPkybEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "read_folda_name='/content/originals_upsamples/'\n",
        "read_folda = os.listdir(read_folda_name)\n",
        "\n",
        "\n",
        "if not os.path.exists('/content/originals_upsamples_creard/'):\n",
        "  os.makedirs('/content/originals_upsamples_creard/')\n",
        "\n",
        "for i in read_folda:\n",
        "  # 対象画像読み込み\n",
        "  im = cv2.imread('/content/originals_upsamples/'+i,cv2.IMREAD_COLOR)\n",
        "\n",
        "\n",
        "  # RGB平均値を出力\n",
        "  # flattenで一次元化しmeanで平均を取得\n",
        "  b = im.T[0].flatten().mean()\n",
        "  g = im.T[1].flatten().mean()\n",
        "  r = im.T[2].flatten().mean()\n",
        "  average=b+r+g\n",
        "\n",
        "  # RGB平均値を取得\n",
        "  if average>0:\n",
        "    shutil.copy('/content/originals_upsamples/'+i,'/content/originals_upsamples_creard/'+i)"
      ],
      "metadata": {
        "id": "nXxeH8vh0l1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##検出"
      ],
      "metadata": {
        "id": "14TlhQgHM24p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#最適confは0.42\n",
        "if os.path.exists('/content/detect_output'):\n",
        "  shutil.rmtree('/content/detect_output')\n",
        "\n",
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "!python detect.py \\\n",
        "  --weights /content/drive/MyDrive/weights_box/best.pt \\\n",
        "  --conf 0.42 \\\n",
        "  --source '/content/originals_upsamples_creard/' \\\n",
        "  --name '/content/detect_output' \\\n",
        "  --save-txt \\\n",
        "  --save-conf"
      ],
      "metadata": {
        "id": "v9jTrC7HmFii",
        "outputId": "7f59acff-af6f-41c8-fd6b-a97793183bfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov7\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.42, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='/content/detect_output', no_trace=False, nosave=False, project='runs/detect', save_conf=True, save_txt=True, source='/content/originals_upsamples_creard/', update=False, view_img=False, weights=['/content/drive/MyDrive/weights_box/best.pt'])\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Done. (20.311s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##画像にアノテーションを描画"
      ],
      "metadata": {
        "id": "pVB9DbPqwiu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "if os.path.exists('/content/originals_test_annotations/'):\n",
        "  shutil.rmtree('/content/originals_test_annotations/')\n",
        "if os.path.exists('/content/originals_test_annotations_yolotype/'):\n",
        "  shutil.rmtree('/content/originals_test_annotations_yolotype/')\n",
        "\n",
        "yolo_pass=\"/content/originals_test_annotations/\"\n",
        "if not os.path.exists(yolo_pass):\n",
        "    os.mkdir(yolo_pass)\n",
        "\n",
        "yolo_pass_yolotype=\"/content/originals_test_annotations_yolotype/\"\n",
        "if not os.path.exists(yolo_pass_yolotype):\n",
        "    os.mkdir(yolo_pass_yolotype)\n",
        "\n",
        "read_files_name_bbox='/content/detect_output/labels/*'\n",
        "read_files_bbox = glob.glob(read_files_name_bbox)\n",
        "\n",
        "\n",
        "for txt_name in read_files_bbox:\n",
        "  txt_file = pd.read_csv(txt_name,header=None, sep=\" \")\n",
        "  for i in range(len(txt_file[0])):\n",
        "    im = Image.open('/content/detect_output/'+txt_name[30:-4]+\".jpg\")\n",
        "    im_original = Image.open('/content/originals_test/'+txt_name[30:-12]+\".jpg\")\n",
        "    image_width,image_height=np.array(im).shape[:2]\n",
        "    image_width_original,image_height_original=np.array(im_original).shape[:2]\n",
        "    name=txt_name[30:]\n",
        "    y_number=int(txt_name[-10:-8])\n",
        "    x_number=int(txt_name[-6:-4])\n",
        "\n",
        "    x_center=float(txt_file[1][i])*image_height\n",
        "    y_center=float(txt_file[2][i])*image_width\n",
        "    width=float(txt_file[3][i])*image_height\n",
        "    height=float(txt_file[4][i])*image_width\n",
        "\n",
        "    x1=(x_center-height/2)\n",
        "    y1=(y_center-width/2)\n",
        "    x2=(x_center+height/2)\n",
        "    y2=(y_center+width/2)\n",
        "    #x1=(x_center-width/2)\n",
        "    #y1=(y_center-height/2)\n",
        "    #x2=(x_center+width/2)\n",
        "    #y2=(y_center+height/2)\n",
        "\n",
        "    x_min_original=x1+image_height*x_number\n",
        "    y_min_original=y1+image_width*y_number\n",
        "    x_max_original=x2+image_height*x_number\n",
        "    y_max_original=y2+image_width*y_number\n",
        "\n",
        "\n",
        "    absolute_x_original=x_min_original+(x_max_original-x_min_original)/2\n",
        "    absolute_y_original=y_min_original+(y_max_original-y_min_original)/2\n",
        "    absolute_width_original=x_max_original-x_min_original\n",
        "    absolute_height_original=y_max_original-y_min_original\n",
        "\n",
        "    col1=\"0\"\n",
        "    col2=str(absolute_x_original / (image_height_original*5))\n",
        "    col3=str(absolute_y_original / (image_width_original*5))\n",
        "    col4=str(absolute_height_original / (image_height_original*5))\n",
        "    col5=str(absolute_width_original / (image_width_original*5))\n",
        "\n",
        "\n",
        "    col6=str(txt_file[5][i])\n",
        "    col7=str(txt_name[30:-4])\n",
        "\n",
        "    with open(yolo_pass+txt_name[30:-12]+'.txt', 'a') as f:\n",
        "        rote=col1+' '+col2+' '+col3+' '+col4+' '+col5+' '+col6+' '+col7+'\\n'\n",
        "        f.write(rote)\n",
        "    with open(yolo_pass_yolotype+txt_name[30:-12]+'.txt', 'a') as f:\n",
        "        rote=col1+' '+col2+' '+col3+' '+col4+' '+col5+'\\n'\n",
        "        f.write(rote)\n",
        "#★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "folda_pass=\"/content/originals_test_annotations_drawing\"\n",
        "if not os.path.exists(folda_pass):\n",
        "    os.mkdir(folda_pass)\n",
        "\n",
        "read_files_name_bbox='/content/originals_test_annotations/*'\n",
        "read_files_bbox = glob.glob(read_files_name_bbox)\n",
        "\n",
        "for txt_name in read_files_bbox:\n",
        "  im_original = Image.open('/content/originals_test/'+txt_name[36:-4]+\".jpg\")\n",
        "  image_width,image_height=np.array(im_original).shape[:2]\n",
        "\n",
        "  txt_file = pd.read_csv('/content/originals_test_annotations/'+txt_name[36:-4]+\".txt\",header=None, sep=\" \")\n",
        "  for annotation in range(len(txt_file)):\n",
        "\n",
        "    x_center=float(txt_file[1][annotation])*image_height\n",
        "    y_center=float(txt_file[2][annotation])*image_width\n",
        "    width=float(txt_file[3][annotation])*image_height\n",
        "    height=float(txt_file[4][annotation])*image_width\n",
        "    #width=float(txt_file[3][annotation])*image_width\n",
        "    #height=float(txt_file[4][annotation])*image_height\n",
        "\n",
        "    #x1=int(x_center-height/2)\n",
        "    #y1=int(y_center-width/2)\n",
        "    #x2=int(x_center+height/2)\n",
        "    #y2=int(y_center+width/2)\n",
        "    x1=(x_center-width/2)\n",
        "    y1=(y_center-height/2)\n",
        "    x2=(x_center+width/2)\n",
        "    y2=(y_center+height/2)\n",
        "\n",
        "    #print(txt_name[36:-4],x_center,y_center,txt_file[5][annotation])\n",
        "\n",
        "    draw = ImageDraw.Draw(im_original)\n",
        "    draw.rectangle((x1, y1, x2, y2), outline=(255, 0, 0), width=5)\n",
        "    im_original.save('/content/originals_test_annotations_drawing/'+txt_name[36:-4]+'.jpg')\n",
        "    #im_original = Image.open('/content/originals_test_annotations_drawing/'+txt_name[36:-4]+\".jpg\")\n",
        "#★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "#画像分割数\n",
        "split_x=20\n",
        "split_y=20\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "if not os.path.exists('/content/originals_test'):\n",
        "  shutil.unpack_archive('/content/originals_test.zip', '/content')\n",
        "\n",
        "#'NoneType' object is not subscriptableといわれるので先にipynb_checkpointsを消す\n",
        "#!rm -rf `find -type d -name .ipynb_checkpoints`\n",
        "\n",
        "#画像の読み込み\n",
        "read_files_name='/content/originals_test_annotations_drawing/'\n",
        "read_files = os.listdir(read_files_name)\n",
        "\n",
        "for file_name in read_files:\n",
        "  fname = read_files_name+file_name #画像ファイル名\n",
        "  foldaname=fname[9:]\n",
        "\n",
        "\n",
        "  #img = np.array(Image.open(fname))  \n",
        "  img=cv2.imread(fname,cv2.IMREAD_COLOR)\n",
        "  #画像分割先のフォルダを作成\n",
        "  #if not os.path.exists('/content/split_originals_test_annotations_drawing/'+file_name[:-4]):\n",
        "  #  os.makedirs('/content/split_originals_test_annotations_drawing/'+file_name[:-4])\n",
        "  if not os.path.exists('/content/split_originals_test_annotations_drawing/'):\n",
        "    os.makedirs('/content/split_originals_test_annotations_drawing/')\n",
        "\n",
        "\n",
        "  #画像の読み込み\n",
        "  h,w=img.shape[:2]\n",
        "\n",
        "  #画像の分割処理\n",
        "  cx=0\n",
        "  cy=0\n",
        "  for j in range(split_x):\n",
        "      for i in range(split_y):\n",
        "          split_pic=img[cy:cy+int(h/split_y),cx:cx+int(w/split_x),:]          \n",
        "          #cv2.imwrite(\"/content/split_originals_test_annotations_drawing/\"+file_name[:-4]+\"/\"+file_name[:-4]+'_y'+str('{0:02d}'.format(int(i)))+'_x'+str('{0:02d}'.format(int(j)))+foldaname[-4:],split_pic)\n",
        "          cy=cy+int(h/split_y)\n",
        "      cy=0\n",
        "      cx=cx+int(w/split_x)\n",
        "\n",
        "  #分割する線を描いた画像を出力\n",
        "  y_step=int(h/split_y) #縦の分割間隔\n",
        "  x_step=int(w/split_x) #横の分割間隔\n",
        "\n",
        "  #オブジェクトimgのshapeメソッドの1つ目の戻り値(画像の高さ)をimg_yに、2つ目の戻り値(画像の幅)をimg_xに\n",
        "  #img_y,img_x=img.size\n",
        "  img_y,img_x=img.shape[:2]  \n",
        "\n",
        "  #横線を引く：y_stepからimg_yの手前までy_stepおきに白い(BGRすべて255)横線を引く\n",
        "  img[y_step:img_y:y_step, :, :] = 0\n",
        "  #縦線を引く：x_stepからimg_xの手前までx_stepおきに白い(BGRすべて255)縦線を引く\n",
        "  img[:, x_step:img_x:x_step, :] = 0\n",
        "\n",
        "  cv2.imwrite(\"/content/split_originals_test_annotations_drawing/\"+file_name[:-4]+\"grid\"+foldaname[-4:],img) #ファイル名'grid.png'でimgを保存"
      ],
      "metadata": {
        "id": "FRURI8e1wpYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##vgg16で補正をかける（やらない）"
      ],
      "metadata": {
        "id": "tHWwymCe6jpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "%cd -q '/content/'\n",
        "# Download trained weights\n",
        "!wget -q https://github.com/1900690/koukai/releases/download/mite_demo/mite_detect_4.zip\n",
        "shutil.unpack_archive('/content/mite_detect_4.zip', '/content')\n",
        "os.remove('/content/mite_detect_4.zip')\n",
        "#★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "#tf用事前準備\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "TF_MODEL_FILE_PATH = '/content/model_3class_4000.tflite' # The default path to the saved TensorFlow Lite model\n",
        "interpreter = tf.lite.Interpreter(model_path=TF_MODEL_FILE_PATH)\n",
        "classify_lite = interpreter.get_signature_runner('serving_default')\n",
        "\n",
        "#class_names =['devidedmite', 'mite', 'notmite']\n",
        "class_names =['2', '1', '0']\n",
        "\n",
        "def rot_cut(src_img, deg, center, size):\n",
        "    rot_mat = cv2.getRotationMatrix2D(center, deg, 1.0)\n",
        "    rot_mat[0][2] += -center[0]+size[0]/2 # -(元画像内での中心位置)+(切り抜きたいサイズの中心)\n",
        "    rot_mat[1][2] += -center[1]+size[1]/2 # 同上\n",
        "    return cv2.warpAffine(src_img, rot_mat, size)\n",
        "\n",
        "\n",
        "def pil2cv(image):\n",
        "    ''' PIL型 -> OpenCV型 '''\n",
        "    new_image = np.array(image, dtype=np.uint8)\n",
        "    if new_image.ndim == 2: # モノクロ\n",
        "        pass\n",
        "    elif new_image.shape[2] == 3: # カラー\n",
        "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGB2BGR)\n",
        "    elif new_image.shape[2] == 4: # 透過\n",
        "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGBA2BGRA)\n",
        "    return new_image"
      ],
      "metadata": {
        "id": "uk-K82On7H4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#座標データを置き換えるので保存用にディレクトリを分ける\n",
        "if not os.path.exists('/content/originals_test_annotations_drawing_yolotype'):\n",
        " shutil.copytree('/content/originals_test_annotations_yolotype','/content/originals_test_annotations_drawing_yolotype')\n",
        "shutil.rmtree('/content/originals_test_annotations_yolotype')\n",
        "os.makedirs('/content/originals_test_annotations_yolotype')\n",
        "\n",
        "#検出した全データ\n",
        "read_files_name_bbox='/content/originals_test_annotations_drawing_yolotype/*'\n",
        "read_files_bbox = glob.glob(read_files_name_bbox)\n",
        "\n",
        "for txt_name in read_files_bbox:\n",
        "  txt_file=pd.read_csv(txt_name,header=None, sep=\" \")\n",
        "  for i in range(len(txt_file[0])):\n",
        "    im_original = Image.open('/content/originals_test/'+txt_name[53:-4]+\".jpg\")\n",
        "    image_width,image_height=np.array(im_original).shape[:2]\n",
        "    x_center=float(txt_file[1][i])*image_height\n",
        "    y_center=float(txt_file[2][i])*image_width\n",
        "    #tfliteで判定★★★★★★★★★★★★★★★★★★★★\n",
        "    cutimage_original=rot_cut(pil2cv(im_original), 0,(int(x_center),int(y_center)), (192,192))\n",
        "    img_array = tf.expand_dims(tf.keras.utils.img_to_array(cutimage_original), 0) # Create a batch\n",
        "    predictions_lite = classify_lite(input_1=img_array)['sequential']#判定\n",
        "    score_lite = tf.nn.softmax(predictions_lite)#スコアを抽出\n",
        "    confidence=np.amax(score_lite)#confidence\n",
        "    tf_score=class_names[np.argmax(score_lite)]          \n",
        "    #★★★★★★★★★★★★★★★★★★★★\n",
        "    if int(tf_score) >0:\n",
        "      with open('/content/originals_test_annotations_yolotype/'+txt_name[53:-4]+'.txt', 'a') as f:      \n",
        "        rote=str(txt_file[0][i])+','+str(txt_file[1][i])+','+str(txt_file[2][i])+','+str(txt_file[3][i])+','+str(txt_file[4][i])+'\\n'\n",
        "        f.write(rote)  \n"
      ],
      "metadata": {
        "id": "ErxBYv6x7mZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##元画像とＹＯＬＯ座標データをエクスポート"
      ],
      "metadata": {
        "id": "ugH5xFlJnx2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "with open('/content/classes.txt', 'w') as f:\n",
        "  rote='mite'\n",
        "  f.write(rote)\n",
        "\n",
        "if not os.path.exists('/content/yolo_format/'):\n",
        "  os.makedirs('/content/yolo_format/')\n",
        "  shutil.move('/content/classes.txt','/content/yolo_format/')\n",
        "  shutil.copytree('/content/originals_test_annotations_yolotype','/content/yolo_format/annotations')\n",
        "\n",
        "shutil.make_archive('/content/yolo_format', format='zip', root_dir='/content/yolo_format')\n",
        "files.download('/content/yolo_format.zip')\n",
        "\n",
        "shutil.make_archive('/content/originals', format='zip', root_dir='/content/originals')\n",
        "files.download('/content/originals.zip')"
      ],
      "metadata": {
        "id": "NJgDchlHoCEe",
        "outputId": "83b3cc6b-0666-43b3-81a7-5caf9dc7ca02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2cea756f-bffc-4a3c-93fe-713cf30e0b9b\", \"yolo_format.zip\", 939)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1059a0bc-e6a9-4ce0-b81f-515c7391ff48\", \"originals.zip\", 9478713)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##マスクとannotationデータをアップロード"
      ],
      "metadata": {
        "id": "NTK0felyvIRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "正解のマスク画像をアップロード"
      ],
      "metadata": {
        "id": "L-1icGvvxS3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('/content/instance_segmentations'):\n",
        "    os.makedirs('/content/instance_segmentations')\n",
        "\n",
        "%cd '/content/instance_segmentations'\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "-Kl3tUr0xbC4",
        "outputId": "a82ce006-b409-4f97-f2c4-291e0efc3b33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/instance_segmentations\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ca744fe1-0b70-4915-91e5-1ef676aa22a3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ca744fe1-0b70-4915-91e5-1ef676aa22a3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IMG_20220310_111421_180.png to IMG_20220310_111421_180.png\n",
            "Saving IMG_20220310_111443_180.png to IMG_20220310_111443_180.png\n",
            "Saving IMG_20220310_111515_180.png to IMG_20220310_111515_180.png\n",
            "Saving IMG_20220310_111535_180.png to IMG_20220310_111535_180.png\n",
            "Saving IMG_20220310_111711_180.png to IMG_20220310_111711_180.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "正解のYOLO座標をアップロード"
      ],
      "metadata": {
        "id": "XYDrtkeAFuh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('/content/annotations'):\n",
        "    os.makedirs('/content/annotations')\n",
        "\n",
        "%cd '/content/annotations'\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "CiUG8-LIVeCr",
        "outputId": "350940f2-0e13-4a5d-f58f-6cf6a5826c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/annotations\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-499c3590-4b5f-45de-8403-4117a77cdf61\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-499c3590-4b5f-45de-8403-4117a77cdf61\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IMG_20220310_111421_180.txt to IMG_20220310_111421_180.txt\n",
            "Saving IMG_20220310_111443_180.txt to IMG_20220310_111443_180.txt\n",
            "Saving IMG_20220310_111515_180.txt to IMG_20220310_111515_180.txt\n",
            "Saving IMG_20220310_111535_180.txt to IMG_20220310_111535_180.txt\n",
            "Saving IMG_20220310_111711_180.txt to IMG_20220310_111711_180.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##正解を赤、見逃しを白、重複を青、誤認識を紫で描写"
      ],
      "metadata": {
        "id": "9iJ88fsf2q0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw\n",
        "\n",
        "#画像の読み込み\n",
        "read_files_name_bbox='/content/instance_segmentations/*'\n",
        "read_files_bbox = glob.glob(read_files_name_bbox)\n",
        "detect_positive=0\n",
        "\n",
        "if os.path.exists('/content/acctuary_count.txt'):\n",
        "  os.remove('/content/acctuary_count.txt')\n",
        "\n",
        "if os.path.exists('/content/answer_count.txt'):\n",
        "  os.remove('/content/answer_count.txt')\n",
        "\n",
        "if not os.path.exists('/content/instance_segmentations_index_coler/'):\n",
        "  os.makedirs('/content/instance_segmentations_index_coler/')\n",
        "\n",
        "for txt_name in read_files_bbox:\n",
        "  \n",
        "  img = np.array(Image.open('/content/originals_test/'+txt_name[32:-4]+\".jpg\"))\n",
        "  img_drawing = Image.open('/content/originals_grid/'+txt_name[32:-4]+\"grid.jpg\")\n",
        "  img_true = np.array(Image.open(txt_name))#ダイレクトカラー\n",
        "\n",
        "  #numpyからpilへ変換\n",
        "  im = Image.fromarray(img_true)\n",
        "  #ダイレクトカラーからインデックスカラーへ\n",
        "  c = im.getcolors(im.width * im.height)\n",
        "  h,w=np.array(im).shape[:2]\n",
        "  indexcoler=np.zeros((h,w))\n",
        "  for coler in range(len(c)):\n",
        "    split=np.zeros((h,w,3))\n",
        "    split[:,:,0]=np.full((h, w), c[coler][1][0])\n",
        "    split[:,:,1]=np.full((h, w), c[coler][1][1])\n",
        "    split[:,:,2]=np.full((h, w), c[coler][1][2])\n",
        "    truefalse=np.equal(split,im)\n",
        "    zeroone = np.where(truefalse == True, 1, 0)\n",
        "    after=zeroone[:,:,0]+zeroone[:,:,1]+zeroone[:,:,2]\n",
        "    split_after = np.where(after == 3, coler, 0)\n",
        "    indexcoler=indexcoler+split_after\n",
        "  #pilからnumpyへ変換\n",
        "  img_true = np.array(indexcoler)\n",
        "  \n",
        "  #最大の面積を０にする\n",
        "  #0を定義するため+1\n",
        "  img_true=img_true+1\n",
        "  #最大の面積に格納されている値を出す\n",
        "  max_area=Image.fromarray(img_true).getcolors(Image.fromarray(img_true).width * Image.fromarray(img_true).height)\n",
        "  max_number=np.sort(max_area,axis=0)[::-1][0][1]\n",
        "  #最大の面積の値を０に置き換え\n",
        "  img_true = np.where(img_true == max_number, 0, img_true)\n",
        "\n",
        "  cv2.imwrite(\"/content/instance_segmentations_index_coler/\"+txt_name[32:],img_true) #indexカラーで保存\n",
        "  #★\n",
        "  txt_file_detected = pd.read_csv('/content/originals_test_annotations_yolotype/'+txt_name[32:-4]+\".txt\",header=None, sep=\" \") \n",
        "  #txt_file_detected = pd.read_csv('/content/originals_test_annotations/'+txt_name[32:-4]+\".txt\",header=None, sep=\" \")\n",
        "  txt_file_answer = pd.read_csv('/content/annotations/'+txt_name[32:-4]+\".txt\",header=None, sep=\" \")\n",
        " \n",
        "  h,w=img.shape[:2]\n",
        "  #binary_img=np.zeros_like(img)\n",
        "\n",
        "  for i in range(len(txt_file_detected)):\n",
        "    x_center=float(txt_file_detected[1][i])*w\n",
        "    y_center=float(txt_file_detected[2][i])*h\n",
        "    width=float(txt_file_detected[3][i])*w\n",
        "    height=float(txt_file_detected[4][i])*h\n",
        "\n",
        "    #x1=int(x_center-height/2)\n",
        "    #y1=int(y_center-width/2)\n",
        "    #x2=int(x_center+height/2)\n",
        "    #y2=int(y_center+width/2)\n",
        "    x1=int(x_center-width/2)\n",
        "    y1=int(y_center-height/2)\n",
        "    x2=int(x_center+width/2)\n",
        "    y2=int(y_center+height/2)\n",
        "    \n",
        "    text=txt_name[32:-4],img_true[int(y_center),int(x_center)]\n",
        "    #print(text)\n",
        "    with open('/content/acctuary_count'+'.txt', 'a') as f:      \n",
        "        #rote=str(txt_name[32:-4])+','+str(img_true[int(y_center),int(x_center)][0])+str(img_true[int(y_center),int(x_center)][1])+str(img_true[int(y_center),int(x_center)][2])+','+str(x_center)+','+str(y_center)+'\\n'\n",
        "        rote=str(txt_name[32:-4])+','+str(img_true[int(y_center),int(x_center)])+','+str(int(x_center))+','+str(int(y_center))+','+str(int(x1))+','+str(int(y1))+','+str(int(x2))+','+str(int(y2))+','+str(txt_file_detected[1][i])+','+str(txt_file_detected[2][i])+','+str(txt_file_detected[3][i])+','+str(txt_file_detected[4][i])+'\\n'\n",
        "        f.write(rote)  \n",
        " \n",
        "  h,w=img.shape[:2]\n",
        "  #binary_img=np.zeros_like(img)\n",
        "\n",
        "  for i in range(len(txt_file_answer)):\n",
        "    x_center=float(txt_file_answer[1][i])*w\n",
        "    y_center=float(txt_file_answer[2][i])*h\n",
        "    width=float(txt_file_answer[3][i])*w\n",
        "    height=float(txt_file_answer[4][i])*h\n",
        "\n",
        "    #x1=int(x_center-height/2)\n",
        "    #y1=int(y_center-width/2)\n",
        "    #x2=int(x_center+height/2)\n",
        "    #y2=int(y_center+width/2)\n",
        "    x1=int(x_center-width/2)\n",
        "    y1=int(y_center-height/2)\n",
        "    x2=int(x_center+width/2)\n",
        "    y2=int(y_center+height/2)\n",
        "    \n",
        "    text=txt_name[32:-4],img_true[int(y_center),int(x_center)]\n",
        "    #print(text)\n",
        "    with open('/content/answer_count'+'.txt', 'a') as f:      \n",
        "        #rote=str(txt_name[32:-4])+','+str(img_true[int(y_center),int(x_center)][0])+str(img_true[int(y_center),int(x_center)][1])+str(img_true[int(y_center),int(x_center)][2])+','+str(x_center)+','+str(y_center)+'\\n'\n",
        "        rote=str(txt_name[32:-4])+','+str(img_true[int(y_center),int(x_center)])+','+str(int(x_center))+','+str(int(y_center))+','+str(int(x1))+','+str(int(y1))+','+str(int(x2))+','+str(int(y2))+','+str(txt_file_answer[1][i])+','+str(txt_file_answer[2][i])+','+str(txt_file_answer[3][i])+','+str(txt_file_answer[4][i])+'\\n'\n",
        "        f.write(rote)\n",
        "#★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "from PIL import Image, ImageDraw\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "if os.path.exists('/content/false_potision.txt'):\n",
        "  os.remove('/content/false_potision.txt')\n",
        "\n",
        "if os.path.exists('/content/split_originals_test_annotations_answer_drawing/'):\n",
        "  shutil.rmtree('/content/split_originals_test_annotations_answer_drawing/')\n",
        "\n",
        "shutil.copytree('/content/originals_grid','/content/split_originals_test_annotations_answer_drawing/')\n",
        "\n",
        "if not os.path.exists('/content/split_originals_test_annotations_answer_yolotype'):\n",
        "  os.makedirs('/content/split_originals_test_annotations_answer_yolotype')\n",
        "\n",
        "#正解の数\n",
        "answer_data=pd.read_csv('/content/answer_count.txt',header=None, sep=\",\")\n",
        "answer_data_ascending=answer_data.sort_values(by=[0,1])\n",
        "\n",
        "#検出した全データ\n",
        "all_data=pd.read_csv('/content/acctuary_count.txt',header=None, sep=\",\")\n",
        "all_data_ascending=all_data.sort_values(by=[0,1])\n",
        "\n",
        "for line_number in range(len(all_data_ascending)):\n",
        "  img_drawing = Image.open('/content/split_originals_test_annotations_answer_drawing/'+all_data_ascending.iloc[line_number][0]+\"grid.jpg\")\n",
        "  draw = ImageDraw.Draw(img_drawing)\n",
        "  #赤\n",
        "  draw.rectangle((all_data_ascending.iloc[line_number][4], all_data_ascending.iloc[line_number][5],all_data_ascending.iloc[line_number][6],all_data_ascending.iloc[line_number][7]),fill=(255,0,0), outline=(255,0,0), width=5)\n",
        "  img_drawing.save('/content/split_originals_test_annotations_answer_drawing/'+all_data_ascending.iloc[line_number][0]+'grid.jpg')\n",
        "\n",
        "#範囲外を検出\n",
        "false_potision_outofrange=all_data[all_data[1]==0]\n",
        "false_potision_outofrange_ascending=false_potision_outofrange.sort_values(by=[0,1])\n",
        "\n",
        "for line_number in range(len(false_potision_outofrange_ascending)):\n",
        "  img_drawing = Image.open('/content/split_originals_test_annotations_answer_drawing/'+false_potision_outofrange_ascending.iloc[line_number][0]+\"grid.jpg\")\n",
        "  draw = ImageDraw.Draw(img_drawing)\n",
        "  #紫\n",
        "  draw.rectangle((false_potision_outofrange_ascending.iloc[line_number][4], false_potision_outofrange_ascending.iloc[line_number][5],false_potision_outofrange_ascending.iloc[line_number][6],false_potision_outofrange_ascending.iloc[line_number][7]),fill=(255,0,255),outline=(255,0,255), width=5)\n",
        "  img_drawing.save('/content/split_originals_test_annotations_answer_drawing/'+false_potision_outofrange_ascending.iloc[line_number][0]+'grid.jpg')\n",
        "\n",
        "  with open('/content/split_originals_test_annotations_answer_yolotype/'+false_potision_outofrange_ascending.iloc[line_number][0]+'.txt', 'a') as f:\n",
        "    rote=str(1)+' '+str(false_potision_outofrange_ascending.iloc[line_number][8])+' '+str(false_potision_outofrange_ascending.iloc[line_number][9])+' '+str(false_potision_outofrange_ascending.iloc[line_number][10])+' '+str(false_potision_outofrange_ascending.iloc[line_number][11])+'\\n'\n",
        "    f.write(rote)\n",
        "\n",
        "#被りを検出\n",
        "false_potision=all_data[all_data.duplicated(subset=[0,1],keep=False)]\n",
        "false_potision_duplicated=false_potision[false_potision[1]!=0]\n",
        "false_potision_duplicated_ascending=false_potision_duplicated.sort_values(by=[0,1])\n",
        "false_potision_duplicated_ascending_half=false_potision_duplicated_ascending[false_potision_duplicated_ascending.duplicated(subset=[0,1])]\n",
        "\n",
        "for line_number in range(len(false_potision_duplicated_ascending)):\n",
        "  img_drawing = Image.open('/content/split_originals_test_annotations_answer_drawing/'+false_potision_duplicated_ascending.iloc[line_number][0]+\"grid.jpg\")\n",
        "  draw = ImageDraw.Draw(img_drawing)\n",
        "  #青\n",
        "  draw.rectangle((false_potision_duplicated_ascending.iloc[line_number][4], false_potision_duplicated_ascending.iloc[line_number][5],false_potision_duplicated_ascending.iloc[line_number][6],false_potision_duplicated_ascending.iloc[line_number][7]),fill=(0,0,255), outline=(0,0,255), width=5)\n",
        "  img_drawing.save('/content/split_originals_test_annotations_answer_drawing/'+false_potision_duplicated_ascending.iloc[line_number][0]+'grid.jpg')\n",
        "  \n",
        "  with open('/content/split_originals_test_annotations_answer_yolotype/'+false_potision_duplicated_ascending.iloc[line_number][0]+'.txt', 'a') as f:\n",
        "    rote=str(2)+' '+str(false_potision_duplicated_ascending.iloc[line_number][8])+' '+str(false_potision_duplicated_ascending.iloc[line_number][9])+' '+str(false_potision_duplicated_ascending.iloc[line_number][10])+' '+str(false_potision_duplicated_ascending.iloc[line_number][11])+'\\n'\n",
        "    f.write(rote)\n",
        "\n",
        "#見逃したダニの数\n",
        "false_potision_overlooked=pd.merge(all_data_ascending,answer_data_ascending, on=[0,1], how='outer', indicator=True)\n",
        "false_potision_overlooked_ascending = false_potision_overlooked[false_potision_overlooked['_merge'] == 'right_only'].iloc[:,[0,1,12,13,14,15,16,17,18,19,20,21]]\n",
        "false_potision_overlooked_ascending=false_potision_overlooked_ascending.rename(columns={'2_y': 2,'3_y': 3,'4_y': 4,'5_y': 5,'6_y': 6,'7_y': 7,'8_y': 8,'9_y': 9,'10_y': 10,'11_y': 11})\n",
        "#false_potision_overlooked_ascending=false_potision_overlooked_ascending.rename(columns={'3_y': 3})\n",
        "\n",
        "for line_number in range(len(false_potision_overlooked_ascending)):\n",
        "  img_drawing = Image.open('/content/split_originals_test_annotations_answer_drawing/'+false_potision_overlooked_ascending.iloc[line_number][0]+\"grid.jpg\")\n",
        "  draw = ImageDraw.Draw(img_drawing)\n",
        "  #白\n",
        "  draw.rectangle((false_potision_overlooked_ascending.iloc[line_number][4], false_potision_overlooked_ascending.iloc[line_number][5],false_potision_overlooked_ascending.iloc[line_number][6],false_potision_overlooked_ascending.iloc[line_number][7]),fill=(255,255,255), outline=(255,255,255), width=5)\n",
        "  img_drawing.save('/content/split_originals_test_annotations_answer_drawing/'+false_potision_overlooked_ascending.iloc[line_number][0]+'grid.jpg')\n",
        "\n",
        "  with open('/content/split_originals_test_annotations_answer_yolotype/'+false_potision_overlooked_ascending.iloc[line_number][0]+'.txt', 'a') as f:\n",
        "    rote=str(3)+' '+str(false_potision_overlooked_ascending.iloc[line_number][8])+' '+str(false_potision_overlooked_ascending.iloc[line_number][9])+' '+str(false_potision_overlooked_ascending.iloc[line_number][10])+' '+str(false_potision_overlooked_ascending.iloc[line_number][11])+'\\n'\n",
        "    f.write(rote)\n",
        "\n",
        "#正解のダニのみ抽出\n",
        "correct1=pd.merge(all_data_ascending,false_potision_outofrange_ascending, how='outer', indicator=True)\n",
        "correct2=correct1[correct1['_merge'] == 'left_only'].iloc[:,0:12]\n",
        "correct3=pd.merge(correct2,false_potision_duplicated_ascending, how='outer', indicator=True)\n",
        "correct=correct3[correct3['_merge'] == 'left_only'].iloc[:,0:12]\n",
        "\n",
        "for line_number in range(len(correct)):\n",
        "  with open('/content/split_originals_test_annotations_answer_yolotype/'+correct.iloc[line_number][0]+'.txt', 'a') as f:\n",
        "    rote=str(0)+' '+str(correct.iloc[line_number][8])+' '+str(correct.iloc[line_number][9])+' '+str(correct.iloc[line_number][10])+' '+str(correct.iloc[line_number][11])+'\\n'\n",
        "    f.write(rote)"
      ],
      "metadata": {
        "id": "xzjQJFf4xpH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##画像とＹＯＬＯ座標データをエクスポート"
      ],
      "metadata": {
        "id": "7zyaDvsRvu7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "with open('/content/classes.txt', 'w') as f:\n",
        "  rote='mite'+'\\n'+'not_mite'+'\\n'+'divided_mite'+'\\n'+'miss_mite'\n",
        "  f.write(rote)\n",
        "\n",
        "if os.path.exists('/content/yolo_format/'):\n",
        "  shutil.rmtree('/content/yolo_format')\n",
        "\n",
        "if not os.path.exists('/content/yolo_format/'):\n",
        "  os.makedirs('/content/yolo_format/')\n",
        "  shutil.move('/content/classes.txt','/content/yolo_format/')\n",
        "  shutil.copytree('/content/split_originals_test_annotations_answer_yolotype','/content/yolo_format/annotations')\n",
        "\n",
        "shutil.make_archive('/content/yolo_format', format='zip', root_dir='/content/yolo_format')\n",
        "files.download('/content/yolo_format.zip')\n",
        "\n",
        "shutil.make_archive('/content/originals_grid', format='zip', root_dir='/content/originals_grid')\n",
        "files.download('/content/originals_grid.zip')"
      ],
      "metadata": {
        "id": "Yyh7T_1AuekF",
        "outputId": "0adf229b-9ed0-4cc6-edb0-11a0171bf14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1a913ae0-c41b-4d81-bd5c-49aa32433a98\", \"yolo_format.zip\", 6257)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aaaa59cb-ba05-4113-9e0b-6db33c79d4f1\", \"originals_grid.zip\", 9759956)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##正答率"
      ],
      "metadata": {
        "id": "8pZT9NnEWOje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(１－((**範囲外のダニ**＋**重複したダニ*1/2**)/**予測のダニのアノテーション数**))×(１－(**見逃したダニの数**/**正解のダニの数**))\n"
      ],
      "metadata": {
        "id": "iq4Q1b7XX7a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#正解率を計算vgg無し\n",
        "falsedetection=(len(false_potision_outofrange_ascending)+len(false_potision_duplicated_ascending)*1/2)/len(all_data_ascending)\n",
        "falseoverlooked=len(false_potision_overlooked_ascending)/len(answer_data_ascending)\n",
        "Accuracy=(1-falsedetection)*(1-falseoverlooked)\n",
        "print('誤検知率は',falsedetection)\n",
        "print('見逃し率は',falseoverlooked)\n",
        "print('正解率は',Accuracy)"
      ],
      "metadata": {
        "id": "aGDG3vrhxpXX",
        "outputId": "f66550b8-3f29-4f26-833b-76935f42b6da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "誤検知率は 0.20430107526881722\n",
            "見逃し率は 0.28846153846153844\n",
            "正解率は 0.5661703887510339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#正解率を計算vggあり\n",
        "falsedetection=(len(false_potision_outofrange_ascending)+len(false_potision_duplicated_ascending)*1/2)/len(all_data_ascending)\n",
        "falseoverlooked=len(false_potision_overlooked_ascending)/len(answer_data_ascending)\n",
        "Accuracy=(1-falsedetection)*(1-falseoverlooked)\n",
        "print('誤検知率は',falsedetection)\n",
        "print('見逃し率は',falseoverlooked)\n",
        "print('正解率は',Accuracy)"
      ],
      "metadata": {
        "id": "vgbVm9nWUssu",
        "outputId": "b6ebb1e6-e37d-46ac-dc24-bcc3c24f0676",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "誤検知率は 0.10897435897435898\n",
            "見逃し率は 0.3317307692307692\n",
            "正解率は 0.5954450197238659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#正解率を計算vggありyolo conf 0.3\n",
        "falsedetection=(len(false_potision_outofrange_ascending)+len(false_potision_duplicated_ascending)*1/2)/len(all_data_ascending)\n",
        "falseoverlooked=len(false_potision_overlooked_ascending)/len(answer_data_ascending)\n",
        "Accuracy=(1-falsedetection)*(1-falseoverlooked)\n",
        "print('誤検知率は',falsedetection)\n",
        "print('見逃し率は',falseoverlooked)\n",
        "print('正解率は',Accuracy)"
      ],
      "metadata": {
        "id": "JVoc43A8c_Si",
        "outputId": "1a19860b-c0bf-47b5-b70a-b9e0d7fcd414",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "誤検知率は 0.18888888888888888\n",
            "見逃し率は 0.2980769230769231\n",
            "正解率は 0.5693376068376068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#正解率を計算vggなし、背景処理あり 見逃し率は消えた葉っぱの分も含まれるので気にしない\n",
        "falsedetection=(len(false_potision_outofrange_ascending)+len(false_potision_duplicated_ascending)*1/2)/len(all_data_ascending)\n",
        "falseoverlooked=len(false_potision_overlooked_ascending)/len(answer_data_ascending)\n",
        "Accuracy=(1-falsedetection)*(1-falseoverlooked)\n",
        "print('誤検知率は',falsedetection)\n",
        "print('見逃し率は',falseoverlooked)\n",
        "print('正解率は',Accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4E-sZOjdl0v",
        "outputId": "d4f58b55-9feb-4766-88b3-e42cc17ff31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "誤検知率は 0.1592356687898089\n",
            "見逃し率は 0.36538461538461536\n",
            "正解率は 0.533561979421852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ONNX形式へexport"
      ],
      "metadata": {
        "id": "9KIq6v6fy8Cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "!python export.py --weight /content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite/weights/best.pt"
      ],
      "metadata": {
        "id": "LwO3u-IgzBcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##画像を結合"
      ],
      "metadata": {
        "id": "Y8lIt4CITbm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "#結合元の画像の読み込み\n",
        "originals=('/content/detect_output/*.jpg')\n",
        "read_files = glob.glob(originals)\n",
        "\n",
        "for name in read_files:\n",
        "  imagename=name[23:-12]\n",
        "  if not os.path.exists('/content/detect_output/'+imagename):\n",
        "    os.makedirs('/content/detect_output/'+imagename)\n",
        "  shutil.move(name,'/content/detect_output/'+imagename)"
      ],
      "metadata": {
        "id": "IhyIWgzL4a-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#'NoneType' object is not subscriptableといわれるので先にipynb_checkpointsを消す\n",
        "#!rm -rf `find -type d -name .ipynb_checkpoints`\n",
        "\n",
        "#画像結合先のフォルダを作成\n",
        "if not os.path.exists('/content/merged_pic_original/'):\n",
        "  os.makedirs('/content/merged_pic_original/')\n",
        "\n",
        "#結合元の画像の読み込み\n",
        "read_folda_name='/content/detect_output'\n",
        "read_folda = os.listdir(read_folda_name)\n",
        "\n",
        "for image_folda_name in read_folda:\n",
        "  if image_folda_name=='labels':\n",
        "    print(\"\")\n",
        "  else:\n",
        "    paths = glob.glob('/content/detect_output/'+image_folda_name+'/*')  # 画像のパス一覧\n",
        "\n",
        "    # 画像を読み込む。\n",
        "    imgs = np.array([cv2.imread(p) for p in sorted(paths)])\n",
        "    print(imgs.shape)\n",
        "\n",
        "    # 画像の形状を変更する。\n",
        "    h, w, c = imgs.shape[1:]\n",
        "    #rows, cols = 5, 3  # 結合前の画像が何行何列あるか\n",
        "    imgs = imgs.reshape(split_y, split_x, h, w, c)\n",
        "\n",
        "    merged = np.vstack([np.hstack(h) for h in imgs])\n",
        "    cv2.imwrite('/content/merged_pic_original/'+image_folda_name+'.jpg', merged)"
      ],
      "metadata": {
        "id": "-BD2GQOGz5H3",
        "outputId": "9f2a38d4-25c3-4353-8980-312e85ca00ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(400, 1040, 780, 3)\n",
            "(400, 1040, 780, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#画像サイズを縮小\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/originals_downsize/'):\n",
        "  os.makedirs('/content/originals_downsize/')\n",
        "\n",
        "read_folda_name='/content/merged_pic_original'\n",
        "read_folda = os.listdir(read_folda_name)\n",
        "\n",
        "for image_folda_name in read_folda:\n",
        "  # 読み込む画像を選択\n",
        "  img = cv2.imread('/content/merged_pic_original/'+image_folda_name)\n",
        "  h,w=img.shape[:2]\n",
        "  # サイズ設定｜cv2では(幅、高さ）の順で数値を設定\n",
        "  size = (int(w/5),int(h/5)) \n",
        "  # 画像拡大・縮小 オプションで拡大計算式変更可能\n",
        "  img_inter_area  = cv2.resize(img,size,interpolation = cv2.INTER_LINEAR) \n",
        "  #保存\n",
        "  cv2.imwrite('/content/originals_downsize/'+image_folda_name, img_inter_area)"
      ],
      "metadata": {
        "id": "R9J1gWWF9nOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##検出結果のテキストを整理"
      ],
      "metadata": {
        "id": "K0JxVvm3M7FW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#検出結果のテキストを整理\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "\n",
        "\n",
        "detectedtxt=('/content/detect_output/labels/*')\n",
        "read_files = glob.glob(detectedtxt)\n",
        "\n",
        "with open(\"/content/detect_position.txt\", \"w\") as new_file:\n",
        "    for name in read_files:\n",
        "        with open(name) as f:\n",
        "            for line in f:\n",
        "                new_file.write(line)\n",
        "txt_file = pd.read_csv(\"/content/detect_position.txt\",header=None, sep=\" \")"
      ],
      "metadata": {
        "id": "e7fBmvVgM_z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#動画でも推論可能"
      ],
      "metadata": {
        "id": "pf1HCVAStv4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py \\\n",
        "  --source inference/images/road.mp4 \\\n",
        "  --weights yolov7-e6e.pt \\\n",
        "  --conf 0.25 \\\n",
        "  --img-size 1280 \\\n",
        "  --device 0"
      ],
      "metadata": {
        "id": "l7_-Rofnt0TB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}