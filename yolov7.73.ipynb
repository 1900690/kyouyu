{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolov7.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1900690/kyouyu/blob/main/yolov7.73.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLOv7を使って自作データセットで物体検出してみたhttps://dev.classmethod.jp/articles/yolov7-train-with-customize-dataset/"
      ],
      "metadata": {
        "id": "rN5V-AInHMBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[精度を上げるための考察](https://www.nakasha.co.jp/future/ai/yolov3train.html)\n",
        "[ハイパーパラメータ進化について](https://farml1.com/yolov7/)"
      ],
      "metadata": {
        "id": "blVDL015QYjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "※まずランタイムをＧＰＵにすること\n",
        "\n",
        "※計算はdriveで行うのでログインするアカウントに注意"
      ],
      "metadata": {
        "id": "EG4zw1tF7aKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#★切り取り消去用道具★\n",
        "import shutil\n",
        "#shutil.rmtree('/content/detect_output2')\n",
        "#shutil.move('/content/drive/MyDrive/cut', '/content/')\n",
        "#shutil.move('/content/cut_crear', '/content/drive/MyDrive')\n",
        "#shutil.move('/content/drive/MyDrive/yolov7', '/content/')\n",
        "#shutil.rmtree('/content/yolo')\n",
        "#shutil.rmtree('/content/drive/MyDrive/yolov7/dataset/mite')\n",
        "#%mkdir \"/content/drive/MyDrive/yolov7/dataset/mite/train/images\"\n",
        "#!unzip -q /content/DSC_0281split_y3_x9.zip\n",
        "shutil.make_archive('/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite', format='zip', root_dir='/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite')\n",
        "#shutil.unpack_archive(\"/content/drive/MyDrive/dataset.zip\", \"/content/drive/MyDrive/yolov7/dataset\")\n",
        "#shutil.unpack_archive(\"/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite.zip\", \"/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite\")\n",
        "#shutil.copy('/content/20221123yolov7-10epoch-8592mages-200size-mite2/weights/20221123yolov7-10epoch-8592mages-200size-mite2.pt','/content/drive/MyDrive/weights_box')"
      ],
      "metadata": {
        "id": "TJ8l9lcfGNsv",
        "outputId": "3b28b64e-ae18-43e2-c9b6-dacb91ad6611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-dce1c91e8b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#%mkdir \"/content/drive/MyDrive/yolov7/dataset/mite/train/images\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#!unzip -q /content/DSC_0281split_y3_x9.zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#shutil.unpack_archive(\"/content/drive/MyDrive/dataset.zip\", \"/content/drive/MyDrive/yolov7/dataset\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#shutil.unpack_archive(\"/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite.zip\", \"/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/shutil.py\u001b[0m in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mbase_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite.zip\", \"/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite\")"
      ],
      "metadata": {
        "id": "9KK8wmOF0Elz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ドライブに接続"
      ],
      "metadata": {
        "id": "NOFSPhoocxaW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xv0DNhGz4Wj-",
        "outputId": "27b63cd8-0b0f-482b-8d49-87bd193fe0d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#リマウント\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "id": "kl3hGKoi9rKh",
        "outputId": "86fd50f8-fe38-411e-dd06-e86b46aab15f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#事前準備"
      ],
      "metadata": {
        "id": "PpgKpzVbdOSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ドライブバージョン\n",
        "%cd \"/content/drive/MyDrive\"\n",
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "%cd \"/content/drive/MyDrive/yolov7\""
      ],
      "metadata": {
        "id": "91UrKWbYY1UE",
        "outputId": "e7d3a0a9-1df9-4a36-9bf9-dbfc18c0ae88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1088, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 1088 (delta 18), reused 81 (delta 17), pack-reused 998\u001b[K\n",
            "Receiving objects: 100% (1088/1088), 69.97 MiB | 17.91 MiB/s, done.\n",
            "Resolving deltas: 100% (485/485), done.\n",
            "Checking out files: 100% (104/104), done.\n",
            "/content/drive/MyDrive/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#contentバージョン\n",
        "!git clone https://github.com/WongKinYiu/yolov7"
      ],
      "metadata": {
        "id": "LFXc9RBy5adI",
        "outputId": "e764eef0-b6c9-41a2-ed84-2cf14825a3c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 998, done.\u001b[K\n",
            "remote: Total 998 (delta 0), reused 0 (delta 0), pack-reused 998\u001b[K\n",
            "Receiving objects: 100% (998/998), 69.77 MiB | 23.50 MiB/s, done.\n",
            "Resolving deltas: 100% (467/467), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -r requirements.txt\n",
        "!pip install PyYAML==5.4.1"
      ],
      "metadata": {
        "id": "eUhiWQ7h5qjw",
        "outputId": "442124f6-b53e-46ba-8275-2c86a462dc75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyYAML==5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 30.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "Successfully installed PyYAML-5.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#データセットを入れるためのフォルダを作成"
      ],
      "metadata": {
        "id": "bHHfw3UQd4Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ドライブバージョン\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/drive/MyDrive/yolov7/dataset/mite/train/images'):\n",
        "  os.makedirs('/content/drive/MyDrive/yolov7/dataset/mite/train/images')\n",
        "  os.makedirs('/content/drive/MyDrive/yolov7/dataset/mite/train/labels')\n",
        "  os.makedirs('/content/drive/MyDrive/yolov7/dataset/mite/valid/images')\n",
        "  os.makedirs('/content/drive/MyDrive/yolov7/dataset/mite/valid/labels')"
      ],
      "metadata": {
        "id": "rLJThEu3HGKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#contentバージョン\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/yolov7/dataset/mite/train/images'):\n",
        "  os.makedirs('/content/yolov7/dataset/mite/train/images')\n",
        "  os.makedirs('/content/yolov7/dataset/mite/train/labels')\n",
        "  os.makedirs('/content/yolov7/dataset/mite/valid/images')\n",
        "  os.makedirs('/content/yolov7/dataset/mite/valid/labels')"
      ],
      "metadata": {
        "id": "dwgD5Mrm6B6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#データセットを分割"
      ],
      "metadata": {
        "id": "LG2hJpEEKi0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fastlabelから直接contentへダウンロード\n",
        "import shutil\n",
        "#fastrabel\n",
        "!wget -O \"/content/fastlabel.zip\" \"https://s3.ap-northeast-1.amazonaws.com/prod.fastlabel.app.exports/3efde406-abc7-4f3e-a3bd-905d3535a34d/3a93ecff-ad81-49b0-b8e1-74f460bc97c5/exports/20221106015037.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAYVHKCFVVH7AKJ5WM%2F20221106%2Fap-northeast-1%2Fs3%2Faws4_request&X-Amz-Date=20221106T054715Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBAaDmFwLW5vcnRoZWFzdC0xIkcwRQIhAKRilNroYbS4S4UrMwDebCBwMDzcDTNNQ1yPYeciwr7HAiA%2F85sv3lXqzII6%2B4s5YOritncpmF5UqJ0AdMghrg16WyqFBAj5%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDU5NTM0Mzg0Njc2MiIM1VIeAfPrwVXhH5LnKtkDomfYFDncXF7V5fEfp7L1kOb0xVl4bNmEo7a3E0R1NNgkFCKuH9SN8wVAhp6POD%2BGsDXcCQdDlDZEbodMKxxBAdnHVjqbxyA%2FmVd3xIAa0CI9LnDx7075a%2B3shibhfNoruSvdWKGeC2oXrSo91yvj0%2FfecgQtVYDzZ%2FLAf5oPqbWcwmG7vzKdX4DEAun75AlES6uNw9k8RCINPBvMX%2BQC%2BQy5MJ8bmY%2FdDgaSNQZCAtQzCNQ%2FGBmwfgc12UJqZrFy7e66bs3cfnCPoQ%2BbicQ5sENFwRaiYVvBZzgph%2FXh7FTlRL4pUhoTrlB24Kvml3%2BKqZRqMveA4GMtix12vZVukjmuvkylQPV0Nq%2BDqBXl%2BShl15EOdx2bYF20u%2FE%2FsY8%2BS488FlCbp1thXr0XrNis6H7dAc7os22Gj0ARGlsbCiF%2BvMJGMKyrwc7aZBxqpvZzzEsi%2F1Immm9CZiAyBrmz6mc3jX4j7mm8NjIIkDNaVP2Z3NWx6%2ByKMreSMLT0w%2FYWLTWJ%2BjxyIBPL3g53dOBFykwuMAXBWqq4xrcIHlsJsRefdWI%2FwINKAb46RJ%2BJUWAnfCN0QJJ2Jo0v5BHWuRNUFU6uEIO89m0MRihHHAioOlH8Jax558I%2FAtkww%2FCbmwY6pQH%2F3hZngAQ3I7zeNp%2BG34TXM6hbxKi8qUWJz%2BfiiuCCPW56cXjqOyss0ioXAFrglN41UlaAWwCbIsfZ1tb339viB%2BCZne1uBWQn15xAr%2FGIuZOZEBWLhzLTygbzyKHCsYQ5bhSQiEPQbyz3mN%2BalhqgTl%2FX1wZ6f3CceDSNdcRUNaBwXkZpxFFUsxnC7Oskp%2BwMNMX2LMCmWUtFKGSALLbEdmY6hdo%3D&X-Amz-Signature=55658812d65af34bb28d3f506eb933c66393aa7c981a3b39e701c3108060a19c&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22mite-bbox-rotation-360-flip_20221106015037.zip%22\"\n",
        "shutil.unpack_archive('/content/fastlabel.zip', '/content')\n",
        "#roboflow\n",
        "#!wget -O \"/content/mask.zip\" \"https://public.roboflow.com/ds/5Sgfwh8fVh?key=B1sJwF8cTX\"\n",
        "#shutil.unpack_archive('/content/mask.zip', '/content')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdUYbPerknvb",
        "outputId": "aa18a83c-0e9f-4e32-fe85-30c4e2f49e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-06 05:47:48--  https://s3.ap-northeast-1.amazonaws.com/prod.fastlabel.app.exports/3efde406-abc7-4f3e-a3bd-905d3535a34d/3a93ecff-ad81-49b0-b8e1-74f460bc97c5/exports/20221106015037.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAYVHKCFVVH7AKJ5WM%2F20221106%2Fap-northeast-1%2Fs3%2Faws4_request&X-Amz-Date=20221106T054715Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBAaDmFwLW5vcnRoZWFzdC0xIkcwRQIhAKRilNroYbS4S4UrMwDebCBwMDzcDTNNQ1yPYeciwr7HAiA%2F85sv3lXqzII6%2B4s5YOritncpmF5UqJ0AdMghrg16WyqFBAj5%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDU5NTM0Mzg0Njc2MiIM1VIeAfPrwVXhH5LnKtkDomfYFDncXF7V5fEfp7L1kOb0xVl4bNmEo7a3E0R1NNgkFCKuH9SN8wVAhp6POD%2BGsDXcCQdDlDZEbodMKxxBAdnHVjqbxyA%2FmVd3xIAa0CI9LnDx7075a%2B3shibhfNoruSvdWKGeC2oXrSo91yvj0%2FfecgQtVYDzZ%2FLAf5oPqbWcwmG7vzKdX4DEAun75AlES6uNw9k8RCINPBvMX%2BQC%2BQy5MJ8bmY%2FdDgaSNQZCAtQzCNQ%2FGBmwfgc12UJqZrFy7e66bs3cfnCPoQ%2BbicQ5sENFwRaiYVvBZzgph%2FXh7FTlRL4pUhoTrlB24Kvml3%2BKqZRqMveA4GMtix12vZVukjmuvkylQPV0Nq%2BDqBXl%2BShl15EOdx2bYF20u%2FE%2FsY8%2BS488FlCbp1thXr0XrNis6H7dAc7os22Gj0ARGlsbCiF%2BvMJGMKyrwc7aZBxqpvZzzEsi%2F1Immm9CZiAyBrmz6mc3jX4j7mm8NjIIkDNaVP2Z3NWx6%2ByKMreSMLT0w%2FYWLTWJ%2BjxyIBPL3g53dOBFykwuMAXBWqq4xrcIHlsJsRefdWI%2FwINKAb46RJ%2BJUWAnfCN0QJJ2Jo0v5BHWuRNUFU6uEIO89m0MRihHHAioOlH8Jax558I%2FAtkww%2FCbmwY6pQH%2F3hZngAQ3I7zeNp%2BG34TXM6hbxKi8qUWJz%2BfiiuCCPW56cXjqOyss0ioXAFrglN41UlaAWwCbIsfZ1tb339viB%2BCZne1uBWQn15xAr%2FGIuZOZEBWLhzLTygbzyKHCsYQ5bhSQiEPQbyz3mN%2BalhqgTl%2FX1wZ6f3CceDSNdcRUNaBwXkZpxFFUsxnC7Oskp%2BwMNMX2LMCmWUtFKGSALLbEdmY6hdo%3D&X-Amz-Signature=55658812d65af34bb28d3f506eb933c66393aa7c981a3b39e701c3108060a19c&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22mite-bbox-rotation-360-flip_20221106015037.zip%22\n",
            "Resolving s3.ap-northeast-1.amazonaws.com (s3.ap-northeast-1.amazonaws.com)... 52.219.196.88, 52.219.196.84, 52.219.16.22, ...\n",
            "Connecting to s3.ap-northeast-1.amazonaws.com (s3.ap-northeast-1.amazonaws.com)|52.219.196.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13321210 (13M) [binary/octet-stream]\n",
            "Saving to: ‘/content/fastlabel.zip’\n",
            "\n",
            "/content/fastlabel. 100%[===================>]  12.70M  5.16MB/s    in 2.5s    \n",
            "\n",
            "2022-11-06 05:47:52 (5.16 MB/s) - ‘/content/fastlabel.zip’ saved [13321210/13321210]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##contentに画像とラベルデータを解凍する"
      ],
      "metadata": {
        "id": "6DaU8-NbJXmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "if not os.path.exists('/content/annotations'):\n",
        "  shutil.unpack_archive('/content/drive/MyDrive/annotations.zip', '/content/annotations')\n",
        "if not os.path.exists('/content/originals'):\n",
        "  shutil.unpack_archive('/content/drive/MyDrive/cut_crear.zip', '/content/originals')\n",
        "if not os.path.exists('/content/annotations_not_mite'):\n",
        "  shutil.unpack_archive('/content/drive/MyDrive/annotations_not_mite.zip', '/content/annotations_not_mite')\n",
        "if not os.path.exists('/content/originals_not_mite'):\n",
        "  shutil.unpack_archive('/content/drive/MyDrive/cut_not_mite.zip', '/content/originals_not_mite')"
      ],
      "metadata": {
        "id": "-3_GJn2ruaHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##画像サイズを640にアップサンプリング（アノテーションはそのままでよい）"
      ],
      "metadata": {
        "id": "pIO89t-FF95q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#画像サイズを640にアップサンプリング（アノテーションはそのままでよい）\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/originals_upsamples/'):\n",
        "  os.makedirs('/content/originals_upsamples/')\n",
        "if not os.path.exists('/content/originals_upsamples_not_mite/'):\n",
        "  os.makedirs('/content/originals_upsamples_not_mite/')\n",
        "\n",
        "originals=('/content/originals/*')\n",
        "read_files = glob.glob(originals)\n",
        "originals_not_mite=('/content/originals_not_mite/*')\n",
        "read_files_not_mite = glob.glob(originals_not_mite)\n",
        "\n",
        "for imgpass in read_files:\n",
        "  # 読み込む画像を選択\n",
        "  img = cv2.imread(imgpass)\n",
        "  # サイズ設定｜cv2では(幅、高さ）の順で数値を設定\n",
        "  size = (640,640) \n",
        "  # 画像拡大・縮小 オプションで拡大計算式変更可能\n",
        "  img_inter_area  = cv2.resize(img,size,interpolation = cv2.INTER_LINEAR) \n",
        "  #保存\n",
        "  cv2.imwrite('/content/originals_upsamples/'+os.path.split(imgpass)[1], img_inter_area)\n",
        "for imgpass in read_files_not_mite:\n",
        "  # 読み込む画像を選択\n",
        "  img = cv2.imread(imgpass)\n",
        "  # サイズ設定｜cv2では(幅、高さ）の順で数値を設定\n",
        "  size = (640,640) \n",
        "  # 画像拡大・縮小 オプションで拡大計算式変更可能\n",
        "  img_inter_area  = cv2.resize(img,size,interpolation = cv2.INTER_LINEAR) \n",
        "  #保存\n",
        "  cv2.imwrite('/content/originals_upsamples_not_mite/'+os.path.split(imgpass)[1], img_inter_area)"
      ],
      "metadata": {
        "id": "jXRvUztnWkuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "annotations=('/content/annotations')\n",
        "originals=('/content/originals_upsamples')\n",
        "annotations_not_mite=('/content/annotations_not_mite')\n",
        "originals_not_mite=('/content/originals_upsamples_not_mite')\n",
        "\n",
        "read_files_annotations = os.listdir(annotations)\n",
        "read_files_annotations.sort()\n",
        "read_files_originals= os.listdir(originals)\n",
        "read_files_originals.sort()\n",
        "read_files_annotations_not_mite = os.listdir(annotations_not_mite)\n",
        "read_files_annotations_not_mite.sort()\n",
        "read_files_originals_not_mite= os.listdir(originals_not_mite)\n",
        "read_files_originals_not_mite.sort()\n",
        "\n",
        "annotations_train, annotations_test, originals_train, originals_test = train_test_split(read_files_annotations,read_files_originals,test_size=0.2)\n",
        "annotations_train_not_mite, annotations_test_not_mite, originals_train_not_mite, originals_test_not_mite = train_test_split(read_files_annotations_not_mite,read_files_originals_not_mite,test_size=0.2)"
      ],
      "metadata": {
        "id": "NPTMFr5NKg3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#driveバージョン\n",
        "import os\n",
        "import math\n",
        "\n",
        "for filename in annotations_train:\n",
        "  shutil.copy( annotations+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/train/labels/')\n",
        "for filename in annotations_test:\n",
        "  shutil.copy( annotations+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/valid/labels')\n",
        "for filename in originals_train:\n",
        "  shutil.copy( originals+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/train/images')\n",
        "for filename in originals_test:\n",
        "  shutil.copy( originals+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/valid/images')\n",
        "\n",
        "for filename in annotations_train_not_mite:\n",
        "  shutil.copy( annotations_not_mite+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/train/labels/')\n",
        "for filename in annotations_test_not_mite:\n",
        "  shutil.copy( annotations_not_mite+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/valid/labels')\n",
        "for filename in originals_train_not_mite:\n",
        "  shutil.copy( originals_not_mite+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/train/images')\n",
        "for filename in originals_test_not_mite:\n",
        "  shutil.copy( originals_not_mite+\"/\"+filename,'/content/drive/MyDrive/yolov7/dataset/mite/valid/images')\n",
        "\n",
        "#ディレクトリのパスを指定\n",
        "train_images = '/content/drive/MyDrive/yolov7/dataset/mite/train/images'\n",
        "train_labels = '/content/drive/MyDrive/yolov7/dataset/mite/train/labels'\n",
        "valid_images = '/content/drive/MyDrive/yolov7/dataset/mite/valid/images'\n",
        "valid_labels = '/content/drive/MyDrive/yolov7/dataset/mite/valid/labels'\n",
        "#ファイル数を出力\n",
        "print(\"train/imagesは\",sum(os.path.isfile(os.path.join(train_images, name)) for name in os.listdir(train_images)))\n",
        "print(\"train/labelsは\",sum(os.path.isfile(os.path.join(train_labels, name)) for name in os.listdir(train_labels)))\n",
        "print(\"valid/imagesは\",sum(os.path.isfile(os.path.join(valid_images, name)) for name in os.listdir(valid_images)))\n",
        "print(\"valid/labelsは\",sum(os.path.isfile(os.path.join(valid_labels, name)) for name in os.listdir(valid_labels)))\n",
        "print(\"最大公約数は\",math.gcd(sum(os.path.isfile(os.path.join(train_images, name)) for name in os.listdir(train_images)),sum(os.path.isfile(os.path.join(valid_images, name)) for name in os.listdir(valid_images))))"
      ],
      "metadata": {
        "id": "KjtJL8BjUUAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b507213-d2d8-426c-cd17-9a2d4fcc8d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/imagesは 4599\n",
            "train/labelsは 4599\n",
            "valid/imagesは 1151\n",
            "valid/labelsは 1151\n",
            "最大公約数は 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#調整後調査用\n",
        "train_images = '/content/drive/MyDrive/yolov7/dataset/mite/train/images'\n",
        "train_labels = '/content/drive/MyDrive/yolov7/dataset/mite/train/labels'\n",
        "valid_images = '/content/drive/MyDrive/yolov7/dataset/mite/valid/images'\n",
        "valid_labels = '/content/drive/MyDrive/yolov7/dataset/mite/valid/labels'\n",
        "#ファイル数を出力\n",
        "print(\"train/imagesは\",sum(os.path.isfile(os.path.join(train_images, name)) for name in os.listdir(train_images)))\n",
        "print(\"train/labelsは\",sum(os.path.isfile(os.path.join(train_labels, name)) for name in os.listdir(train_labels)))\n",
        "print(\"valid/imagesは\",sum(os.path.isfile(os.path.join(valid_images, name)) for name in os.listdir(valid_images)))\n",
        "print(\"valid/labelsは\",sum(os.path.isfile(os.path.join(valid_labels, name)) for name in os.listdir(valid_labels)))\n",
        "print(\"最大公約数は\",math.gcd(sum(os.path.isfile(os.path.join(train_images, name)) for name in os.listdir(train_images)),sum(os.path.isfile(os.path.join(valid_images, name)) for name in os.listdir(valid_images))))"
      ],
      "metadata": {
        "id": "-4BeSEGqJKsM",
        "outputId": "3d2461e0-c8fd-46ec-cdd1-a753de342a60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/imagesは 4600\n",
            "train/labelsは 4600\n",
            "valid/imagesは 1150\n",
            "valid/labelsは 1150\n",
            "最大公約数は 1150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#contentバージョン\n",
        "import os\n",
        "\n",
        "for filename in annotations_train:\n",
        "  shutil.copy( annotations+\"/\"+filename,'/content/yolov7/dataset/mite/train/labels/')\n",
        "for filename in annotations_test:\n",
        "  shutil.copy( annotations+\"/\"+filename,'/content/yolov7/dataset/mite/valid/labels')\n",
        "for filename in originals_train:\n",
        "  shutil.copy( originals+\"/\"+filename,'/content/yolov7/dataset/mite/train/images')\n",
        "for filename in originals_test:\n",
        "  shutil.copy( originals+\"/\"+filename,'/content/yolov7/dataset/mite/valid/images')\n",
        "#ディレクトリのパスを指定\n",
        "train_images = '/content/yolov7/dataset/mite/train/images'\n",
        "train_labels = '/content/yolov7/dataset/mite/train/labels'\n",
        "valid_images = '/content/yolov7/dataset/mite/valid/images'\n",
        "valid_labels = '/content/yolov7/dataset/mite/valid/labels'\n",
        "#ファイル数を出力\n",
        "print(\"train/imagesは\",sum(os.path.isfile(os.path.join(train_images, name)) for name in os.listdir(train_images)))\n",
        "print(\"train/labelsは\",sum(os.path.isfile(os.path.join(train_labels, name)) for name in os.listdir(train_labels)))\n",
        "print(\"valid/imagesは\",sum(os.path.isfile(os.path.join(valid_images, name)) for name in os.listdir(valid_images)))\n",
        "print(\"valid/labelsは\",sum(os.path.isfile(os.path.join(valid_labels, name)) for name in os.listdir(valid_labels)))"
      ],
      "metadata": {
        "id": "koHCIvwO7Akn",
        "outputId": "60926aa7-b889-4888-969c-233e83059e22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/imagesは 2296\n",
            "train/labelsは 2296\n",
            "valid/imagesは 574\n",
            "valid/labelsは 574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#データセットへのパスとクラスについての情報を記載しdataファイルへ入れる"
      ],
      "metadata": {
        "id": "bMau9RQveSVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/yolov7/data/mite.yaml\n",
        "# COCO 2017 dataset http://cocodataset.org\n",
        "\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: ./dataset/mite/train\n",
        "val: ./dataset/mite/valid\n",
        "\n",
        "# number of classes\n",
        "nc: 1\n",
        "\n",
        "# class names\n",
        "names: ['mite']"
      ],
      "metadata": {
        "id": "_odMXZBiYngq",
        "outputId": "aaf33259-56bc-4e2e-fdfd-3293d27b8be4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/drive/MyDrive/yolov7/data/mite.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/yolov7/data/mite.yaml\n",
        "# COCO 2017 dataset http://cocodataset.org\n",
        "\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: ./dataset/mite/train\n",
        "val: ./dataset/mite/valid\n",
        "\n",
        "# number of classes\n",
        "nc: 1\n",
        "\n",
        "# class names\n",
        "names: ['mite']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYQbuRa-HNXi",
        "outputId": "896544a0-15d1-415c-945b-5880907efdcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/yolov7/data/mite.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/yolov7/data/mask.yaml\n",
        "# COCO 2017 dataset http://cocodataset.org\n",
        "\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: ./dataset/mask/train\n",
        "val: ./dataset/mask/valid\n",
        "\n",
        "# number of classes\n",
        "nc: 2\n",
        "\n",
        "# class names\n",
        "names: ['mask','non-mask']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMLDEmX8MJDH",
        "outputId": "e8a47ee5-3dad-40d2-85eb-810e7ca17b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/yolov7/data/mask.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#学習開始\n",
        "※学習時間はlogの中に書いてある"
      ],
      "metadata": {
        "id": "Tw3efjK_H1MS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[物体検出の評価指標の計算方法](https://axa.biopapyrus.jp/deep-learning/cnn/object-detection/map.html)"
      ],
      "metadata": {
        "id": "AW2R7xfJsqSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "if os.path.exists('/content/drive/MyDrive/yolov7/checkpoints'):\n",
        "  shutil.rmtree('/content/drive/MyDrive/yolov7/checkpoints')\n",
        "#重みをコピー\n",
        "shutil.copytree('/content/drive/MyDrive/weights_box','/content/drive/MyDrive/yolov7/checkpoints')"
      ],
      "metadata": {
        "id": "FhPYxMwf83mV",
        "outputId": "d37f13e1-c83b-41c8-e604-a67e48e39d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/yolov7/checkpoints'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "#初学習用、学習前の重みをダウンロード\n",
        "#!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-e6.pt -P ./checkpoints\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt -P ./checkpoints"
      ],
      "metadata": {
        "id": "1qf9VrXAIIk8",
        "outputId": "b4b724ec-8926-4a61-e33b-c2d60387d897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov7\n",
            "--2022-11-25 07:44:45--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221125%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221125T074445Z&X-Amz-Expires=300&X-Amz-Signature=6551ace14d644646966b247dfd62c34df7651e4ca38ba6197ffa300655bccdb4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-25 07:44:45--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221125%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221125T074445Z&X-Amz-Expires=300&X-Amz-Signature=6551ace14d644646966b247dfd62c34df7651e4ca38ba6197ffa300655bccdb4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75628875 (72M) [application/octet-stream]\n",
            "Saving to: ‘./checkpoints/yolov7_training.pt’\n",
            "\n",
            "yolov7_training.pt  100%[===================>]  72.12M  66.2MB/s    in 1.1s    \n",
            "\n",
            "2022-11-25 07:44:46 (66.2 MB/s) - ‘./checkpoints/yolov7_training.pt’ saved [75628875/75628875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   batch-sizeでepochあたりに使用する画像の枚数を調節（2だと1epochあたり総数/2枚使用する。なので、ここを増やすとGPUメモリを節約できる）（バッチ枚ごとにパラメータの見直しを行う）\n",
        "*   [index 30 is out of bounds for axis 0 with size 30 for Evolveエラーの場合](https://github.com/WongKinYiu/yolov7/issues/999)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qqT4FJfKpupu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#初学習\n",
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "!python train.py \\\n",
        "  --workers 1 \\\n",
        "  --batch-size 2 \\\n",
        "  --data data/mite.yaml \\\n",
        "  --cfg cfg/training/yolov7.yaml \\\n",
        "  --weights /content/drive/MyDrive/weights_box/yolov7_training.pt \\\n",
        "  --name '/content/drive/MyDrive/20221128yolov7-100epoch-2batch-5750images-640upsized-mite' \\\n",
        "  --hyp data/hyp.scratch.p5.yaml \\\n",
        "  --img 640 640 \\\n",
        "  --epochs 100 \\\n",
        "  --device 0 "
      ],
      "metadata": {
        "id": "VR0zPw8o8D3O",
        "outputId": "62659bfe-de81-4209-8b3e-45f40ffe4ead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov7\n",
            "YOLOR 🚀 v0.1-115-g072f76c torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=2, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/mite.yaml', device='0', entity=None, epochs=100, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='/content/drive/MyDrive/20221128yolov7-100epoch-2batch-5750images-640upsized-mite', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='/content/drive/MyDrive/20221128yolov7-100epoch-2batch-5750images-640upsized-mite', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=2, upload_dataset=False, v5_metric=False, weights='/content/drive/MyDrive/weights_box/yolov7_training.pt', workers=1, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     34156  models.yolo.IDetect                     [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "Model Summary: 415 layers, 37196556 parameters, 37196556 gradients\n",
            "\n",
            "Transferred 555/566 items from /content/drive/MyDrive/weights_box/yolov7_training.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'dataset/mite/train/labels' images and labels... 4600 found, 0 missing, 2279 empty, 0 corrupted: 100% 4600/4600 [00:12<00:00, 372.12it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: dataset/mite/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'dataset/mite/valid/labels' images and labels... 1150 found, 0 missing, 570 empty, 0 corrupted: 100% 1150/1150 [00:03<00:00, 357.86it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: dataset/mite/valid/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.44, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to /content/drive/MyDrive/20221128yolov7-100epoch-2batch-5750images-640upsized-mite\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/99     2.55G   0.04319  0.005595         0   0.04879         1       640: 100% 2300/2300 [06:25<00:00,  5.97it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/288 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:29<00:00,  9.63it/s]\n",
            "                 all        1150         606     0.00594       0.112     0.00279    0.000466\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/99     2.51G   0.04136  0.003045         0   0.04441         2       640: 100% 2300/2300 [05:56<00:00,  6.46it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.49it/s]\n",
            "                 all        1150         606    0.000799       0.106    0.000262       4e-05\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/99     2.51G   0.04212  0.002952         0   0.04507         2       640: 100% 2300/2300 [05:51<00:00,  6.54it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.55it/s]\n",
            "                 all        1150         606     0.00171       0.401    0.000808    0.000148\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/99     2.51G    0.0391  0.002806         0    0.0419         1       640: 100% 2300/2300 [05:42<00:00,  6.71it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.66it/s]\n",
            "                 all        1150         606     0.00223     0.00495    0.000104    2.47e-05\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/99     2.51G     0.039  0.003144         0   0.04214         1       640: 100% 2300/2300 [05:48<00:00,  6.60it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.52it/s]\n",
            "                 all        1150         606     0.00148       0.234    0.000593    9.92e-05\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/99     2.51G   0.03787  0.003266         0   0.04114         1       640: 100% 2300/2300 [05:44<00:00,  6.68it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.50it/s]\n",
            "                 all        1150         606     0.00313      0.0413    0.000604    0.000116\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/99     2.51G   0.03852  0.003393         0   0.04191         1       640: 100% 2300/2300 [05:44<00:00,  6.68it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.19it/s]\n",
            "                 all        1150         606     0.00427      0.0644     0.00155    0.000284\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/99     2.51G   0.03815  0.003386         0   0.04154         0       640: 100% 2300/2300 [05:46<00:00,  6.64it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.53it/s]\n",
            "                 all        1150         606     0.00505      0.0495     0.00145     0.00027\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/99     2.51G   0.03623  0.003286         0   0.03952         2       640: 100% 2300/2300 [05:43<00:00,  6.70it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.56it/s]\n",
            "                 all        1150         606      0.0139      0.0149     0.00182    0.000343\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/99     2.51G   0.03772  0.003406         0   0.04113         2       640: 100% 2300/2300 [05:42<00:00,  6.71it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.10it/s]\n",
            "                 all        1150         606      0.0144       0.033       0.002    0.000325\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/99     2.51G   0.03746  0.003331         0   0.04079         0       640: 100% 2300/2300 [05:44<00:00,  6.67it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.53it/s]\n",
            "                 all        1150         606     0.00808      0.0116     0.00119      0.0002\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/99     2.51G   0.03791  0.003307         0   0.04122         1       640: 100% 2300/2300 [05:47<00:00,  6.62it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.59it/s]\n",
            "                 all        1150         606     0.00672      0.0347     0.00129    0.000263\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/99     2.51G   0.03803  0.003244         0   0.04127         2       640: 100% 2300/2300 [05:45<00:00,  6.66it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:24<00:00, 11.95it/s]\n",
            "                 all        1150         606     0.00757     0.00825     0.00139    0.000224\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/99     2.51G   0.03811   0.00311         0   0.04122         1       640: 100% 2300/2300 [05:47<00:00,  6.61it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.53it/s]\n",
            "                 all        1150         606     0.00473       0.183     0.00228    0.000431\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/99     2.51G   0.03856   0.00321         0   0.04176         0       640: 100% 2300/2300 [05:48<00:00,  6.60it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.50it/s]\n",
            "                 all        1150         606     0.00586       0.186     0.00327    0.000615\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/99     2.51G   0.03763  0.003218         0   0.04085         0       640: 100% 2300/2300 [05:45<00:00,  6.66it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.55it/s]\n",
            "                 all        1150         606       0.014      0.0726     0.00529     0.00116\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/99     2.51G   0.03758  0.003247         0   0.04082         0       640: 100% 2300/2300 [05:46<00:00,  6.64it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.18it/s]\n",
            "                 all        1150         606      0.0234       0.165      0.0113     0.00257\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/99     2.51G   0.03705  0.003277         0   0.04032         3       640: 100% 2300/2300 [05:47<00:00,  6.61it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.51it/s]\n",
            "                 all        1150         606      0.0358       0.195      0.0171     0.00384\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/99     2.51G    0.0363  0.003244         0   0.03955         1       640: 100% 2300/2300 [05:48<00:00,  6.60it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.50it/s]\n",
            "                 all        1150         606       0.248       0.172       0.106      0.0303\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/99     2.51G   0.03604  0.003223         0   0.03927         1       640: 100% 2300/2300 [05:44<00:00,  6.69it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.51it/s]\n",
            "                 all        1150         606       0.149       0.271       0.085      0.0233\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/99     2.51G   0.03508  0.003261         0   0.03834         3       640: 100% 2300/2300 [05:43<00:00,  6.70it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.58it/s]\n",
            "                 all        1150         606      0.0293       0.417      0.0192     0.00542\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/99     2.51G   0.03538  0.003239         0   0.03862         3       640: 100% 2300/2300 [05:41<00:00,  6.73it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.58it/s]\n",
            "                 all        1150         606      0.0352       0.317      0.0231     0.00652\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/99     2.51G   0.03447  0.003264         0   0.03773         1       640: 100% 2300/2300 [05:45<00:00,  6.65it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.54it/s]\n",
            "                 all        1150         606      0.0313       0.515      0.0241     0.00775\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/99     2.51G   0.03411  0.003164         0   0.03728         0       640: 100% 2300/2300 [05:46<00:00,  6.64it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.60it/s]\n",
            "                 all        1150         606      0.0467       0.413      0.0328     0.00976\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/99     2.51G   0.03399   0.00318         0   0.03717         0       640: 100% 2300/2300 [05:45<00:00,  6.66it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.51it/s]\n",
            "                 all        1150         606      0.0423       0.502      0.0323      0.0109\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/99     2.51G    0.0332  0.003157         0   0.03635         5       640: 100% 2300/2300 [05:45<00:00,  6.66it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.52it/s]\n",
            "                 all        1150         606        0.13       0.421      0.0882       0.027\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/99     2.51G   0.03272  0.003107         0   0.03583         2       640: 100% 2300/2300 [05:42<00:00,  6.71it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.55it/s]\n",
            "                 all        1150         606       0.332       0.366         0.2      0.0807\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/99     2.51G   0.03249  0.003072         0   0.03557         0       640: 100% 2300/2300 [05:44<00:00,  6.68it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.54it/s]\n",
            "                 all        1150         606       0.136       0.373      0.0946      0.0328\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/99     2.51G   0.03252  0.003136         0   0.03565         3       640: 100% 2300/2300 [05:41<00:00,  6.74it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.58it/s]\n",
            "                 all        1150         606      0.0634       0.421      0.0435      0.0157\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/99     2.51G   0.03074  0.003058         0    0.0338         3       640: 100% 2300/2300 [05:40<00:00,  6.75it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.62it/s]\n",
            "                 all        1150         606       0.238        0.33       0.155      0.0566\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/99     2.51G   0.03057  0.003004         0   0.03358         2       640: 100% 2300/2300 [05:39<00:00,  6.78it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.62it/s]\n",
            "                 all        1150         606       0.304       0.422       0.206      0.0749\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/99     2.51G   0.03122  0.003093         0   0.03431         0       640: 100% 2300/2300 [05:43<00:00,  6.70it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.62it/s]\n",
            "                 all        1150         606        0.11       0.416      0.0821       0.028\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/99     2.51G   0.03069  0.003043         0   0.03374         1       640: 100% 2300/2300 [05:40<00:00,  6.76it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.61it/s]\n",
            "                 all        1150         606       0.278        0.33       0.215      0.0866\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/99     2.51G   0.03038  0.003027         0    0.0334         2       640: 100% 2300/2300 [05:44<00:00,  6.68it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.60it/s]\n",
            "                 all        1150         606       0.316       0.366       0.203      0.0784\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/99     2.51G   0.03091  0.003087         0     0.034         2       640: 100% 2300/2300 [05:40<00:00,  6.75it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.60it/s]\n",
            "                 all        1150         606       0.598       0.446       0.461       0.181\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     35/99     2.51G   0.03133  0.003075         0   0.03441         1       640: 100% 2300/2300 [05:42<00:00,  6.71it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.65it/s]\n",
            "                 all        1150         606       0.347       0.365       0.266       0.105\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     36/99     2.51G   0.03063  0.003101         0   0.03373         1       640: 100% 2300/2300 [05:43<00:00,  6.70it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.57it/s]\n",
            "                 all        1150         606        0.28       0.368       0.204      0.0821\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     37/99     2.51G   0.03008  0.003104         0   0.03319         3       640: 100% 2300/2300 [05:42<00:00,  6.71it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.57it/s]\n",
            "                 all        1150         606       0.172       0.437       0.131      0.0486\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     38/99     2.51G    0.0303  0.003069         0   0.03337         2       640: 100% 2300/2300 [05:41<00:00,  6.73it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.60it/s]\n",
            "                 all        1150         606       0.362       0.483       0.322       0.135\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     39/99     2.51G   0.02995  0.003059         0   0.03301         0       640: 100% 2300/2300 [05:40<00:00,  6.76it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.55it/s]\n",
            "                 all        1150         606       0.242       0.368        0.19      0.0735\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     40/99     2.51G   0.02952  0.003057         0   0.03258         0       640: 100% 2300/2300 [05:42<00:00,  6.72it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.51it/s]\n",
            "                 all        1150         606      0.0598       0.515       0.048      0.0173\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     41/99     2.51G   0.02963  0.003021         0   0.03265         7       640: 100% 2300/2300 [05:39<00:00,  6.78it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.62it/s]\n",
            "                 all        1150         606       0.593        0.45       0.447       0.188\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     42/99     2.51G   0.03021  0.003091         0    0.0333         1       640: 100% 2300/2300 [05:48<00:00,  6.61it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.61it/s]\n",
            "                 all        1150         606       0.327       0.455       0.234      0.0949\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     43/99     2.51G   0.02949  0.003011         0    0.0325         4       640: 100% 2300/2300 [05:41<00:00,  6.74it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.60it/s]\n",
            "                 all        1150         606       0.544       0.441       0.395       0.161\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     44/99     2.51G   0.02905  0.002962         0   0.03201         1       640: 100% 2300/2300 [05:36<00:00,  6.83it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.27it/s]\n",
            "                 all        1150         606       0.607       0.443       0.453       0.201\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     45/99     2.51G   0.03038  0.003099         0   0.03348         1       640: 100% 2300/2300 [05:43<00:00,  6.69it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.22it/s]\n",
            "                 all        1150         606       0.422       0.403       0.285       0.122\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     46/99     2.51G   0.02916  0.003055         0   0.03222         2       640: 100% 2300/2300 [05:40<00:00,  6.76it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.23it/s]\n",
            "                 all        1150         606       0.494       0.529       0.445       0.187\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     47/99     2.51G   0.02895   0.00298         0   0.03193         0       640: 100% 2300/2300 [05:43<00:00,  6.70it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.20it/s]\n",
            "                 all        1150         606       0.161       0.502       0.128      0.0526\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     48/99     2.51G   0.02898  0.003026         0   0.03201         0       640: 100% 2300/2300 [05:45<00:00,  6.66it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.45it/s]\n",
            "                 all        1150         606       0.401       0.507       0.328       0.143\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     49/99     2.51G   0.02937  0.003068         0   0.03244         2       640: 100% 2300/2300 [05:47<00:00,  6.61it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.54it/s]\n",
            "                 all        1150         606       0.566       0.452        0.43       0.192\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     50/99     2.51G    0.0283  0.002993         0   0.03129         3       640: 100% 2300/2300 [05:50<00:00,  6.56it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.50it/s]\n",
            "                 all        1150         606       0.568       0.558       0.542       0.254\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     51/99     2.51G   0.02833   0.00296         0   0.03129         2       640: 100% 2300/2300 [05:45<00:00,  6.66it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.59it/s]\n",
            "                 all        1150         606       0.592       0.576        0.55       0.247\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     52/99     2.51G   0.02803  0.002972         0     0.031         1       640: 100% 2300/2300 [05:41<00:00,  6.73it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.52it/s]\n",
            "                 all        1150         606       0.216       0.416       0.158      0.0673\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     53/99     2.51G   0.02839  0.003045         0   0.03143         5       640: 100% 2300/2300 [05:43<00:00,  6.70it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.58it/s]\n",
            "                 all        1150         606       0.615       0.493       0.503        0.23\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     54/99     2.51G    0.0277  0.003006         0   0.03071         1       640: 100% 2300/2300 [05:45<00:00,  6.65it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.56it/s]\n",
            "                 all        1150         606       0.625       0.533       0.544       0.259\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     55/99     2.51G   0.02793  0.003089         0   0.03102         2       640: 100% 2300/2300 [05:45<00:00,  6.65it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:22<00:00, 12.55it/s]\n",
            "                 all        1150         606       0.698       0.517       0.591       0.279\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     56/99     2.51G   0.02776  0.003004         0   0.03077         1       640: 100% 2300/2300 [05:51<00:00,  6.54it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 288/288 [00:23<00:00, 12.45it/s]\n",
            "                 all        1150         606       0.349        0.53       0.264       0.112\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     57/99     2.51G   0.02839  0.003072         0   0.03146         3       640:  37% 842/2300 [02:10<03:24,  7.14it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#初学習\n",
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "!python train_aux.py --workers 8 --batch-size 8 \\\n",
        "  --data data/mask.yaml \\\n",
        "  --cfg cfg/training/yolov7.yaml \\\n",
        "  --weights '/content/drive/MyDrive/yolov7/checkpoints' \\\n",
        "  --name '/content/drive/MyDrive/20221103yolov7-e6-mask' \\\n",
        "  --nosave \\\n",
        "  --hyp data/hyp.scratch.p6.yaml \\\n",
        "  --device 0 \\\n",
        "  --evolve"
      ],
      "metadata": {
        "id": "XBbgrPuOMdCn",
        "outputId": "2c1b89b5-ae97-46fa-ff33-79bd4c96ba28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov7\n",
            "YOLOR 🚀 v0.1-115-g072f76c torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7-e6.yaml', data='data/mask.yaml', device='0', entity=None, epochs=300, evolve=True, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.p6.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='evolve', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/evolve', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, v5_metric=False, weights='/content/drive/MyDrive/yolov7/checkpoints', workers=2, world_size=1)\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1, anchors=3\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1         0  models.common.ReOrg                     []                            \n",
            "  1                -1  1      8800  models.common.Conv                      [12, 80, 3, 1]                \n",
            "  2                -1  1     70880  models.common.DownC                     [80, 160, 1]                  \n",
            "  3                -1  1     10368  models.common.Conv                      [160, 64, 1, 1]               \n",
            "  4                -2  1     10368  models.common.Conv                      [160, 64, 1, 1]               \n",
            "  5                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 11[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           \n",
            " 12                -1  1     51520  models.common.Conv                      [320, 160, 1, 1]              \n",
            " 13                -1  1    282560  models.common.DownC                     [160, 320, 1]                 \n",
            " 14                -1  1     41216  models.common.Conv                      [320, 128, 1, 1]              \n",
            " 15                -2  1     41216  models.common.Conv                      [320, 128, 1, 1]              \n",
            " 16                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 17                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 24                -1  1   1128320  models.common.DownC                     [320, 640, 1]                 \n",
            " 25                -1  1    164352  models.common.Conv                      [640, 256, 1, 1]              \n",
            " 26                -2  1    164352  models.common.Conv                      [640, 256, 1, 1]              \n",
            " 27                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 29                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 30                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 31                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           \n",
            " 34                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 35                -1  1   3484800  models.common.DownC                     [640, 960, 1]                 \n",
            " 36                -1  1    369408  models.common.Conv                      [960, 384, 1, 1]              \n",
            " 37                -2  1    369408  models.common.Conv                      [960, 384, 1, 1]              \n",
            " 38                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
            " 39                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
            " 40                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
            " 41                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
            " 42                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
            " 43                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
            " 44[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           \n",
            " 45                -1  1   1845120  models.common.Conv                      [1920, 960, 1, 1]             \n",
            " 46                -1  1   7070080  models.common.DownC                     [960, 1280, 1]                \n",
            " 47                -1  1    656384  models.common.Conv                      [1280, 512, 1, 1]             \n",
            " 48                -2  1    656384  models.common.Conv                      [1280, 512, 1, 1]             \n",
            " 49                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
            " 50                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
            " 51                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
            " 52                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
            " 53                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
            " 54                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
            " 55[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1   3279360  models.common.Conv                      [2560, 1280, 1, 1]            \n",
            " 57                -1  1  11887360  models.common.SPPCSPC                   [1280, 640, 1]                \n",
            " 58                -1  1    308160  models.common.Conv                      [640, 480, 1, 1]              \n",
            " 59                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 60                45  1    461760  models.common.Conv                      [960, 480, 1, 1]              \n",
            " 61          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 62                -1  1    369408  models.common.Conv                      [960, 384, 1, 1]              \n",
            " 63                -2  1    369408  models.common.Conv                      [960, 384, 1, 1]              \n",
            " 64                -1  1    663936  models.common.Conv                      [384, 192, 3, 1]              \n",
            " 65                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            " 66                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            " 67                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            " 68                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            " 69                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            " 70[-1, -2, -3, -4, -5, -6, -7, -8]  1         0  models.common.Concat                    [1]                           \n",
            " 71                -1  1    922560  models.common.Conv                      [1920, 480, 1, 1]             \n",
            " 72                -1  1    154240  models.common.Conv                      [480, 320, 1, 1]              \n",
            " 73                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 74                34  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 75          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 76                -1  1    164352  models.common.Conv                      [640, 256, 1, 1]              \n",
            " 77                -2  1    164352  models.common.Conv                      [640, 256, 1, 1]              \n",
            " 78                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 80                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 81                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 82                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 83                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 84[-1, -2, -3, -4, -5, -6, -7, -8]  1         0  models.common.Concat                    [1]                           \n",
            " 85                -1  1    410240  models.common.Conv                      [1280, 320, 1, 1]             \n",
            " 86                -1  1     51520  models.common.Conv                      [320, 160, 1, 1]              \n",
            " 87                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 88                23  1     51520  models.common.Conv                      [320, 160, 1, 1]              \n",
            " 89          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 90                -1  1     41216  models.common.Conv                      [320, 128, 1, 1]              \n",
            " 91                -2  1     41216  models.common.Conv                      [320, 128, 1, 1]              \n",
            " 92                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 93                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 94                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 95                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 96                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 97                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 98[-1, -2, -3, -4, -5, -6, -7, -8]  1         0  models.common.Concat                    [1]                           \n",
            " 99                -1  1    102720  models.common.Conv                      [640, 160, 1, 1]              \n",
            "100                -1  1    282560  models.common.DownC                     [160, 320, 1]                 \n",
            "101          [-1, 85]  1         0  models.common.Concat                    [1]                           \n",
            "102                -1  1    164352  models.common.Conv                      [640, 256, 1, 1]              \n",
            "103                -2  1    164352  models.common.Conv                      [640, 256, 1, 1]              \n",
            "104                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            "105                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            "106                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            "107                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            "108                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            "109                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            "110[-1, -2, -3, -4, -5, -6, -7, -8]  1         0  models.common.Concat                    [1]                           \n",
            "111                -1  1    410240  models.common.Conv                      [1280, 320, 1, 1]             \n",
            "112                -1  1    872000  models.common.DownC                     [320, 480, 1]                 \n",
            "113          [-1, 71]  1         0  models.common.Concat                    [1]                           \n",
            "114                -1  1    369408  models.common.Conv                      [960, 384, 1, 1]              \n",
            "115                -2  1    369408  models.common.Conv                      [960, 384, 1, 1]              \n",
            "116                -1  1    663936  models.common.Conv                      [384, 192, 3, 1]              \n",
            "117                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            "118                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            "119                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            "120                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            "121                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            "122[-1, -2, -3, -4, -5, -6, -7, -8]  1         0  models.common.Concat                    [1]                           \n",
            "123                -1  1    922560  models.common.Conv                      [1920, 480, 1, 1]             \n",
            "124                -1  1   1768640  models.common.DownC                     [480, 640, 1]                 \n",
            "125          [-1, 57]  1         0  models.common.Concat                    [1]                           \n",
            "126                -1  1    656384  models.common.Conv                      [1280, 512, 1, 1]             \n",
            "127                -2  1    656384  models.common.Conv                      [1280, 512, 1, 1]             \n",
            "128                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            "129                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "130                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "131                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "132                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "133                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "134[-1, -2, -3, -4, -5, -6, -7, -8]  1         0  models.common.Concat                    [1]                           \n",
            "135                -1  1   1639680  models.common.Conv                      [2560, 640, 1, 1]             \n",
            "136                99  1    461440  models.common.Conv                      [160, 320, 3, 1]              \n",
            "137               111  1   1844480  models.common.Conv                      [320, 640, 3, 1]              \n",
            "138               123  1   4149120  models.common.Conv                      [480, 960, 3, 1]              \n",
            "139               135  1   7375360  models.common.Conv                      [640, 1280, 3, 1]             \n",
            "140                99  1    461440  models.common.Conv                      [160, 320, 3, 1]              \n",
            "141                85  1   1844480  models.common.Conv                      [320, 640, 3, 1]              \n",
            "142                71  1   4149120  models.common.Conv                      [480, 960, 3, 1]              \n",
            "143                57  1   7375360  models.common.Conv                      [640, 1280, 3, 1]             \n",
            "144[136, 137, 138, 139, 140, 141, 142, 143]  1    141136  models.yolo.IAuxDetect                  [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [320, 640, 960, 1280, 320, 640, 960, 1280]]\n",
            "Traceback (most recent call last):\n",
            "  File \"train_aux.py\", line 691, in <module>\n",
            "    results = train(hyp.copy(), opt, device)\n",
            "  File \"train_aux.py\", line 95, in train\n",
            "    model = Model(opt.cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n",
            "  File \"/content/drive/MyDrive/yolov7/models/yolo.py\", line 552, in __init__\n",
            "    m.stride = torch.tensor([s / x.shape[-2] for x in self.forward(torch.zeros(1, ch, s, s))[:4]])  # forward\n",
            "  File \"/content/drive/MyDrive/yolov7/models/yolo.py\", line 599, in forward\n",
            "    return self.forward_once(x, profile)  # single-scale inference, train\n",
            "  File \"/content/drive/MyDrive/yolov7/models/yolo.py\", line 625, in forward_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/yolov7/models/yolo.py\", line 344, in forward\n",
            "    x[i+self.nl] = self.m2[i](x[i+self.nl])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 197, in __getitem__\n",
            "    return self._modules[self._get_abs_string_index(idx)]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 187, in _get_abs_string_index\n",
            "    raise IndexError('index {} is out of range'.format(idx))\n",
            "IndexError: index 0 is out of range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#続きから学習\n",
        "\n",
        "\n",
        "*   [接続が切れたときに途中から学習を再開するには](https://tt-tsukumochi.com/archives/3288#vk-htags-258c208d-53e5-453d-acd8-c3e332224cfd)\n",
        "\n",
        "\n",
        "*   [エラー indices should be either on cpu or on the same device as the indexed tensor (cpu)の場合](https://github.com/WongKinYiu/yolov7/issues/1101)"
      ],
      "metadata": {
        "id": "c2zHqhK5nWSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JsKs9a0cQhHF",
        "outputId": "793bcbb7-8d25-410a-a529-1908dbe8c9b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#途中で切れた場合\n",
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "!python train.py --resume /content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite/weights/last.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CoDWdNpEFqk",
        "outputId": "09ac2174-9988-4db9-c304-7424cf3d7b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov7\n",
            "Resuming training from /content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite/weights/last.pt\n",
            "YOLOR 🚀 v0.1-116-g8c0bf3f torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=2, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='data/mite.yaml', device='0', entity=None, epochs=300, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=True, save_dir='/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=2, upload_dataset=False, v5_metric=False, weights='/content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite/weights/last.pt', workers=1, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     34156  models.yolo.IDetect                     [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "Model Summary: 415 layers, 37196556 parameters, 37196556 gradients\n",
            "\n",
            "Transferred 566/566 items from /content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite/weights/last.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'dataset/mite/train/labels.cache' images and labels... 6920 found, 0 missing, 3861 empty, 0 corrupted: 100% 6920/6920 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'dataset/mite/valid/labels.cache' images and labels... 790 found, 0 missing, 0 empty, 0 corrupted: 100% 790/790 [00:00<?, ?it/s]\n",
            "Image sizes 640 train, 640 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to /content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "   296/299     2.76G   0.01142   0.00164         0   0.01306         0       640: 100% 3460/3460 [37:33<00:00,  1.54it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/198 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 198/198 [00:23<00:00,  8.33it/s]\n",
            "                 all         790         926       0.957       0.961       0.987       0.796\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "   297/299     2.66G   0.01176  0.001719         0   0.01348         2       640: 100% 3460/3460 [09:23<00:00,  6.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 198/198 [00:17<00:00, 11.17it/s]\n",
            "                 all         790         926       0.957       0.961       0.987       0.797\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "   298/299     2.66G   0.01144  0.001673         0   0.01311         2       640: 100% 3460/3460 [09:24<00:00,  6.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 198/198 [00:16<00:00, 11.76it/s]\n",
            "                 all         790         926       0.961       0.959       0.987       0.798\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "   299/299     2.66G   0.01121  0.001657         0   0.01286         1       640: 100% 3460/3460 [09:18<00:00,  6.19it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 198/198 [00:17<00:00, 11.12it/s]\n",
            "                 all         790         926       0.961       0.959       0.987       0.799\n",
            "4 epochs completed in 1.123 hours.\n",
            "\n",
            "Optimizer stripped from /content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from /content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite/weights/best.pt, 74.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#続きから新しく学習\n",
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "!python train.py \\\n",
        "  --workers 1 \\\n",
        "  --batch-size 2 \\\n",
        "  --data data/mite.yaml \\\n",
        "  --cfg cfg/training/yolov7.yaml \\\n",
        "  --weights /content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite/weights/best.pt \\\n",
        "  --name '/content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite' \\\n",
        "  --hyp data/hyp.scratch.p5.yaml \\\n",
        "  --img 160 160 \\\n",
        "  --epochs 50 \\\n",
        "  --device 0 "
      ],
      "metadata": {
        "id": "pbLG3pDJ2x09",
        "outputId": "649906f9-f7fd-4387-9924-21ddd6e7b9c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov7\n",
            "YOLOR 🚀 v0.1-115-g072f76c torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=2, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/mite.yaml', device='0', entity=None, epochs=50, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[160, 160], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='/content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='/content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=2, upload_dataset=False, v5_metric=False, weights='/content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite/weights/best.pt', workers=1, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     34156  models.yolo.IDetect                     [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "Model Summary: 415 layers, 37196556 parameters, 37196556 gradients\n",
            "\n",
            "Transferred 564/566 items from /content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite/weights/best.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'dataset/mite/train/labels.cache' images and labels... 1242 found, 0 missing, 0 empty, 0 corrupted: 100% 1242/1242 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'dataset/mite/valid/labels.cache' images and labels... 310 found, 0 missing, 0 empty, 0 corrupted: 100% 310/310 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.51, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 160 train, 160 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to /content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite2\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/49     2.75G   0.02441  0.002455         0   0.02687         1       160: 100% 621/621 [01:14<00:00,  8.37it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/78 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:05<00:00, 14.86it/s]\n",
            "                 all         310         319      0.0287        0.31      0.0165     0.00394\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/49     2.69G   0.02468  0.002372         0   0.02705         0       160: 100% 621/621 [01:09<00:00,  8.98it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.52it/s]\n",
            "                 all         310         319      0.0289       0.376      0.0194     0.00441\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/49     2.69G   0.02498  0.002433         0   0.02742         2       160: 100% 621/621 [01:07<00:00,  9.27it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.45it/s]\n",
            "                 all         310         319      0.0229       0.191     0.00976     0.00205\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/49     2.69G   0.02405  0.002391         0   0.02644         8       160: 100% 621/621 [01:06<00:00,  9.34it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.17it/s]\n",
            "                 all         310         319      0.0271       0.298      0.0147     0.00327\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/49     2.69G   0.02521  0.002476         0   0.02769         7       160: 100% 621/621 [01:06<00:00,  9.39it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.89it/s]\n",
            "                 all         310         319      0.0274       0.357      0.0174     0.00417\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/49     2.69G   0.02361  0.002303         0   0.02592         3       160: 100% 621/621 [01:05<00:00,  9.53it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.81it/s]\n",
            "                 all         310         319       0.026       0.213      0.0134     0.00253\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/49     2.69G   0.02456  0.002262         0   0.02682         4       160: 100% 621/621 [01:07<00:00,  9.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.50it/s]\n",
            "                 all         310         319      0.0295        0.21      0.0152     0.00358\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/49     2.69G   0.02303  0.002369         0    0.0254         0       160: 100% 621/621 [01:05<00:00,  9.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.98it/s]\n",
            "                 all         310         319      0.0443       0.238      0.0257     0.00624\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/49     2.69G   0.02326  0.002267         0   0.02553         7       160: 100% 621/621 [01:07<00:00,  9.27it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 16.14it/s]\n",
            "                 all         310         319      0.0345       0.373      0.0239     0.00572\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/49     2.69G    0.0244  0.002314         0   0.02672         0       160: 100% 621/621 [01:05<00:00,  9.50it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.19it/s]\n",
            "                 all         310         319      0.0522       0.317      0.0341     0.00984\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/49     2.69G    0.0236  0.002387         0   0.02598         8       160: 100% 621/621 [01:05<00:00,  9.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.17it/s]\n",
            "                 all         310         319      0.0688       0.292      0.0384      0.0107\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/49     2.69G   0.02387   0.00227         0   0.02614         5       160: 100% 621/621 [01:07<00:00,  9.24it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.76it/s]\n",
            "                 all         310         319      0.0304       0.389      0.0207     0.00554\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/49     2.69G   0.02284  0.002289         0   0.02512         2       160: 100% 621/621 [01:04<00:00,  9.59it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.80it/s]\n",
            "                 all         310         319      0.0264       0.248      0.0173     0.00512\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/49     2.69G   0.02305    0.0023         0   0.02535         4       160: 100% 621/621 [01:05<00:00,  9.51it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.57it/s]\n",
            "                 all         310         319      0.0901       0.245      0.0504      0.0166\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/49     2.69G   0.02365  0.002365         0   0.02602         3       160: 100% 621/621 [01:08<00:00,  9.04it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.82it/s]\n",
            "                 all         310         319      0.0331       0.451      0.0244     0.00731\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/49     2.69G    0.0235  0.002341         0   0.02584         7       160: 100% 621/621 [01:06<00:00,  9.31it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.03it/s]\n",
            "                 all         310         319      0.0523       0.395      0.0343      0.0105\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/49     2.69G   0.02321  0.002347         0   0.02556         0       160: 100% 621/621 [01:07<00:00,  9.22it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.61it/s]\n",
            "                 all         310         319      0.0237       0.185     0.00886     0.00232\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/49     2.69G   0.02321  0.002362         0   0.02557         9       160: 100% 621/621 [01:05<00:00,  9.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.05it/s]\n",
            "                 all         310         319       0.301       0.325       0.224      0.0744\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/49     2.69G   0.02219  0.002331         0   0.02452         4       160: 100% 621/621 [01:07<00:00,  9.19it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.89it/s]\n",
            "                 all         310         319       0.228       0.298       0.148      0.0531\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/49     2.69G   0.02302  0.002341         0   0.02537         6       160: 100% 621/621 [01:07<00:00,  9.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.28it/s]\n",
            "                 all         310         319       0.372       0.332       0.269      0.0901\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/49     2.69G   0.02271  0.002245         0   0.02496         2       160: 100% 621/621 [01:06<00:00,  9.38it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.24it/s]\n",
            "                 all         310         319       0.291       0.351       0.176      0.0596\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/49     2.69G   0.02215  0.002235         0   0.02438         2       160: 100% 621/621 [01:05<00:00,  9.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.52it/s]\n",
            "                 all         310         319       0.261       0.367       0.176      0.0576\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/49     2.69G   0.02231  0.002237         0   0.02455         1       160: 100% 621/621 [01:07<00:00,  9.21it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.88it/s]\n",
            "                 all         310         319       0.143       0.352      0.0954      0.0291\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/49     2.69G    0.0222  0.002301         0    0.0245         8       160: 100% 621/621 [01:06<00:00,  9.34it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.91it/s]\n",
            "                 all         310         319       0.434       0.323       0.298       0.112\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/49     2.69G   0.02219  0.002293         0   0.02449        12       160: 100% 621/621 [01:08<00:00,  9.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.27it/s]\n",
            "                 all         310         319       0.188       0.338       0.108      0.0351\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/49     2.69G   0.02197  0.002353         0   0.02433         1       160: 100% 621/621 [01:07<00:00,  9.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.84it/s]\n",
            "                 all         310         319       0.269       0.382       0.172      0.0572\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/49     2.69G   0.02253  0.002269         0    0.0248         1       160: 100% 621/621 [01:05<00:00,  9.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.13it/s]\n",
            "                 all         310         319       0.259       0.401       0.163      0.0517\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/49     2.69G   0.02323  0.002346         0   0.02557         4       160: 100% 621/621 [01:06<00:00,  9.38it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.89it/s]\n",
            "                 all         310         319       0.164       0.389       0.109      0.0335\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/49     2.69G   0.02252  0.002258         0   0.02478         2       160: 100% 621/621 [01:04<00:00,  9.60it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.22it/s]\n",
            "                 all         310         319      0.0666       0.417      0.0487      0.0155\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/49     2.69G   0.02132  0.002277         0    0.0236         5       160: 100% 621/621 [01:05<00:00,  9.52it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.15it/s]\n",
            "                 all         310         319      0.0505       0.639      0.0412      0.0132\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/49     2.69G   0.02169  0.002227         0   0.02392         0       160: 100% 621/621 [01:05<00:00,  9.50it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.27it/s]\n",
            "                 all         310         319      0.0321        0.42      0.0209     0.00587\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/49     2.69G   0.02148   0.00222         0    0.0237         1       160: 100% 621/621 [01:04<00:00,  9.61it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.17it/s]\n",
            "                 all         310         319      0.0625        0.47      0.0501      0.0155\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/49     2.69G   0.02242  0.002346         0   0.02477         4       160: 100% 621/621 [01:04<00:00,  9.56it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.39it/s]\n",
            "                 all         310         319      0.0429       0.549      0.0348      0.0117\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/49     2.69G   0.02103  0.002352         0   0.02338         0       160: 100% 621/621 [01:06<00:00,  9.34it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.03it/s]\n",
            "                 all         310         319      0.0495       0.605      0.0406      0.0126\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/49     2.69G   0.02184  0.002337         0   0.02417         8       160: 100% 621/621 [01:05<00:00,  9.47it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.08it/s]\n",
            "                 all         310         319      0.0489       0.624      0.0412      0.0128\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     35/49     2.69G   0.02087  0.002395         0   0.02327         2       160: 100% 621/621 [01:06<00:00,  9.35it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.12it/s]\n",
            "                 all         310         319      0.0481        0.58      0.0397       0.012\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     36/49     2.69G   0.02142  0.002275         0   0.02369         4       160: 100% 621/621 [01:05<00:00,  9.55it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.67it/s]\n",
            "                 all         310         319      0.0496        0.62      0.0415      0.0137\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     37/49     2.69G    0.0211  0.002329         0   0.02343         4       160: 100% 621/621 [01:05<00:00,  9.51it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.39it/s]\n",
            "                 all         310         319      0.0455       0.627      0.0375      0.0124\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     38/49     2.69G   0.02095   0.00232         0   0.02327         3       160: 100% 621/621 [01:06<00:00,  9.38it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.18it/s]\n",
            "                 all         310         319      0.0456       0.605      0.0369      0.0125\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     39/49     2.69G   0.02165  0.002326         0   0.02398         5       160: 100% 621/621 [01:04<00:00,  9.66it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.30it/s]\n",
            "                 all         310         319      0.0453       0.608      0.0372      0.0125\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     40/49     2.69G   0.02151  0.002277         0   0.02378         8       160: 100% 621/621 [01:04<00:00,  9.65it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:03<00:00, 19.67it/s]\n",
            "                 all         310         319      0.0466       0.545      0.0378      0.0129\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     41/49     2.69G   0.02125  0.002326         0   0.02357         4       160: 100% 621/621 [01:05<00:00,  9.45it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 18.98it/s]\n",
            "                 all         310         319      0.0508       0.577      0.0421      0.0138\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     42/49     2.69G   0.02138  0.002464         0   0.02384         2       160: 100% 621/621 [01:05<00:00,  9.49it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.33it/s]\n",
            "                 all         310         319      0.0579        0.58      0.0482       0.016\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     43/49     2.69G   0.02177  0.002321         0   0.02409         5       160: 100% 621/621 [01:04<00:00,  9.63it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:03<00:00, 19.57it/s]\n",
            "                 all         310         319      0.0685       0.574       0.055      0.0186\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     44/49     2.69G   0.01964  0.002345         0   0.02199         6       160: 100% 621/621 [01:05<00:00,  9.49it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.47it/s]\n",
            "                 all         310         319      0.0492       0.633      0.0409      0.0146\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     45/49     2.69G   0.02009  0.002372         0   0.02247         5       160: 100% 621/621 [01:03<00:00,  9.74it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:03<00:00, 19.53it/s]\n",
            "                 all         310         319      0.0404       0.652      0.0337       0.011\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     46/49     2.69G   0.02048  0.002368         0   0.02285         0       160: 100% 621/621 [01:06<00:00,  9.33it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 15.80it/s]\n",
            "                 all         310         319      0.0444       0.627      0.0365       0.012\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     47/49     2.69G   0.02084  0.002406         0   0.02324         4       160: 100% 621/621 [01:05<00:00,  9.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 19.40it/s]\n",
            "                 all         310         319      0.0438       0.592      0.0359      0.0122\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     48/49     2.69G   0.02203  0.002331         0   0.02436         5       160: 100% 621/621 [01:05<00:00,  9.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:03<00:00, 19.55it/s]\n",
            "                 all         310         319      0.0475       0.571      0.0389      0.0129\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     49/49     2.69G   0.02037  0.002293         0   0.02266         4       160: 100% 621/621 [01:07<00:00,  9.20it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 78/78 [00:04<00:00, 17.65it/s]\n",
            "                 all         310         319      0.0691       0.473      0.0537       0.018\n",
            "50 epochs completed in 1.007 hours.\n",
            "\n",
            "Optimizer stripped from /content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite2/weights/last.pt, 74.7MB\n",
            "Optimizer stripped from /content/drive/MyDrive/20221125yolov7-50epoch-1552mages-160size-mite2/weights/best.pt, 74.7MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#学習結果で推論\n",
        "\n",
        "[出力オプションについて](https://qiita.com/hkwsdgea_ttt2/items/ba352f6e5ef6032b5dc9)\n",
        "[出力テキストの内容について](https://tt-tsukumochi.com/object_detection)\n",
        "*   「--save-txt」でテスト結果の座標を出力することができます。実行すると「runs/detect/exp〇/labels」にテキストファイルとして保存されます。「–save-txt」、「–save-conf」の引数を追加することで、テスト結果の座標とスコアを同時に出力することができます。"
      ],
      "metadata": {
        "id": "gSgJQuA_kuvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXnHvyngutCC",
        "outputId": "3334b2ba-db1e-4ffb-d5b8-875ade7dbbce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##画像をアップロード"
      ],
      "metadata": {
        "id": "EwvviqXk_nJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#画像をアップロードする場合\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/originals_test/'):\n",
        "    os.makedirs('/content/originals_test/')\n",
        "\n",
        "%cd '/content/originals_test/'\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "GCx-5xKf_l8v",
        "outputId": "72ea1ffa-d3e8-441f-d482-e39be4d661f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/originals_test\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0754acd1-7320-46ad-880e-98cfcc195646\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0754acd1-7320-46ad-880e-98cfcc195646\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IMG_20220310_110900_000.jpg to IMG_20220310_110900_000.jpg\n",
            "Saving IMG_20220310_111004_000.jpg to IMG_20220310_111004_000.jpg\n",
            "Saving IMG_20220310_111048_000.jpg to IMG_20220310_111048_000.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ドライブから直接コピー\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "from_file='/content/drive/MyDrive/バラ画像/20220310/mite/IMG_20220310_111711.jpg'\n",
        "\n",
        "file_renamed=os.path.basename(from_file[:-4])+'_180'+'.jpg'#向きの情報が必要\n",
        "\n",
        "if not os.path.exists('/content/originals_test/'):\n",
        "    os.makedirs('/content/originals_test/')\n",
        "\n",
        "shutil.copy(from_file, '/content/originals_test/'+file_renamed)"
      ],
      "metadata": {
        "id": "z46lNpiCxGbZ",
        "outputId": "b47caa9a-fcf5-43ce-8e07-33255cff137f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/originals_test/IMG_20220310_111711_180.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fastlabelから直接contentへダウンロード\n",
        "import shutil\n",
        "import os\n",
        "#fastrabel\n",
        "!wget -O \"/content/fastlabel.zip\" \"https://s3.ap-northeast-1.amazonaws.com/prod.fastlabel.app.exports/3efde406-abc7-4f3e-a3bd-905d3535a34d/a1881091-7309-419a-a791-a047028973a7/exports/20230113133925.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAYVHKCFVVMAV75HRC%2F20230113%2Fap-northeast-1%2Fs3%2Faws4_request&X-Amz-Date=20230113T044028Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHEaDmFwLW5vcnRoZWFzdC0xIkgwRgIhAL4bihE6tiIaGY2KUNTH0ZtN0XICswjxyD6Ic4xsKS%2FmAiEA256R3nCDIvaAJ1z1MmCUeKCJzO8qpC9XEM87kq7WoVkqhQQIyv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw1OTUzNDM4NDY3NjIiDJmRt%2FuyhoV9BmZ6ByrZA6YUAnnNLVp6tsSvmrgWubysSxdhi68r5s1BgTdaQlAO3q7y%2BkIMHHeM%2BtpftDcUXIi%2BYkwJBJ6aNgUMGDzfat6oi7X%2FCdVC8BLc3W0LZxjoI7l9BkNzgcS7Fsvnb%2F1MBBwo2uwsL87DGelwTzh56W31WtVGrif8QiNjOMQvtjYGJlS6wOzZ7okrCGSYRp9TuaUF38FDy7exSFJ%2BKj36y0FSAT%2Bs4N0oDCI7IdcluNhY%2BffZ7lJ5vMgK%2FIZ2niOkwGPygMjuj0JxLrz5eURtdEP%2Fx%2FjZmydgYBEJnfhqCX6mbkfwi3gYM9X6ECuQQ6RoT92Z86%2FQNpPtQILiUPQBq3XZBthlA8GhrHqspd0LBqVheA9YGcw%2BcOtV58Kbff1aFPEI4A9vuUKes8%2BV%2FNowCiFEFlyjH8qQANDyOEIoPeEMVXThVsfCRP2%2F5dkTAntccedNZ5qlnTr96pmLIp889pjN7xUz0mOhFqyKw4xsTEEVCWfNPxv1dsy0peZyZonYeiFS81U6zG3I6wuChuBMQxU3NON32Uog2YNOlWB85j9mZjwLgu%2FXO%2B%2ByV7KZFMDeflB3%2B0Ucz5inexletnKgVNbLWqqUo5EJ5Sa4rWxLPcukfi9ZiSMBw6T3MM7Rgp4GOqQByVO0J752VtzdAHJutV31b2hkuNnhVOgLrbdKyI44b5Z9xqkK7SdjCISWy%2Fpeq35bEnHoMrJVOxryBXxHEApPaPmXuCtkLGSzV0qVo2khC2sQJgxuIDK0SsDvnUS4%2FlYIglEL%2B296CAsxYkQzcvVar8GbUUUSr%2Bp7N9kuAu77VKL8xUr0HbIiFVLbe8kDqXLdXTkueAquKckS6gV691rKE0%2B7%2BIY%3D&X-Amz-Signature=a8349c07bedf413b03384941c441ca7af39cbc88965e348758cf6d40bd813a69&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22not-training-boundhingbox-mite_20230113133925.zip%22\"\n",
        "!wget -O \"/content/fastlabel2.zip\" \"https://s3.ap-northeast-1.amazonaws.com/prod.fastlabel.app.exports/3efde406-abc7-4f3e-a3bd-905d3535a34d/a1881091-7309-419a-a791-a047028973a7/exports/20230113133920.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAYVHKCFVVOVWEOTNI%2F20230113%2Fap-northeast-1%2Fs3%2Faws4_request&X-Amz-Date=20230113T044027Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHEaDmFwLW5vcnRoZWFzdC0xIkgwRgIhALHx2TDj7s1ECDyQPtvm6liXBXet9mp3jz4gh9rGcjSUAiEAw0WTLnEUaQVUjUXMsCBgDIfRt9Ao5dLk1F%2BKgfExC9UqhQQIy%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw1OTUzNDM4NDY3NjIiDLUMScrsZpF11pJXsSrZA4v9o4P%2BRLfUTW%2BuJodCuILzkBb00j7BwEj%2FjIvgeeT3mIdTrmSOuz4Q1ewp4WPV%2F5GChfZzqxImCEJ7A6RN4XrXhTRf3NyK0JCnOHoYyTUC490gGM5R2X9gYQsDVwG7Sn9%2Bn%2FHXwTrxTDDCPLOGhwriddLUQgiJqQ9XBW6osPsM9ccqB56Eu0enGZa7A6akLIEBKcIRSRJZeQjjkBj5NrNpuWXKhBnMHO07tj8Ljh9ezwJp68%2FrdMwOXwlyxv%2FCsor6rZO6PtX0JizkN%2BIutB1kmaCnxK41FdRclFWEJWGPpGVgSjIWYp74bfHs1Avf0G8kNsPM%2FkyehIPwIaS7Xbeyie5qenfFAFWw9YQHNvM9WX9%2B5xhqtPQcYUOg4Wr1G%2BSlsItcEazxmHQERvNuLUOU2VigrvcEKNBnbZH7JoRVQTtPRgFECzfQQkPOi%2FU9GsAYpQu%2FqGVHwAPJLNVoBfnEe1Mg%2BKrAu0%2FL35OIS2fP46u75gCXLw1%2FBhzOm1umBlzFDUAsZQ3J5DR9mShhvHig%2BB8TCdMVjylaS%2Fh6hUCeP0%2FXvKRYuD4aW3J1m1EimyJzBy8Qi7C1hXgkepa9cNDShV%2BTF9phMWeVFY8SfA9X90jHF%2FSYMb%2BnMPLpgp4GOqQBZ5znXhjTPM14j53IobZ%2B4b3VHMs5dZZE%2Ff5Ha5ZX6k%2Bt%2FW9M5wu0Iwos9%2FYUlDqOF8HiPvdWiTlcdlpqih8EsQ56lZqwBjrKGBQxLiqefBfIER6HrpvBaW68hnEfCR9WZiFMWN3NYhz4uOL2RzYDHnSpOls%2BfqmKpmC98xTBrlXelX2208ubwFTa1YEHrCsP%2F9mLMQ%2FcEv9Uu49DULY9bhF%2FKtA%3D&X-Amz-Signature=9f78d89971c0e2bdff97cd56370cd9ac7b6ab14b6611660048c9df9379ad47f7&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22not-training-boundhingbox-mite_20230113133920.zip%22\"\n",
        "shutil.unpack_archive('/content/fastlabel.zip', '/content')\n",
        "shutil.unpack_archive('/content/fastlabel2.zip', '/content')\n",
        "\n",
        "os.rename('/content/originals', '/content/originals_test')\n",
        "shutil.move('/content/mask_direct_color/instance_segmentations','/content/instance_segmentations')\n",
        "shutil.rmtree('/content/mask_direct_color')\n",
        "shutil.move('/content/yolo/annotations','/content/annotations')\n",
        "\n",
        "if os.path.exists('/content/csv'):\n",
        "  shutil.rmtree('/content/csv')\n",
        "if os.path.exists('/content/yolo'):\n",
        "  shutil.rmtree('/content/yolo')\n",
        "\n",
        "os.remove('/content/fastlabel.zip')\n",
        "os.remove('/content/fastlabel2.zip')  "
      ],
      "metadata": {
        "id": "ONDQAagBUD4E",
        "outputId": "b4596188-e9b3-4cbd-c5f9-2aee61059f96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-13 05:21:54--  https://s3.ap-northeast-1.amazonaws.com/prod.fastlabel.app.exports/3efde406-abc7-4f3e-a3bd-905d3535a34d/a1881091-7309-419a-a791-a047028973a7/exports/20230113133925.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAYVHKCFVVMAV75HRC%2F20230113%2Fap-northeast-1%2Fs3%2Faws4_request&X-Amz-Date=20230113T044028Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHEaDmFwLW5vcnRoZWFzdC0xIkgwRgIhAL4bihE6tiIaGY2KUNTH0ZtN0XICswjxyD6Ic4xsKS%2FmAiEA256R3nCDIvaAJ1z1MmCUeKCJzO8qpC9XEM87kq7WoVkqhQQIyv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw1OTUzNDM4NDY3NjIiDJmRt%2FuyhoV9BmZ6ByrZA6YUAnnNLVp6tsSvmrgWubysSxdhi68r5s1BgTdaQlAO3q7y%2BkIMHHeM%2BtpftDcUXIi%2BYkwJBJ6aNgUMGDzfat6oi7X%2FCdVC8BLc3W0LZxjoI7l9BkNzgcS7Fsvnb%2F1MBBwo2uwsL87DGelwTzh56W31WtVGrif8QiNjOMQvtjYGJlS6wOzZ7okrCGSYRp9TuaUF38FDy7exSFJ%2BKj36y0FSAT%2Bs4N0oDCI7IdcluNhY%2BffZ7lJ5vMgK%2FIZ2niOkwGPygMjuj0JxLrz5eURtdEP%2Fx%2FjZmydgYBEJnfhqCX6mbkfwi3gYM9X6ECuQQ6RoT92Z86%2FQNpPtQILiUPQBq3XZBthlA8GhrHqspd0LBqVheA9YGcw%2BcOtV58Kbff1aFPEI4A9vuUKes8%2BV%2FNowCiFEFlyjH8qQANDyOEIoPeEMVXThVsfCRP2%2F5dkTAntccedNZ5qlnTr96pmLIp889pjN7xUz0mOhFqyKw4xsTEEVCWfNPxv1dsy0peZyZonYeiFS81U6zG3I6wuChuBMQxU3NON32Uog2YNOlWB85j9mZjwLgu%2FXO%2B%2ByV7KZFMDeflB3%2B0Ucz5inexletnKgVNbLWqqUo5EJ5Sa4rWxLPcukfi9ZiSMBw6T3MM7Rgp4GOqQByVO0J752VtzdAHJutV31b2hkuNnhVOgLrbdKyI44b5Z9xqkK7SdjCISWy%2Fpeq35bEnHoMrJVOxryBXxHEApPaPmXuCtkLGSzV0qVo2khC2sQJgxuIDK0SsDvnUS4%2FlYIglEL%2B296CAsxYkQzcvVar8GbUUUSr%2Bp7N9kuAu77VKL8xUr0HbIiFVLbe8kDqXLdXTkueAquKckS6gV691rKE0%2B7%2BIY%3D&X-Amz-Signature=a8349c07bedf413b03384941c441ca7af39cbc88965e348758cf6d40bd813a69&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22not-training-boundhingbox-mite_20230113133925.zip%22\n",
            "Resolving s3.ap-northeast-1.amazonaws.com (s3.ap-northeast-1.amazonaws.com)... 52.219.1.98, 52.219.197.48, 52.219.16.54, ...\n",
            "Connecting to s3.ap-northeast-1.amazonaws.com (s3.ap-northeast-1.amazonaws.com)|52.219.1.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 62511 (61K) [binary/octet-stream]\n",
            "Saving to: ‘/content/fastlabel.zip’\n",
            "\n",
            "/content/fastlabel. 100%[===================>]  61.05K   334KB/s    in 0.2s    \n",
            "\n",
            "2023-01-13 05:21:54 (334 KB/s) - ‘/content/fastlabel.zip’ saved [62511/62511]\n",
            "\n",
            "--2023-01-13 05:21:54--  https://s3.ap-northeast-1.amazonaws.com/prod.fastlabel.app.exports/3efde406-abc7-4f3e-a3bd-905d3535a34d/a1881091-7309-419a-a791-a047028973a7/exports/20230113133920.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAYVHKCFVVOVWEOTNI%2F20230113%2Fap-northeast-1%2Fs3%2Faws4_request&X-Amz-Date=20230113T044027Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHEaDmFwLW5vcnRoZWFzdC0xIkgwRgIhALHx2TDj7s1ECDyQPtvm6liXBXet9mp3jz4gh9rGcjSUAiEAw0WTLnEUaQVUjUXMsCBgDIfRt9Ao5dLk1F%2BKgfExC9UqhQQIy%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw1OTUzNDM4NDY3NjIiDLUMScrsZpF11pJXsSrZA4v9o4P%2BRLfUTW%2BuJodCuILzkBb00j7BwEj%2FjIvgeeT3mIdTrmSOuz4Q1ewp4WPV%2F5GChfZzqxImCEJ7A6RN4XrXhTRf3NyK0JCnOHoYyTUC490gGM5R2X9gYQsDVwG7Sn9%2Bn%2FHXwTrxTDDCPLOGhwriddLUQgiJqQ9XBW6osPsM9ccqB56Eu0enGZa7A6akLIEBKcIRSRJZeQjjkBj5NrNpuWXKhBnMHO07tj8Ljh9ezwJp68%2FrdMwOXwlyxv%2FCsor6rZO6PtX0JizkN%2BIutB1kmaCnxK41FdRclFWEJWGPpGVgSjIWYp74bfHs1Avf0G8kNsPM%2FkyehIPwIaS7Xbeyie5qenfFAFWw9YQHNvM9WX9%2B5xhqtPQcYUOg4Wr1G%2BSlsItcEazxmHQERvNuLUOU2VigrvcEKNBnbZH7JoRVQTtPRgFECzfQQkPOi%2FU9GsAYpQu%2FqGVHwAPJLNVoBfnEe1Mg%2BKrAu0%2FL35OIS2fP46u75gCXLw1%2FBhzOm1umBlzFDUAsZQ3J5DR9mShhvHig%2BB8TCdMVjylaS%2Fh6hUCeP0%2FXvKRYuD4aW3J1m1EimyJzBy8Qi7C1hXgkepa9cNDShV%2BTF9phMWeVFY8SfA9X90jHF%2FSYMb%2BnMPLpgp4GOqQBZ5znXhjTPM14j53IobZ%2B4b3VHMs5dZZE%2Ff5Ha5ZX6k%2Bt%2FW9M5wu0Iwos9%2FYUlDqOF8HiPvdWiTlcdlpqih8EsQ56lZqwBjrKGBQxLiqefBfIER6HrpvBaW68hnEfCR9WZiFMWN3NYhz4uOL2RzYDHnSpOls%2BfqmKpmC98xTBrlXelX2208ubwFTa1YEHrCsP%2F9mLMQ%2FcEv9Uu49DULY9bhF%2FKtA%3D&X-Amz-Signature=9f78d89971c0e2bdff97cd56370cd9ac7b6ab14b6611660048c9df9379ad47f7&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22not-training-boundhingbox-mite_20230113133920.zip%22\n",
            "Resolving s3.ap-northeast-1.amazonaws.com (s3.ap-northeast-1.amazonaws.com)... 52.219.1.98, 52.219.197.48, 52.219.16.54, ...\n",
            "Connecting to s3.ap-northeast-1.amazonaws.com (s3.ap-northeast-1.amazonaws.com)|52.219.1.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8882899 (8.5M) [binary/octet-stream]\n",
            "Saving to: ‘/content/fastlabel2.zip’\n",
            "\n",
            "/content/fastlabel2 100%[===================>]   8.47M  9.90MB/s    in 0.9s    \n",
            "\n",
            "2023-01-13 05:21:56 (9.90 MB/s) - ‘/content/fastlabel2.zip’ saved [8882899/8882899]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##★背景処理（やってもやらんくてもよい）"
      ],
      "metadata": {
        "id": "nxHWmDL6Y0Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pillow"
      ],
      "metadata": {
        "id": "6yZAutDCf54N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rembg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5qRejbZY7Y8",
        "outputId": "5859bf47-b65a-484d-fe5e-01b678df5a8a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rembg\n",
            "  Downloading rembg-2.0.30-py3-none-any.whl (13 kB)\n",
            "Collecting numpy~=1.23.5\n",
            "  Downloading numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp~=3.8.1 in /usr/local/lib/python3.8/dist-packages (from rembg) (3.8.3)\n",
            "Collecting click~=8.1.3\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pooch~=1.6.0 in /usr/local/lib/python3.8/dist-packages (from rembg) (1.6.0)\n",
            "Collecting opencv-python-headless~=4.6.0.66\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchdog~=2.1.9\n",
            "  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart~=0.0.5\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime~=1.13.1\n",
            "  Downloading onnxruntime-1.13.1-cp38-cp38-manylinux_2_27_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filetype~=1.2.0\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting scipy~=1.9.3\n",
            "  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow~=9.3.0\n",
            "  Downloading Pillow-9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-image~=0.19.3\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asyncer~=0.0.2\n",
            "  Downloading asyncer-0.0.2-py3-none-any.whl (8.3 kB)\n",
            "Collecting fastapi~=0.87.0\n",
            "  Downloading fastapi-0.87.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imagehash~=4.3.1\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymatting~=1.1.8\n",
            "  Downloading PyMatting-1.1.8-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn~=0.20.0\n",
            "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm~=4.64.1 in /usr/local/lib/python3.8/dist-packages (from rembg) (4.64.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp~=3.8.1->rembg) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp~=3.8.1->rembg) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp~=3.8.1->rembg) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp~=3.8.1->rembg) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp~=3.8.1->rembg) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp~=3.8.1->rembg) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp~=3.8.1->rembg) (22.2.0)\n",
            "Collecting anyio<4.0.0,>=3.4.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from fastapi~=0.87.0->rembg) (1.10.4)\n",
            "Collecting starlette==0.21.0\n",
            "  Downloading starlette-0.21.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from starlette==0.21.0->fastapi~=0.87.0->rembg) (4.4.0)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.8/dist-packages (from imagehash~=4.3.1->rembg) (1.4.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime~=1.13.1->rembg) (1.12)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime~=1.13.1->rembg) (3.19.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime~=1.13.1->rembg) (1.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime~=1.13.1->rembg) (21.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch~=1.6.0->rembg) (2.25.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch~=1.6.0->rembg) (1.4.4)\n",
            "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.8/dist-packages (from pymatting~=1.1.8->rembg) (0.56.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from python-multipart~=0.0.5->rembg) (1.15.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image~=0.19.3->rembg) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image~=0.19.3->rembg) (2022.10.10)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image~=0.19.3->rembg) (2.8.8)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio<4.0.0,>=3.4.0->asyncer~=0.0.2->rembg) (2.10)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba!=0.49.0->pymatting~=1.1.8->rembg) (6.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba!=0.49.0->pymatting~=1.1.8->rembg) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba!=0.49.0->pymatting~=1.1.8->rembg) (0.39.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->onnxruntime~=1.13.1->rembg) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch~=1.6.0->rembg) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch~=1.6.0->rembg) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch~=1.6.0->rembg) (4.0.0)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime~=1.13.1->rembg) (1.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba!=0.49.0->pymatting~=1.1.8->rembg) (3.11.0)\n",
            "Building wheels for collected packages: python-multipart\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=5b3bc30b38a9b3860b976f8482b992ccfc646e5556a77e1dd9412a0baa83c2d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/fc/1c/cf980e6413d3ee8e70cd8f39e2366b0f487e3e221aeb452eb0\n",
            "Successfully built python-multipart\n",
            "Installing collected packages: filetype, watchdog, sniffio, python-multipart, pillow, numpy, humanfriendly, h11, click, uvicorn, scipy, opencv-python-headless, coloredlogs, anyio, starlette, scikit-image, pymatting, onnxruntime, imagehash, asyncer, fastapi, rembg\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.7.0.68\n",
            "    Uninstalling opencv-python-headless-4.7.0.68:\n",
            "      Successfully uninstalled opencv-python-headless-4.7.0.68\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anyio-3.6.2 asyncer-0.0.2 click-8.1.3 coloredlogs-15.0.1 fastapi-0.87.0 filetype-1.2.0 h11-0.14.0 humanfriendly-10.0 imagehash-4.3.1 numpy-1.23.5 onnxruntime-1.13.1 opencv-python-headless-4.6.0.66 pillow-9.3.0 pymatting-1.1.8 python-multipart-0.0.5 rembg-2.0.30 scikit-image-0.19.3 scipy-1.9.3 sniffio-1.3.0 starlette-0.21.0 uvicorn-0.20.0 watchdog-2.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exit()"
      ],
      "metadata": {
        "id": "aycnd5WzkZQ2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rembg import remove\n",
        "import cv2\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/originals/'):\n",
        "  shutil.copytree('/content/originals_test/','/content/originals/')\n",
        "  shutil.rmtree('/content/originals_test/')\n",
        "  os.mkdir('/content/originals_test/')\n",
        "\n",
        "\n",
        "read_folda_name='/content/originals/'\n",
        "read_folda = os.listdir(read_folda_name)\n",
        "\n",
        "for imgname in read_folda:\n",
        "  input = cv2.imread('/content/originals/'+imgname)\n",
        "  output = remove(input)\n",
        "  cv2.imwrite('/content/originals_test/'+imgname, output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkJxwnZ_ZcZ-",
        "outputId": "8c73e9c7-9e54-4a51-c6c9-6959cb8ba836"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/root/.u2net/u2net.onnx'.\n",
            "100%|███████████████████████████████████████| 176M/176M [00:00<00:00, 55.6GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##画像分割"
      ],
      "metadata": {
        "id": "sVWRvD5CGquV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#画像分割数\n",
        "split_x=20\n",
        "split_y=20\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "if not os.path.exists('/content/originals_test'):\n",
        "  shutil.unpack_archive('/content/originals_test.zip', '/content')\n",
        "\n",
        "#'NoneType' object is not subscriptableといわれるので先にipynb_checkpointsを消す\n",
        "#!rm -rf `find -type d -name .ipynb_checkpoints`\n",
        "\n",
        "#画像の読み込み\n",
        "read_files_name='/content/originals_test/'\n",
        "read_files = os.listdir(read_files_name)\n",
        "\n",
        "for file_name in read_files:\n",
        "  fname = read_files_name+file_name #画像ファイル名\n",
        "  foldaname=fname[9:]\n",
        "\n",
        "\n",
        "  #img = np.array(Image.open(fname))  \n",
        "  img=cv2.imread(fname,cv2.IMREAD_COLOR)\n",
        "  #画像分割先のフォルダを作成\n",
        "  if not os.path.exists('/content/split_pic_original/'+file_name[:-4]):\n",
        "    os.makedirs('/content/split_pic_original/'+file_name[:-4])\n",
        "\n",
        "\n",
        "  #画像の読み込み\n",
        "  h,w=img.shape[:2]\n",
        "\n",
        "  #画像の分割処理\n",
        "  cx=0\n",
        "  cy=0\n",
        "  for j in range(split_x):\n",
        "      for i in range(split_y):\n",
        "          split_pic=img[cy:cy+int(h/split_y),cx:cx+int(w/split_x),:]          \n",
        "          cv2.imwrite(\"/content/split_pic_original/\"+file_name[:-4]+\"/\"+file_name[:-4]+'_y'+str('{0:02d}'.format(int(i)))+'_x'+str('{0:02d}'.format(int(j)))+foldaname[-4:],split_pic)\n",
        "          cy=cy+int(h/split_y)\n",
        "      cy=0\n",
        "      cx=cx+int(w/split_x)\n",
        "\n",
        "  #分割する線を描いた画像を出力\n",
        "  y_step=int(h/split_y) #縦の分割間隔\n",
        "  x_step=int(w/split_x) #横の分割間隔\n",
        "\n",
        "  #オブジェクトimgのshapeメソッドの1つ目の戻り値(画像の高さ)をimg_yに、2つ目の戻り値(画像の幅)をimg_xに\n",
        "  #img_y,img_x=img.size\n",
        "  img_y,img_x=img.shape[:2]  \n",
        "\n",
        "  #横線を引く：y_stepからimg_yの手前までy_stepおきに白い(BGRすべて255)横線を引く\n",
        "  img[y_step:img_y:y_step, :, :] = 0\n",
        "  #縦線を引く：x_stepからimg_xの手前までx_stepおきに白い(BGRすべて255)縦線を引く\n",
        "  img[:, x_step:img_x:x_step, :] = 0\n",
        "\n",
        "  cv2.imwrite(\"/content/split_pic_original/\"+file_name[:-4]+\"grid\"+foldaname[-4:],img) #ファイル名'grid.png'でimgを保存\n",
        "#★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "import glob\n",
        "if not os.path.exists('/content/originals_grid/'):\n",
        "    os.makedirs('/content/originals_grid/')\n",
        "\n",
        "originals=('/content/split_pic_original/*.jpg')\n",
        "read_files = glob.glob(originals)\n",
        "\n",
        "for i in read_files:\n",
        "  shutil.copy(i, '/content/originals_grid/')\n",
        "#★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "#画像サイズを640にアップサンプリング\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/originals_upsamples/'):\n",
        "  os.makedirs('/content/originals_upsamples/')\n",
        "\n",
        "read_folda_name='/content/split_pic_original/'\n",
        "read_folda = os.listdir(read_folda_name)\n",
        "\n",
        "for image_folda_name in read_folda:\n",
        "  originals=('/content/split_pic_original/'+image_folda_name+'/*')\n",
        "  read_files = glob.glob(originals)\n",
        "\n",
        "  for imgpass in read_files:\n",
        "    # 読み込む画像を選択\n",
        "    img = cv2.imread(imgpass)\n",
        "    h,w=img.shape[:2]\n",
        "    # サイズ設定｜cv2では(幅、高さ）の順で数値を設定\n",
        "    size = (w*5,h*5) \n",
        "    # 画像拡大・縮小 オプションで拡大計算式変更可能\n",
        "    img_inter_area  = cv2.resize(img,size,interpolation = cv2.INTER_LINEAR) \n",
        "    #保存\n",
        "    cv2.imwrite('/content/originals_upsamples/'+os.path.split(imgpass)[1], img_inter_area)"
      ],
      "metadata": {
        "id": "MiIFeBJGEuGH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##検出"
      ],
      "metadata": {
        "id": "14TlhQgHM24p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#最適confは0.42\n",
        "if os.path.exists('/content/detect_output'):\n",
        "  shutil.rmtree('/content/detect_output')\n",
        "\n",
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "!python detect.py \\\n",
        "  --weights /content/drive/MyDrive/weights_box/best.pt \\\n",
        "  --conf 0.42 \\\n",
        "  --source '/content/originals_upsamples' \\\n",
        "  --name '/content/detect_output' \\\n",
        "  --save-txt \\\n",
        "  --save-conf"
      ],
      "metadata": {
        "id": "v9jTrC7HmFii",
        "outputId": "0d981c01-50ca-43ac-b632-e74bab0c66db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov7\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.42, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='/content/detect_output', no_trace=False, nosave=False, project='runs/detect', save_conf=True, save_txt=True, source='/content/originals_upsamples', update=False, view_img=False, weights=['/content/drive/MyDrive/weights_box/best.pt'])\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Done. (142.508s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##画像にアノテーションを描画"
      ],
      "metadata": {
        "id": "pVB9DbPqwiu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "if os.path.exists('/content/originals_test_annotations/'):\n",
        "  shutil.rmtree('/content/originals_test_annotations/')\n",
        "if os.path.exists('/content/originals_test_annotations_yolotype/'):\n",
        "  shutil.rmtree('/content/originals_test_annotations_yolotype/')\n",
        "\n",
        "yolo_pass=\"/content/originals_test_annotations/\"\n",
        "if not os.path.exists(yolo_pass):\n",
        "    os.mkdir(yolo_pass)\n",
        "\n",
        "yolo_pass_yolotype=\"/content/originals_test_annotations_yolotype/\"\n",
        "if not os.path.exists(yolo_pass_yolotype):\n",
        "    os.mkdir(yolo_pass_yolotype)\n",
        "\n",
        "read_files_name_bbox='/content/detect_output/labels/*'\n",
        "read_files_bbox = glob.glob(read_files_name_bbox)\n",
        "\n",
        "\n",
        "for txt_name in read_files_bbox:\n",
        "  txt_file = pd.read_csv(txt_name,header=None, sep=\" \")\n",
        "  for i in range(len(txt_file[0])):\n",
        "    im = Image.open('/content/detect_output/'+txt_name[30:-4]+\".jpg\")\n",
        "    im_original = Image.open('/content/originals_test/'+txt_name[30:-12]+\".jpg\")\n",
        "    image_width,image_height=np.array(im).shape[:2]\n",
        "    image_width_original,image_height_original=np.array(im_original).shape[:2]\n",
        "    name=txt_name[30:]\n",
        "    y_number=int(txt_name[-10:-8])\n",
        "    x_number=int(txt_name[-6:-4])\n",
        "\n",
        "    x_center=float(txt_file[1][i])*image_height\n",
        "    y_center=float(txt_file[2][i])*image_width\n",
        "    width=float(txt_file[3][i])*image_height\n",
        "    height=float(txt_file[4][i])*image_width\n",
        "\n",
        "    x1=(x_center-height/2)\n",
        "    y1=(y_center-width/2)\n",
        "    x2=(x_center+height/2)\n",
        "    y2=(y_center+width/2)\n",
        "    #x1=(x_center-width/2)\n",
        "    #y1=(y_center-height/2)\n",
        "    #x2=(x_center+width/2)\n",
        "    #y2=(y_center+height/2)\n",
        "\n",
        "    x_min_original=x1+image_height*x_number\n",
        "    y_min_original=y1+image_width*y_number\n",
        "    x_max_original=x2+image_height*x_number\n",
        "    y_max_original=y2+image_width*y_number\n",
        "\n",
        "\n",
        "    absolute_x_original=x_min_original+(x_max_original-x_min_original)/2\n",
        "    absolute_y_original=y_min_original+(y_max_original-y_min_original)/2\n",
        "    absolute_width_original=x_max_original-x_min_original\n",
        "    absolute_height_original=y_max_original-y_min_original\n",
        "\n",
        "    col1=\"0\"\n",
        "    col2=str(absolute_x_original / (image_height_original*5))\n",
        "    col3=str(absolute_y_original / (image_width_original*5))\n",
        "    col4=str(absolute_height_original / (image_height_original*5))\n",
        "    col5=str(absolute_width_original / (image_width_original*5))\n",
        "\n",
        "\n",
        "    col6=str(txt_file[5][i])\n",
        "    col7=str(txt_name[30:-4])\n",
        "\n",
        "    with open(yolo_pass+txt_name[30:-12]+'.txt', 'a') as f:\n",
        "        rote=col1+' '+col2+' '+col3+' '+col4+' '+col5+' '+col6+' '+col7+'\\n'\n",
        "        f.write(rote)\n",
        "    with open(yolo_pass_yolotype+txt_name[30:-12]+'.txt', 'a') as f:\n",
        "        rote=col1+' '+col2+' '+col3+' '+col4+' '+col5+'\\n'\n",
        "        f.write(rote)\n",
        "#★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "folda_pass=\"/content/originals_test_annotations_drawing\"\n",
        "if not os.path.exists(folda_pass):\n",
        "    os.mkdir(folda_pass)\n",
        "\n",
        "read_files_name_bbox='/content/originals_test_annotations/*'\n",
        "read_files_bbox = glob.glob(read_files_name_bbox)\n",
        "\n",
        "for txt_name in read_files_bbox:\n",
        "  im_original = Image.open('/content/originals_test/'+txt_name[36:-4]+\".jpg\")\n",
        "  image_width,image_height=np.array(im_original).shape[:2]\n",
        "\n",
        "  txt_file = pd.read_csv('/content/originals_test_annotations/'+txt_name[36:-4]+\".txt\",header=None, sep=\" \")\n",
        "  for annotation in range(len(txt_file)):\n",
        "\n",
        "    x_center=float(txt_file[1][annotation])*image_height\n",
        "    y_center=float(txt_file[2][annotation])*image_width\n",
        "    width=float(txt_file[3][annotation])*image_height\n",
        "    height=float(txt_file[4][annotation])*image_width\n",
        "    #width=float(txt_file[3][annotation])*image_width\n",
        "    #height=float(txt_file[4][annotation])*image_height\n",
        "\n",
        "    #x1=int(x_center-height/2)\n",
        "    #y1=int(y_center-width/2)\n",
        "    #x2=int(x_center+height/2)\n",
        "    #y2=int(y_center+width/2)\n",
        "    x1=(x_center-width/2)\n",
        "    y1=(y_center-height/2)\n",
        "    x2=(x_center+width/2)\n",
        "    y2=(y_center+height/2)\n",
        "\n",
        "    #print(txt_name[36:-4],x_center,y_center,txt_file[5][annotation])\n",
        "\n",
        "    draw = ImageDraw.Draw(im_original)\n",
        "    draw.rectangle((x1, y1, x2, y2), outline=(255, 0, 0), width=5)\n",
        "    im_original.save('/content/originals_test_annotations_drawing/'+txt_name[36:-4]+'.jpg')\n",
        "    #im_original = Image.open('/content/originals_test_annotations_drawing/'+txt_name[36:-4]+\".jpg\")\n",
        "#★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "#画像分割数\n",
        "split_x=20\n",
        "split_y=20\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "if not os.path.exists('/content/originals_test'):\n",
        "  shutil.unpack_archive('/content/originals_test.zip', '/content')\n",
        "\n",
        "#'NoneType' object is not subscriptableといわれるので先にipynb_checkpointsを消す\n",
        "#!rm -rf `find -type d -name .ipynb_checkpoints`\n",
        "\n",
        "#画像の読み込み\n",
        "read_files_name='/content/originals_test_annotations_drawing/'\n",
        "read_files = os.listdir(read_files_name)\n",
        "\n",
        "for file_name in read_files:\n",
        "  fname = read_files_name+file_name #画像ファイル名\n",
        "  foldaname=fname[9:]\n",
        "\n",
        "\n",
        "  #img = np.array(Image.open(fname))  \n",
        "  img=cv2.imread(fname,cv2.IMREAD_COLOR)\n",
        "  #画像分割先のフォルダを作成\n",
        "  #if not os.path.exists('/content/split_originals_test_annotations_drawing/'+file_name[:-4]):\n",
        "  #  os.makedirs('/content/split_originals_test_annotations_drawing/'+file_name[:-4])\n",
        "  if not os.path.exists('/content/split_originals_test_annotations_drawing/'):\n",
        "    os.makedirs('/content/split_originals_test_annotations_drawing/')\n",
        "\n",
        "\n",
        "  #画像の読み込み\n",
        "  h,w=img.shape[:2]\n",
        "\n",
        "  #画像の分割処理\n",
        "  cx=0\n",
        "  cy=0\n",
        "  for j in range(split_x):\n",
        "      for i in range(split_y):\n",
        "          split_pic=img[cy:cy+int(h/split_y),cx:cx+int(w/split_x),:]          \n",
        "          #cv2.imwrite(\"/content/split_originals_test_annotations_drawing/\"+file_name[:-4]+\"/\"+file_name[:-4]+'_y'+str('{0:02d}'.format(int(i)))+'_x'+str('{0:02d}'.format(int(j)))+foldaname[-4:],split_pic)\n",
        "          cy=cy+int(h/split_y)\n",
        "      cy=0\n",
        "      cx=cx+int(w/split_x)\n",
        "\n",
        "  #分割する線を描いた画像を出力\n",
        "  y_step=int(h/split_y) #縦の分割間隔\n",
        "  x_step=int(w/split_x) #横の分割間隔\n",
        "\n",
        "  #オブジェクトimgのshapeメソッドの1つ目の戻り値(画像の高さ)をimg_yに、2つ目の戻り値(画像の幅)をimg_xに\n",
        "  #img_y,img_x=img.size\n",
        "  img_y,img_x=img.shape[:2]  \n",
        "\n",
        "  #横線を引く：y_stepからimg_yの手前までy_stepおきに白い(BGRすべて255)横線を引く\n",
        "  img[y_step:img_y:y_step, :, :] = 0\n",
        "  #縦線を引く：x_stepからimg_xの手前までx_stepおきに白い(BGRすべて255)縦線を引く\n",
        "  img[:, x_step:img_x:x_step, :] = 0\n",
        "\n",
        "  cv2.imwrite(\"/content/split_originals_test_annotations_drawing/\"+file_name[:-4]+\"grid\"+foldaname[-4:],img) #ファイル名'grid.png'でimgを保存"
      ],
      "metadata": {
        "id": "FRURI8e1wpYj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##★vgg16で補正をかける（やってもやらなくてもよい）"
      ],
      "metadata": {
        "id": "tHWwymCe6jpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "%cd -q '/content/'\n",
        "# Download trained weights\n",
        "!wget -q https://github.com/1900690/koukai/releases/download/mite_demo/mite_detect_4.zip\n",
        "shutil.unpack_archive('/content/mite_detect_4.zip', '/content')\n",
        "os.remove('/content/mite_detect_4.zip')\n",
        "#★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "#tf用事前準備\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "TF_MODEL_FILE_PATH = '/content/model_3class_4000.tflite' # The default path to the saved TensorFlow Lite model\n",
        "interpreter = tf.lite.Interpreter(model_path=TF_MODEL_FILE_PATH)\n",
        "classify_lite = interpreter.get_signature_runner('serving_default')\n",
        "\n",
        "#class_names =['devidedmite', 'mite', 'notmite']\n",
        "class_names =['2', '1', '0']\n",
        "\n",
        "def rot_cut(src_img, deg, center, size):\n",
        "    rot_mat = cv2.getRotationMatrix2D(center, deg, 1.0)\n",
        "    rot_mat[0][2] += -center[0]+size[0]/2 # -(元画像内での中心位置)+(切り抜きたいサイズの中心)\n",
        "    rot_mat[1][2] += -center[1]+size[1]/2 # 同上\n",
        "    return cv2.warpAffine(src_img, rot_mat, size)\n",
        "\n",
        "\n",
        "def pil2cv(image):\n",
        "    ''' PIL型 -> OpenCV型 '''\n",
        "    new_image = np.array(image, dtype=np.uint8)\n",
        "    if new_image.ndim == 2: # モノクロ\n",
        "        pass\n",
        "    elif new_image.shape[2] == 3: # カラー\n",
        "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGB2BGR)\n",
        "    elif new_image.shape[2] == 4: # 透過\n",
        "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGBA2BGRA)\n",
        "    return new_image"
      ],
      "metadata": {
        "id": "uk-K82On7H4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#座標データを置き換えるので保存用にディレクトリを分ける\n",
        "if not os.path.exists('/content/originals_test_annotations_drawing_yolotype'):\n",
        " shutil.copytree('/content/originals_test_annotations_yolotype','/content/originals_test_annotations_drawing_yolotype')\n",
        "shutil.rmtree('/content/originals_test_annotations_yolotype')\n",
        "os.makedirs('/content/originals_test_annotations_yolotype')\n",
        "\n",
        "#検出した全データ\n",
        "read_files_name_bbox='/content/originals_test_annotations_drawing_yolotype/*'\n",
        "read_files_bbox = glob.glob(read_files_name_bbox)\n",
        "\n",
        "for txt_name in read_files_bbox:\n",
        "  txt_file=pd.read_csv(txt_name,header=None, sep=\" \")\n",
        "  for i in range(len(txt_file[0])):\n",
        "    im_original = Image.open('/content/originals_test/'+txt_name[53:-4]+\".jpg\")\n",
        "    image_width,image_height=np.array(im_original).shape[:2]\n",
        "    x_center=float(txt_file[1][i])*image_height\n",
        "    y_center=float(txt_file[2][i])*image_width\n",
        "    #tfliteで判定★★★★★★★★★★★★★★★★★★★★\n",
        "    cutimage_original=rot_cut(pil2cv(im_original), 0,(int(x_center),int(y_center)), (192,192))\n",
        "    img_array = tf.expand_dims(tf.keras.utils.img_to_array(cutimage_original), 0) # Create a batch\n",
        "    predictions_lite = classify_lite(input_1=img_array)['sequential']#判定\n",
        "    score_lite = tf.nn.softmax(predictions_lite)#スコアを抽出\n",
        "    confidence=np.amax(score_lite)#confidence\n",
        "    tf_score=class_names[np.argmax(score_lite)]          \n",
        "    #★★★★★★★★★★★★★★★★★★★★\n",
        "    if int(tf_score) >0:\n",
        "      with open('/content/originals_test_annotations_yolotype/'+txt_name[53:-4]+'.txt', 'a') as f:      \n",
        "        rote=str(txt_file[0][i])+','+str(txt_file[1][i])+','+str(txt_file[2][i])+','+str(txt_file[3][i])+','+str(txt_file[4][i])+'\\n'\n",
        "        f.write(rote)  \n"
      ],
      "metadata": {
        "id": "ErxBYv6x7mZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##元画像とＹＯＬＯ座標データをエクスポート"
      ],
      "metadata": {
        "id": "ugH5xFlJnx2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "with open('/content/classes.txt', 'w') as f:\n",
        "  rote='mite'\n",
        "  f.write(rote)\n",
        "\n",
        "if not os.path.exists('/content/yolo_format/'):\n",
        "  os.makedirs('/content/yolo_format/')\n",
        "  shutil.move('/content/classes.txt','/content/yolo_format/')\n",
        "  shutil.copytree('/content/originals_test_annotations_yolotype','/content/yolo_format/annotations')\n",
        "\n",
        "shutil.make_archive('/content/yolo_format', format='zip', root_dir='/content/yolo_format')\n",
        "files.download('/content/yolo_format.zip')\n",
        "\n",
        "shutil.make_archive('/content/originals', format='zip', root_dir='/content/originals_test')\n",
        "files.download('/content/originals.zip')"
      ],
      "metadata": {
        "id": "NJgDchlHoCEe",
        "outputId": "e1ab74c6-661c-4c69-ade3-6890868c7683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_308a0460-887c-4879-a600-96ac39105ba5\", \"yolo_format.zip\", 2995)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_811d74f8-dd55-41e3-b3e2-1745ab666b58\", \"originals.zip\", 13067145)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##マスクとannotationデータをアップロード"
      ],
      "metadata": {
        "id": "NTK0felyvIRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "正解のマスク画像をアップロード"
      ],
      "metadata": {
        "id": "L-1icGvvxS3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('/content/instance_segmentations'):\n",
        "    os.makedirs('/content/instance_segmentations')\n",
        "\n",
        "%cd '/content/instance_segmentations'\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "-Kl3tUr0xbC4",
        "outputId": "a82ce006-b409-4f97-f2c4-291e0efc3b33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/instance_segmentations\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ca744fe1-0b70-4915-91e5-1ef676aa22a3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ca744fe1-0b70-4915-91e5-1ef676aa22a3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IMG_20220310_111421_180.png to IMG_20220310_111421_180.png\n",
            "Saving IMG_20220310_111443_180.png to IMG_20220310_111443_180.png\n",
            "Saving IMG_20220310_111515_180.png to IMG_20220310_111515_180.png\n",
            "Saving IMG_20220310_111535_180.png to IMG_20220310_111535_180.png\n",
            "Saving IMG_20220310_111711_180.png to IMG_20220310_111711_180.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "正解のYOLO座標をアップロード"
      ],
      "metadata": {
        "id": "XYDrtkeAFuh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('/content/annotations'):\n",
        "    os.makedirs('/content/annotations')\n",
        "\n",
        "%cd '/content/annotations'\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "CiUG8-LIVeCr",
        "outputId": "350940f2-0e13-4a5d-f58f-6cf6a5826c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/annotations\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-499c3590-4b5f-45de-8403-4117a77cdf61\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-499c3590-4b5f-45de-8403-4117a77cdf61\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IMG_20220310_111421_180.txt to IMG_20220310_111421_180.txt\n",
            "Saving IMG_20220310_111443_180.txt to IMG_20220310_111443_180.txt\n",
            "Saving IMG_20220310_111515_180.txt to IMG_20220310_111515_180.txt\n",
            "Saving IMG_20220310_111535_180.txt to IMG_20220310_111535_180.txt\n",
            "Saving IMG_20220310_111711_180.txt to IMG_20220310_111711_180.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##正解を赤、見逃しを白、重複を青、誤認識を紫で描写"
      ],
      "metadata": {
        "id": "9iJ88fsf2q0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw\n",
        "\n",
        "#画像の読み込み\n",
        "read_files_name_bbox='/content/instance_segmentations/*'\n",
        "read_files_bbox = glob.glob(read_files_name_bbox)\n",
        "detect_positive=0\n",
        "\n",
        "if os.path.exists('/content/acctuary_count.txt'):\n",
        "  os.remove('/content/acctuary_count.txt')\n",
        "\n",
        "if os.path.exists('/content/answer_count.txt'):\n",
        "  os.remove('/content/answer_count.txt')\n",
        "\n",
        "if not os.path.exists('/content/instance_segmentations_index_coler/'):\n",
        "  os.makedirs('/content/instance_segmentations_index_coler/')\n",
        "\n",
        "for txt_name in read_files_bbox:\n",
        "  \n",
        "  img = np.array(Image.open('/content/originals_test/'+txt_name[32:-4]+\".jpg\"))\n",
        "  img_drawing = Image.open('/content/originals_grid/'+txt_name[32:-4]+\"grid.jpg\")\n",
        "  img_true = np.array(Image.open(txt_name))#ダイレクトカラー\n",
        "\n",
        "  #numpyからpilへ変換\n",
        "  im = Image.fromarray(img_true)\n",
        "  #ダイレクトカラーからインデックスカラーへ\n",
        "  c = im.getcolors(im.width * im.height)\n",
        "  h,w=np.array(im).shape[:2]\n",
        "  indexcoler=np.zeros((h,w))\n",
        "  for coler in range(len(c)):\n",
        "    split=np.zeros((h,w,3))\n",
        "    split[:,:,0]=np.full((h, w), c[coler][1][0])\n",
        "    split[:,:,1]=np.full((h, w), c[coler][1][1])\n",
        "    split[:,:,2]=np.full((h, w), c[coler][1][2])\n",
        "    truefalse=np.equal(split,im)\n",
        "    zeroone = np.where(truefalse == True, 1, 0)\n",
        "    after=zeroone[:,:,0]+zeroone[:,:,1]+zeroone[:,:,2]\n",
        "    split_after = np.where(after == 3, coler, 0)\n",
        "    indexcoler=indexcoler+split_after\n",
        "  #pilからnumpyへ変換\n",
        "  img_true = np.array(indexcoler)\n",
        "  \n",
        "  #最大の面積を０にする\n",
        "  #0を定義するため+1\n",
        "  img_true=img_true+1\n",
        "  #最大の面積に格納されている値を出す\n",
        "  max_area=Image.fromarray(img_true).getcolors(Image.fromarray(img_true).width * Image.fromarray(img_true).height)\n",
        "  max_number=np.sort(max_area,axis=0)[::-1][0][1]\n",
        "  #最大の面積の値を０に置き換え\n",
        "  img_true = np.where(img_true == max_number, 0, img_true)\n",
        "\n",
        "  cv2.imwrite(\"/content/instance_segmentations_index_coler/\"+txt_name[32:],img_true) #indexカラーで保存\n",
        "  #★\n",
        "  txt_file_detected = pd.read_csv('/content/originals_test_annotations_yolotype/'+txt_name[32:-4]+\".txt\",header=None, sep=\" \") \n",
        "  #txt_file_detected = pd.read_csv('/content/originals_test_annotations/'+txt_name[32:-4]+\".txt\",header=None, sep=\" \")\n",
        "  txt_file_answer = pd.read_csv('/content/annotations/'+txt_name[32:-4]+\".txt\",header=None, sep=\" \")\n",
        " \n",
        "  h,w=img.shape[:2]\n",
        "  #binary_img=np.zeros_like(img)\n",
        "\n",
        "  for i in range(len(txt_file_detected)):\n",
        "    x_center=float(txt_file_detected[1][i])*w\n",
        "    y_center=float(txt_file_detected[2][i])*h\n",
        "    width=float(txt_file_detected[3][i])*w\n",
        "    height=float(txt_file_detected[4][i])*h\n",
        "\n",
        "    #x1=int(x_center-height/2)\n",
        "    #y1=int(y_center-width/2)\n",
        "    #x2=int(x_center+height/2)\n",
        "    #y2=int(y_center+width/2)\n",
        "    x1=int(x_center-width/2)\n",
        "    y1=int(y_center-height/2)\n",
        "    x2=int(x_center+width/2)\n",
        "    y2=int(y_center+height/2)\n",
        "    \n",
        "    text=txt_name[32:-4],img_true[int(y_center),int(x_center)]\n",
        "    #print(text)\n",
        "    with open('/content/acctuary_count'+'.txt', 'a') as f:      \n",
        "        #rote=str(txt_name[32:-4])+','+str(img_true[int(y_center),int(x_center)][0])+str(img_true[int(y_center),int(x_center)][1])+str(img_true[int(y_center),int(x_center)][2])+','+str(x_center)+','+str(y_center)+'\\n'\n",
        "        rote=str(txt_name[32:-4])+','+str(img_true[int(y_center),int(x_center)])+','+str(int(x_center))+','+str(int(y_center))+','+str(int(x1))+','+str(int(y1))+','+str(int(x2))+','+str(int(y2))+','+str(txt_file_detected[1][i])+','+str(txt_file_detected[2][i])+','+str(txt_file_detected[3][i])+','+str(txt_file_detected[4][i])+'\\n'\n",
        "        f.write(rote)  \n",
        " \n",
        "  h,w=img.shape[:2]\n",
        "  #binary_img=np.zeros_like(img)\n",
        "\n",
        "  for i in range(len(txt_file_answer)):\n",
        "    x_center=float(txt_file_answer[1][i])*w\n",
        "    y_center=float(txt_file_answer[2][i])*h\n",
        "    width=float(txt_file_answer[3][i])*w\n",
        "    height=float(txt_file_answer[4][i])*h\n",
        "\n",
        "    #x1=int(x_center-height/2)\n",
        "    #y1=int(y_center-width/2)\n",
        "    #x2=int(x_center+height/2)\n",
        "    #y2=int(y_center+width/2)\n",
        "    x1=int(x_center-width/2)\n",
        "    y1=int(y_center-height/2)\n",
        "    x2=int(x_center+width/2)\n",
        "    y2=int(y_center+height/2)\n",
        "    \n",
        "    text=txt_name[32:-4],img_true[int(y_center),int(x_center)]\n",
        "    #print(text)\n",
        "    with open('/content/answer_count'+'.txt', 'a') as f:      \n",
        "        #rote=str(txt_name[32:-4])+','+str(img_true[int(y_center),int(x_center)][0])+str(img_true[int(y_center),int(x_center)][1])+str(img_true[int(y_center),int(x_center)][2])+','+str(x_center)+','+str(y_center)+'\\n'\n",
        "        rote=str(txt_name[32:-4])+','+str(img_true[int(y_center),int(x_center)])+','+str(int(x_center))+','+str(int(y_center))+','+str(int(x1))+','+str(int(y1))+','+str(int(x2))+','+str(int(y2))+','+str(txt_file_answer[1][i])+','+str(txt_file_answer[2][i])+','+str(txt_file_answer[3][i])+','+str(txt_file_answer[4][i])+'\\n'\n",
        "        f.write(rote)\n",
        "#★★★★★★★★★★★★★★★★★★★★★★★★\n",
        "from PIL import Image, ImageDraw\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "if os.path.exists('/content/false_potision.txt'):\n",
        "  os.remove('/content/false_potision.txt')\n",
        "\n",
        "if os.path.exists('/content/split_originals_test_annotations_answer_drawing/'):\n",
        "  shutil.rmtree('/content/split_originals_test_annotations_answer_drawing/')\n",
        "\n",
        "shutil.copytree('/content/originals_grid','/content/split_originals_test_annotations_answer_drawing/')\n",
        "\n",
        "if not os.path.exists('/content/split_originals_test_annotations_answer_yolotype'):\n",
        "  os.makedirs('/content/split_originals_test_annotations_answer_yolotype')\n",
        "\n",
        "#正解の数\n",
        "answer_data=pd.read_csv('/content/answer_count.txt',header=None, sep=\",\")\n",
        "answer_data_ascending=answer_data.sort_values(by=[0,1])\n",
        "\n",
        "#検出した全データ\n",
        "all_data=pd.read_csv('/content/acctuary_count.txt',header=None, sep=\",\")\n",
        "all_data_ascending=all_data.sort_values(by=[0,1])\n",
        "\n",
        "for line_number in range(len(all_data_ascending)):\n",
        "  img_drawing = Image.open('/content/split_originals_test_annotations_answer_drawing/'+all_data_ascending.iloc[line_number][0]+\"grid.jpg\")\n",
        "  draw = ImageDraw.Draw(img_drawing)\n",
        "  #赤\n",
        "  draw.rectangle((all_data_ascending.iloc[line_number][4], all_data_ascending.iloc[line_number][5],all_data_ascending.iloc[line_number][6],all_data_ascending.iloc[line_number][7]),fill=(255,0,0), outline=(255,0,0), width=5)\n",
        "  img_drawing.save('/content/split_originals_test_annotations_answer_drawing/'+all_data_ascending.iloc[line_number][0]+'grid.jpg')\n",
        "\n",
        "#範囲外を検出\n",
        "false_potision_outofrange=all_data[all_data[1]==0]\n",
        "false_potision_outofrange_ascending=false_potision_outofrange.sort_values(by=[0,1])\n",
        "\n",
        "for line_number in range(len(false_potision_outofrange_ascending)):\n",
        "  img_drawing = Image.open('/content/split_originals_test_annotations_answer_drawing/'+false_potision_outofrange_ascending.iloc[line_number][0]+\"grid.jpg\")\n",
        "  draw = ImageDraw.Draw(img_drawing)\n",
        "  #紫\n",
        "  draw.rectangle((false_potision_outofrange_ascending.iloc[line_number][4], false_potision_outofrange_ascending.iloc[line_number][5],false_potision_outofrange_ascending.iloc[line_number][6],false_potision_outofrange_ascending.iloc[line_number][7]),fill=(255,0,255),outline=(255,0,255), width=5)\n",
        "  img_drawing.save('/content/split_originals_test_annotations_answer_drawing/'+false_potision_outofrange_ascending.iloc[line_number][0]+'grid.jpg')\n",
        "\n",
        "  with open('/content/split_originals_test_annotations_answer_yolotype/'+false_potision_outofrange_ascending.iloc[line_number][0]+'grid.txt', 'a') as f:\n",
        "    rote=str(1)+' '+str(false_potision_outofrange_ascending.iloc[line_number][8])+' '+str(false_potision_outofrange_ascending.iloc[line_number][9])+' '+str(false_potision_outofrange_ascending.iloc[line_number][10])+' '+str(false_potision_outofrange_ascending.iloc[line_number][11])+'\\n'\n",
        "    f.write(rote)\n",
        "\n",
        "#被りを検出\n",
        "false_potision=all_data[all_data.duplicated(subset=[0,1],keep=False)]\n",
        "false_potision_duplicated=false_potision[false_potision[1]!=0]\n",
        "false_potision_duplicated_ascending=false_potision_duplicated.sort_values(by=[0,1])\n",
        "false_potision_duplicated_ascending_half=false_potision_duplicated_ascending[false_potision_duplicated_ascending.duplicated(subset=[0,1])]\n",
        "\n",
        "for line_number in range(len(false_potision_duplicated_ascending)):\n",
        "  img_drawing = Image.open('/content/split_originals_test_annotations_answer_drawing/'+false_potision_duplicated_ascending.iloc[line_number][0]+\"grid.jpg\")\n",
        "  draw = ImageDraw.Draw(img_drawing)\n",
        "  #青\n",
        "  draw.rectangle((false_potision_duplicated_ascending.iloc[line_number][4], false_potision_duplicated_ascending.iloc[line_number][5],false_potision_duplicated_ascending.iloc[line_number][6],false_potision_duplicated_ascending.iloc[line_number][7]),fill=(0,0,255), outline=(0,0,255), width=5)\n",
        "  img_drawing.save('/content/split_originals_test_annotations_answer_drawing/'+false_potision_duplicated_ascending.iloc[line_number][0]+'grid.jpg')\n",
        "  \n",
        "  with open('/content/split_originals_test_annotations_answer_yolotype/'+false_potision_duplicated_ascending.iloc[line_number][0]+'grid.txt', 'a') as f:\n",
        "    rote=str(2)+' '+str(false_potision_duplicated_ascending.iloc[line_number][8])+' '+str(false_potision_duplicated_ascending.iloc[line_number][9])+' '+str(false_potision_duplicated_ascending.iloc[line_number][10])+' '+str(false_potision_duplicated_ascending.iloc[line_number][11])+'\\n'\n",
        "    f.write(rote)\n",
        "\n",
        "#見逃したダニの数\n",
        "false_potision_overlooked=pd.merge(all_data_ascending,answer_data_ascending, on=[0,1], how='outer', indicator=True)\n",
        "false_potision_overlooked_ascending = false_potision_overlooked[false_potision_overlooked['_merge'] == 'right_only'].iloc[:,[0,1,12,13,14,15,16,17,18,19,20,21]]\n",
        "false_potision_overlooked_ascending=false_potision_overlooked_ascending.rename(columns={'2_y': 2,'3_y': 3,'4_y': 4,'5_y': 5,'6_y': 6,'7_y': 7,'8_y': 8,'9_y': 9,'10_y': 10,'11_y': 11})\n",
        "#false_potision_overlooked_ascending=false_potision_overlooked_ascending.rename(columns={'3_y': 3})\n",
        "\n",
        "for line_number in range(len(false_potision_overlooked_ascending)):\n",
        "  img_drawing = Image.open('/content/split_originals_test_annotations_answer_drawing/'+false_potision_overlooked_ascending.iloc[line_number][0]+\"grid.jpg\")\n",
        "  draw = ImageDraw.Draw(img_drawing)\n",
        "  #白\n",
        "  draw.rectangle((false_potision_overlooked_ascending.iloc[line_number][4], false_potision_overlooked_ascending.iloc[line_number][5],false_potision_overlooked_ascending.iloc[line_number][6],false_potision_overlooked_ascending.iloc[line_number][7]),fill=(255,255,255), outline=(255,255,255), width=5)\n",
        "  img_drawing.save('/content/split_originals_test_annotations_answer_drawing/'+false_potision_overlooked_ascending.iloc[line_number][0]+'grid.jpg')\n",
        "\n",
        "  with open('/content/split_originals_test_annotations_answer_yolotype/'+false_potision_overlooked_ascending.iloc[line_number][0]+'grid.txt', 'a') as f:\n",
        "    rote=str(3)+' '+str(false_potision_overlooked_ascending.iloc[line_number][8])+' '+str(false_potision_overlooked_ascending.iloc[line_number][9])+' '+str(false_potision_overlooked_ascending.iloc[line_number][10])+' '+str(false_potision_overlooked_ascending.iloc[line_number][11])+'\\n'\n",
        "    f.write(rote)\n",
        "\n",
        "#正解のダニのみ抽出\n",
        "correct1=pd.merge(all_data_ascending,false_potision_outofrange_ascending, how='outer', indicator=True)\n",
        "correct2=correct1[correct1['_merge'] == 'left_only'].iloc[:,0:12]\n",
        "correct3=pd.merge(correct2,false_potision_duplicated_ascending, how='outer', indicator=True)\n",
        "correct=correct3[correct3['_merge'] == 'left_only'].iloc[:,0:12]\n",
        "\n",
        "for line_number in range(len(correct)):\n",
        "  with open('/content/split_originals_test_annotations_answer_yolotype/'+correct.iloc[line_number][0]+'grid.txt', 'a') as f:\n",
        "    rote=str(0)+' '+str(correct.iloc[line_number][8])+' '+str(correct.iloc[line_number][9])+' '+str(correct.iloc[line_number][10])+' '+str(correct.iloc[line_number][11])+'\\n'\n",
        "    f.write(rote)"
      ],
      "metadata": {
        "id": "xzjQJFf4xpH0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##grid画像とＹＯＬＯ座標データをエクスポート"
      ],
      "metadata": {
        "id": "7zyaDvsRvu7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "with open('/content/classes.txt', 'w') as f:\n",
        "  rote='mite'+'\\n'+'not_mite'+'\\n'+'divided_mite'+'\\n'+'miss_mite'\n",
        "  f.write(rote)\n",
        "\n",
        "if os.path.exists('/content/yolo_format/'):\n",
        "  shutil.rmtree('/content/yolo_format')\n",
        "\n",
        "if not os.path.exists('/content/yolo_format/'):\n",
        "  os.makedirs('/content/yolo_format/')\n",
        "  shutil.move('/content/classes.txt','/content/yolo_format/')\n",
        "  shutil.copytree('/content/split_originals_test_annotations_answer_yolotype','/content/yolo_format/annotations')\n",
        "\n",
        "shutil.make_archive('/content/yolo_format', format='zip', root_dir='/content/yolo_format')\n",
        "files.download('/content/yolo_format.zip')\n",
        "\n",
        "shutil.make_archive('/content/originals_grid', format='zip', root_dir='/content/originals_grid')\n",
        "files.download('/content/originals_grid.zip')"
      ],
      "metadata": {
        "id": "Yyh7T_1AuekF",
        "outputId": "0adf229b-9ed0-4cc6-edb0-11a0171bf14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1a913ae0-c41b-4d81-bd5c-49aa32433a98\", \"yolo_format.zip\", 6257)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aaaa59cb-ba05-4113-9e0b-6db33c79d4f1\", \"originals_grid.zip\", 9759956)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##正答率"
      ],
      "metadata": {
        "id": "8pZT9NnEWOje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(１－((**範囲外のダニ**＋**重複したダニ*1/2**)/**予測のダニのアノテーション数**))×(１－(**見逃したダニの数**/**正解のダニの数**))\n"
      ],
      "metadata": {
        "id": "iq4Q1b7XX7a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#正解率を計算vgg無し\n",
        "falsedetection=(len(false_potision_outofrange_ascending)+len(false_potision_duplicated_ascending)*1/2)/len(all_data_ascending)\n",
        "falseoverlooked=len(false_potision_overlooked_ascending)/len(answer_data_ascending)\n",
        "Accuracy=(1-falsedetection)*(1-falseoverlooked)\n",
        "print('誤検知率は',falsedetection)\n",
        "print('見逃し率は',falseoverlooked)\n",
        "print('正解率は',Accuracy)"
      ],
      "metadata": {
        "id": "aGDG3vrhxpXX",
        "outputId": "f66550b8-3f29-4f26-833b-76935f42b6da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "誤検知率は 0.20430107526881722\n",
            "見逃し率は 0.28846153846153844\n",
            "正解率は 0.5661703887510339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#正解率を計算vggあり\n",
        "falsedetection=(len(false_potision_outofrange_ascending)+len(false_potision_duplicated_ascending)*1/2)/len(all_data_ascending)\n",
        "falseoverlooked=len(false_potision_overlooked_ascending)/len(answer_data_ascending)\n",
        "Accuracy=(1-falsedetection)*(1-falseoverlooked)\n",
        "print('誤検知率は',falsedetection)\n",
        "print('見逃し率は',falseoverlooked)\n",
        "print('正解率は',Accuracy)"
      ],
      "metadata": {
        "id": "vgbVm9nWUssu",
        "outputId": "b6ebb1e6-e37d-46ac-dc24-bcc3c24f0676",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "誤検知率は 0.10897435897435898\n",
            "見逃し率は 0.3317307692307692\n",
            "正解率は 0.5954450197238659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#正解率を計算vggありyolo conf 0.3\n",
        "falsedetection=(len(false_potision_outofrange_ascending)+len(false_potision_duplicated_ascending)*1/2)/len(all_data_ascending)\n",
        "falseoverlooked=len(false_potision_overlooked_ascending)/len(answer_data_ascending)\n",
        "Accuracy=(1-falsedetection)*(1-falseoverlooked)\n",
        "print('誤検知率は',falsedetection)\n",
        "print('見逃し率は',falseoverlooked)\n",
        "print('正解率は',Accuracy)"
      ],
      "metadata": {
        "id": "JVoc43A8c_Si",
        "outputId": "1a19860b-c0bf-47b5-b70a-b9e0d7fcd414",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "誤検知率は 0.18888888888888888\n",
            "見逃し率は 0.2980769230769231\n",
            "正解率は 0.5693376068376068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#正解率を計算vggなし、背景処理あり 見逃し率は消えた葉っぱの分も含まれるので気にしない\n",
        "falsedetection=(len(false_potision_outofrange_ascending)+len(false_potision_duplicated_ascending)*1/2)/len(all_data_ascending)\n",
        "falseoverlooked=len(false_potision_overlooked_ascending)/len(answer_data_ascending)\n",
        "Accuracy=(1-falsedetection)*(1-falseoverlooked)\n",
        "print('誤検知率は',falsedetection)\n",
        "print('見逃し率は',falseoverlooked)\n",
        "print('正解率は',Accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4E-sZOjdl0v",
        "outputId": "d4f58b55-9feb-4766-88b3-e42cc17ff31a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "誤検知率は 0.1592356687898089\n",
            "見逃し率は 0.36538461538461536\n",
            "正解率は 0.533561979421852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ONNX形式へexport"
      ],
      "metadata": {
        "id": "9KIq6v6fy8Cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/yolov7'\n",
        "!python export.py --weight /content/drive/MyDrive/20221206yolov7-300epoch-2batch-7710images-640upsized-mite/weights/best.pt"
      ],
      "metadata": {
        "id": "LwO3u-IgzBcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##画像を結合"
      ],
      "metadata": {
        "id": "Y8lIt4CITbm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "#結合元の画像の読み込み\n",
        "originals=('/content/detect_output/*.jpg')\n",
        "read_files = glob.glob(originals)\n",
        "\n",
        "for name in read_files:\n",
        "  imagename=name[23:-12]\n",
        "  if not os.path.exists('/content/detect_output/'+imagename):\n",
        "    os.makedirs('/content/detect_output/'+imagename)\n",
        "  shutil.move(name,'/content/detect_output/'+imagename)"
      ],
      "metadata": {
        "id": "IhyIWgzL4a-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#'NoneType' object is not subscriptableといわれるので先にipynb_checkpointsを消す\n",
        "#!rm -rf `find -type d -name .ipynb_checkpoints`\n",
        "\n",
        "#画像結合先のフォルダを作成\n",
        "if not os.path.exists('/content/merged_pic_original/'):\n",
        "  os.makedirs('/content/merged_pic_original/')\n",
        "\n",
        "#結合元の画像の読み込み\n",
        "read_folda_name='/content/detect_output'\n",
        "read_folda = os.listdir(read_folda_name)\n",
        "\n",
        "for image_folda_name in read_folda:\n",
        "  if image_folda_name=='labels':\n",
        "    print(\"\")\n",
        "  else:\n",
        "    paths = glob.glob('/content/detect_output/'+image_folda_name+'/*')  # 画像のパス一覧\n",
        "\n",
        "    # 画像を読み込む。\n",
        "    imgs = np.array([cv2.imread(p) for p in sorted(paths)])\n",
        "    print(imgs.shape)\n",
        "\n",
        "    # 画像の形状を変更する。\n",
        "    h, w, c = imgs.shape[1:]\n",
        "    #rows, cols = 5, 3  # 結合前の画像が何行何列あるか\n",
        "    imgs = imgs.reshape(split_y, split_x, h, w, c)\n",
        "\n",
        "    merged = np.vstack([np.hstack(h) for h in imgs])\n",
        "    cv2.imwrite('/content/merged_pic_original/'+image_folda_name+'.jpg', merged)"
      ],
      "metadata": {
        "id": "-BD2GQOGz5H3",
        "outputId": "9f2a38d4-25c3-4353-8980-312e85ca00ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(400, 1040, 780, 3)\n",
            "(400, 1040, 780, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#画像サイズを縮小\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/originals_downsize/'):\n",
        "  os.makedirs('/content/originals_downsize/')\n",
        "\n",
        "read_folda_name='/content/merged_pic_original'\n",
        "read_folda = os.listdir(read_folda_name)\n",
        "\n",
        "for image_folda_name in read_folda:\n",
        "  # 読み込む画像を選択\n",
        "  img = cv2.imread('/content/merged_pic_original/'+image_folda_name)\n",
        "  h,w=img.shape[:2]\n",
        "  # サイズ設定｜cv2では(幅、高さ）の順で数値を設定\n",
        "  size = (int(w/5),int(h/5)) \n",
        "  # 画像拡大・縮小 オプションで拡大計算式変更可能\n",
        "  img_inter_area  = cv2.resize(img,size,interpolation = cv2.INTER_LINEAR) \n",
        "  #保存\n",
        "  cv2.imwrite('/content/originals_downsize/'+image_folda_name, img_inter_area)"
      ],
      "metadata": {
        "id": "R9J1gWWF9nOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##検出結果のテキストを整理"
      ],
      "metadata": {
        "id": "K0JxVvm3M7FW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#検出結果のテキストを整理\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "\n",
        "\n",
        "detectedtxt=('/content/detect_output/labels/*')\n",
        "read_files = glob.glob(detectedtxt)\n",
        "\n",
        "with open(\"/content/detect_position.txt\", \"w\") as new_file:\n",
        "    for name in read_files:\n",
        "        with open(name) as f:\n",
        "            for line in f:\n",
        "                new_file.write(line)\n",
        "txt_file = pd.read_csv(\"/content/detect_position.txt\",header=None, sep=\" \")"
      ],
      "metadata": {
        "id": "e7fBmvVgM_z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#動画でも推論可能"
      ],
      "metadata": {
        "id": "pf1HCVAStv4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py \\\n",
        "  --source inference/images/road.mp4 \\\n",
        "  --weights yolov7-e6e.pt \\\n",
        "  --conf 0.25 \\\n",
        "  --img-size 1280 \\\n",
        "  --device 0"
      ],
      "metadata": {
        "id": "l7_-Rofnt0TB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}